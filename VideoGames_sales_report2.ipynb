{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD4PcoWQ7fuZ"
      },
      "source": [
        "# Video game sales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au1bFZOP8kqi"
      },
      "source": [
        "Mount the drive folders to enable us to work with the data directly from the google drive shared folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xWvu3wm8sUK"
      },
      "source": [
        "Navigate to the shared folder and use pandas to import all the needed data. The data is in a CSV format (Comma Separated Values)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTS\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sys \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure, plot, title, xlabel, ylabel, show, legend\n",
        "from scipy.linalg import svd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "emln-g7c2pbD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8MSX_Klxwpw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e98dbe-6260-44d9-a270-85a5e2368de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#comment if not being run in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RQrmGY_s7fTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a11bf8-cd14-4642-ce0a-8ba2a26eb71f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1y22z3-6z1uAkyXOu7VSZEuBCOb3R_Gw4/INTRO DATA MINING\n",
            " 02450_exam-master.zip\n",
            " ANN_VideoGames_sales_report2.ipynb\n",
            "'K of One lambda testVideoGames_sales_report2.ipynb'\n",
            " \u001b[0m\u001b[01;34mOthers\u001b[0m/\n",
            "'Project 2 Report.gdoc'\n",
            " Test_classification_tasks_VideoGames_sales_report2.ipynb\n",
            " Test_linear_regression_VideoGames_sales_report2.ipynb\n",
            " Test_logistic_regression_VideoGames_sales_report2.ipynb\n",
            "'Test of get_dummies of VideoGames_sales_report2.ipynb'\n",
            " Test_regression_statistics_VideoGames_sales_report2.ipynb\n",
            " \u001b[01;34mtoolbox_02450\u001b[0m/\n",
            " Video_Games_Sales_as_at_22_Dec_2016.csv\n",
            " Video_Games_Sales_as_at_22_Dec_2016.gsheet\n",
            " VideoGames_sales_report2.ipynb\n",
            " Weights.gsheet\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/INTRO\\ DATA\\ MINING/\n",
        "%ls\n",
        "data_csv = pd.read_csv(\"Video_Games_Sales_as_at_22_Dec_2016.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ECUCKn-Fx6dH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7b0b83-956d-422d-a92b-6589da048bfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name                  2\n",
              "Platform              0\n",
              "Year_of_Release     269\n",
              "Genre                 2\n",
              "Publisher            54\n",
              "NA_Sales              0\n",
              "EU_Sales              0\n",
              "JP_Sales              0\n",
              "Other_Sales           0\n",
              "Global_Sales          0\n",
              "Critic_Score       8582\n",
              "Critic_Count       8582\n",
              "User_Score         9129\n",
              "User_Count         9129\n",
              "Developer          6623\n",
              "Rating             6769\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#check missing values\n",
        "data_csv.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CxOMDJw86Hw"
      },
      "source": [
        "#Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiuAuGLOp8nK"
      },
      "source": [
        "First of all we will use the method \"describe()\" to get the name of all the columns, together with some samples of each dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kq3xo05_s6Bu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "d55857d4-4c41-45b1-d4ba-47a03ae94b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Year_of_Release      NA_Sales      EU_Sales      JP_Sales  \\\n",
            "count     16450.000000  16719.000000  16719.000000  16719.000000   \n",
            "mean       2006.487356      0.263330      0.145025      0.077602   \n",
            "std           5.878995      0.813514      0.503283      0.308818   \n",
            "min        1980.000000      0.000000      0.000000      0.000000   \n",
            "25%        2003.000000      0.000000      0.000000      0.000000   \n",
            "50%        2007.000000      0.080000      0.020000      0.000000   \n",
            "75%        2010.000000      0.240000      0.110000      0.040000   \n",
            "max        2020.000000     41.360000     28.960000     10.220000   \n",
            "\n",
            "        Other_Sales  Global_Sales  Critic_Score  Critic_Count   User_Score  \\\n",
            "count  16719.000000  16719.000000   8137.000000   8137.000000  7590.000000   \n",
            "mean       0.047332      0.533543     68.967679     26.360821     7.125046   \n",
            "std        0.186710      1.547935     13.938165     18.980495     1.500006   \n",
            "min        0.000000      0.010000     13.000000      3.000000     0.000000   \n",
            "25%        0.000000      0.060000     60.000000     12.000000     6.400000   \n",
            "50%        0.010000      0.170000     71.000000     21.000000     7.500000   \n",
            "75%        0.030000      0.470000     79.000000     36.000000     8.200000   \n",
            "max       10.570000     82.530000     98.000000    113.000000     9.700000   \n",
            "\n",
            "         User_Count  \n",
            "count   7590.000000  \n",
            "mean     162.229908  \n",
            "std      561.282326  \n",
            "min        4.000000  \n",
            "25%       10.000000  \n",
            "50%       24.000000  \n",
            "75%       81.000000  \n",
            "max    10665.000000  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
              "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
              "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
              "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
              "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
              "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
              "\n",
              "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
              "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
              "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
              "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
              "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
              "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
              "\n",
              "   Critic_Count  User_Score  User_Count Developer Rating  \n",
              "0          51.0         8.0       322.0  Nintendo      E  \n",
              "1           NaN         NaN         NaN       NaN    NaN  \n",
              "2          73.0         8.3       709.0  Nintendo      E  \n",
              "3          73.0         8.0       192.0  Nintendo      E  \n",
              "4           NaN         NaN         NaN       NaN    NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d0708c9-f3b1-43af-b69d-bd6a81a6faea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Platform</th>\n",
              "      <th>Year_of_Release</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Other_Sales</th>\n",
              "      <th>Global_Sales</th>\n",
              "      <th>Critic_Score</th>\n",
              "      <th>Critic_Count</th>\n",
              "      <th>User_Score</th>\n",
              "      <th>User_Count</th>\n",
              "      <th>Developer</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wii Sports</td>\n",
              "      <td>Wii</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>41.36</td>\n",
              "      <td>28.96</td>\n",
              "      <td>3.77</td>\n",
              "      <td>8.45</td>\n",
              "      <td>82.53</td>\n",
              "      <td>76.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Super Mario Bros.</td>\n",
              "      <td>NES</td>\n",
              "      <td>1985.0</td>\n",
              "      <td>Platform</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>29.08</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.81</td>\n",
              "      <td>0.77</td>\n",
              "      <td>40.24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mario Kart Wii</td>\n",
              "      <td>Wii</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>Racing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.68</td>\n",
              "      <td>12.76</td>\n",
              "      <td>3.79</td>\n",
              "      <td>3.29</td>\n",
              "      <td>35.52</td>\n",
              "      <td>82.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>709.0</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wii Sports Resort</td>\n",
              "      <td>Wii</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>15.61</td>\n",
              "      <td>10.93</td>\n",
              "      <td>3.28</td>\n",
              "      <td>2.95</td>\n",
              "      <td>32.77</td>\n",
              "      <td>80.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pokemon Red/Pokemon Blue</td>\n",
              "      <td>GB</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>Role-Playing</td>\n",
              "      <td>Nintendo</td>\n",
              "      <td>11.27</td>\n",
              "      <td>8.89</td>\n",
              "      <td>10.22</td>\n",
              "      <td>1.00</td>\n",
              "      <td>31.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d0708c9-f3b1-43af-b69d-bd6a81a6faea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d0708c9-f3b1-43af-b69d-bd6a81a6faea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d0708c9-f3b1-43af-b69d-bd6a81a6faea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(data_csv.describe())\n",
        "data_csv.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hUjGg3ctR-r"
      },
      "source": [
        "We will drop the Name, Critic count and User count columns since we believe they do not add any relevant information in our dataset. Finally, we delete all the rows that contain a NULL value since it is uncomplete data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g3yzir-RtkYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a06c2fb-e827-431d-a270-8973f5de136e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6826 entries, 0 to 16706\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Platform         6826 non-null   object \n",
            " 1   Year_of_Release  6826 non-null   float64\n",
            " 2   Genre            6826 non-null   object \n",
            " 3   NA_Sales         6826 non-null   float64\n",
            " 4   EU_Sales         6826 non-null   float64\n",
            " 5   JP_Sales         6826 non-null   float64\n",
            " 6   Other_Sales      6826 non-null   float64\n",
            " 7   Critic_Score     6826 non-null   float64\n",
            " 8   User_Score       6826 non-null   float64\n",
            " 9   Rating           6826 non-null   object \n",
            "dtypes: float64(7), object(3)\n",
            "memory usage: 586.6+ KB\n"
          ]
        }
      ],
      "source": [
        "data_csv = data_csv.drop(columns=['Name'])\n",
        "data_csv = data_csv.drop(columns=['Critic_Count'])\n",
        "data_csv = data_csv.drop(columns=['User_Count'])\n",
        "data_csv = data_csv.drop(columns=['Global_Sales'])\n",
        "data_csv = data_csv.drop(columns=['Publisher'])\n",
        "data_csv = data_csv.drop(columns=['Developer'])\n",
        "data_csv['User_Score'] = data_csv['User_Score'].astype(float) #make the user score float64\n",
        "data_csv['EU_Sales'] = data_csv['EU_Sales'].mul(1000)\n",
        "data_csv['Other_Sales'] = data_csv['Other_Sales'].mul(1000)\n",
        "data_csv['JP_Sales'] = data_csv['JP_Sales'].mul(1000)\n",
        "data_csv['NA_Sales'] = data_csv['NA_Sales'].mul(1000)\n",
        "data_csv['User_Score'] = data_csv['User_Score'].mul(10)\n",
        "data_csv = data_csv.dropna()\n",
        "data_csv.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMSnCtqqyeGb"
      },
      "source": [
        "We will start the encoding of the variables that need it, which are the following:\n",
        "\n",
        "1. Platform → Label Encoder\n",
        "2. Genre → Label Encoder\n",
        "5. Rating → Label Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "esUVHaBRyjtc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "1a48115f-289f-4678-fe77-ae6e9ae533c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################ DATA AFTER ENCODING ################################################################\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year_of_Release  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Critic_Score  \\\n",
              "0           2006.0   41360.0   28960.0    3770.0       8450.0          76.0   \n",
              "2           2008.0   15680.0   12760.0    3790.0       3290.0          82.0   \n",
              "3           2009.0   15610.0   10930.0    3280.0       2950.0          80.0   \n",
              "6           2006.0   11280.0    9140.0    6500.0       2880.0          89.0   \n",
              "7           2006.0   13960.0    9180.0    2930.0       2840.0          58.0   \n",
              "\n",
              "   User_Score  AO  E  E10+  ...  Fighting  Misc  Platform  Puzzle  Racing  \\\n",
              "0        80.0   0  1     0  ...         0     0         0       0       0   \n",
              "2        83.0   0  1     0  ...         0     0         0       0       1   \n",
              "3        80.0   0  1     0  ...         0     0         0       0       0   \n",
              "6        85.0   0  1     0  ...         0     0         1       0       0   \n",
              "7        66.0   0  1     0  ...         0     1         0       0       0   \n",
              "\n",
              "   Role-Playing  Shooter  Simulation  Sports  Strategy  \n",
              "0             0        0           0       1         0  \n",
              "2             0        0           0       0         0  \n",
              "3             0        0           0       1         0  \n",
              "6             0        0           0       0         0  \n",
              "7             0        0           0       0         0  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c369f15b-c197-4f46-a6a4-3aca4418df8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year_of_Release</th>\n",
              "      <th>NA_Sales</th>\n",
              "      <th>EU_Sales</th>\n",
              "      <th>JP_Sales</th>\n",
              "      <th>Other_Sales</th>\n",
              "      <th>Critic_Score</th>\n",
              "      <th>User_Score</th>\n",
              "      <th>AO</th>\n",
              "      <th>E</th>\n",
              "      <th>E10+</th>\n",
              "      <th>...</th>\n",
              "      <th>Fighting</th>\n",
              "      <th>Misc</th>\n",
              "      <th>Platform</th>\n",
              "      <th>Puzzle</th>\n",
              "      <th>Racing</th>\n",
              "      <th>Role-Playing</th>\n",
              "      <th>Shooter</th>\n",
              "      <th>Simulation</th>\n",
              "      <th>Sports</th>\n",
              "      <th>Strategy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>41360.0</td>\n",
              "      <td>28960.0</td>\n",
              "      <td>3770.0</td>\n",
              "      <td>8450.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008.0</td>\n",
              "      <td>15680.0</td>\n",
              "      <td>12760.0</td>\n",
              "      <td>3790.0</td>\n",
              "      <td>3290.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009.0</td>\n",
              "      <td>15610.0</td>\n",
              "      <td>10930.0</td>\n",
              "      <td>3280.0</td>\n",
              "      <td>2950.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>11280.0</td>\n",
              "      <td>9140.0</td>\n",
              "      <td>6500.0</td>\n",
              "      <td>2880.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2006.0</td>\n",
              "      <td>13960.0</td>\n",
              "      <td>9180.0</td>\n",
              "      <td>2930.0</td>\n",
              "      <td>2840.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c369f15b-c197-4f46-a6a4-3aca4418df8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c369f15b-c197-4f46-a6a4-3aca4418df8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c369f15b-c197-4f46-a6a4-3aca4418df8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "Ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "\n",
        "# data_csv['Platform'] = label_encoder.fit_transform(data_csv['Platform']) #encoding 'Platform' attribute\n",
        "# data_csv['Genre'] = label_encoder.fit_transform(data_csv['Genre']) #encoding 'Genre' attribute\n",
        "# data_csv['Rating'] = label_encoder.fit_transform(data_csv['Rating']) #encoding 'Rating' attribute\n",
        "\n",
        "three_hot = pd.get_dummies(data_csv['Rating'])\n",
        "#Drop column B as it is now encoded\n",
        "data_csv = data_csv.drop('Rating',axis = 1)\n",
        "#Join the encoded data_csv\n",
        "data_csv = data_csv.join(three_hot)\n",
        "\n",
        "\n",
        "one_hot = pd.get_dummies(data_csv['Platform'])\n",
        "#Drop column B as it is now encoded\n",
        "data_csv = data_csv.drop('Platform',axis = 1)\n",
        "#Join the encoded data_csv\n",
        "data_csv = data_csv.join(one_hot)\n",
        "\n",
        "\n",
        "two_hot = pd.get_dummies(data_csv['Genre'])\n",
        "#Drop column B as it is now encoded\n",
        "data_csv = data_csv.drop('Genre',axis = 1)\n",
        "#Join the encoded data_csv\n",
        "data_csv = data_csv.join(two_hot)\n",
        "\n",
        "print('################################################################ DATA AFTER ENCODING ################################################################')\n",
        "data_csv.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see some outliers that should be removed before proceeding with the data processing."
      ],
      "metadata": {
        "id": "QwASFerfOOm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_low = data_csv[\"JP_Sales\"].quantile(0.025)\n",
        "q_hi  = data_csv[\"JP_Sales\"].quantile(0.975)\n",
        "\n",
        "print(q_low, q_hi)\n",
        "\n",
        "data_csv = data_csv[(data_csv[\"JP_Sales\"] < q_hi) & (data_csv[\"JP_Sales\"] > q_low)]\n",
        "data_csv.info()"
      ],
      "metadata": {
        "id": "8ab2oTvKOpnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3e4602-33f8-4333-86de-4d56dd0f9065"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 560.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1837 entries, 14 to 16573\n",
            "Data columns (total 43 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Year_of_Release  1837 non-null   float64\n",
            " 1   NA_Sales         1837 non-null   float64\n",
            " 2   EU_Sales         1837 non-null   float64\n",
            " 3   JP_Sales         1837 non-null   float64\n",
            " 4   Other_Sales      1837 non-null   float64\n",
            " 5   Critic_Score     1837 non-null   float64\n",
            " 6   User_Score       1837 non-null   float64\n",
            " 7   AO               1837 non-null   uint8  \n",
            " 8   E                1837 non-null   uint8  \n",
            " 9   E10+             1837 non-null   uint8  \n",
            " 10  K-A              1837 non-null   uint8  \n",
            " 11  M                1837 non-null   uint8  \n",
            " 12  RP               1837 non-null   uint8  \n",
            " 13  T                1837 non-null   uint8  \n",
            " 14  3DS              1837 non-null   uint8  \n",
            " 15  DC               1837 non-null   uint8  \n",
            " 16  DS               1837 non-null   uint8  \n",
            " 17  GBA              1837 non-null   uint8  \n",
            " 18  GC               1837 non-null   uint8  \n",
            " 19  PC               1837 non-null   uint8  \n",
            " 20  PS               1837 non-null   uint8  \n",
            " 21  PS2              1837 non-null   uint8  \n",
            " 22  PS3              1837 non-null   uint8  \n",
            " 23  PS4              1837 non-null   uint8  \n",
            " 24  PSP              1837 non-null   uint8  \n",
            " 25  PSV              1837 non-null   uint8  \n",
            " 26  Wii              1837 non-null   uint8  \n",
            " 27  WiiU             1837 non-null   uint8  \n",
            " 28  X360             1837 non-null   uint8  \n",
            " 29  XB               1837 non-null   uint8  \n",
            " 30  XOne             1837 non-null   uint8  \n",
            " 31  Action           1837 non-null   uint8  \n",
            " 32  Adventure        1837 non-null   uint8  \n",
            " 33  Fighting         1837 non-null   uint8  \n",
            " 34  Misc             1837 non-null   uint8  \n",
            " 35  Platform         1837 non-null   uint8  \n",
            " 36  Puzzle           1837 non-null   uint8  \n",
            " 37  Racing           1837 non-null   uint8  \n",
            " 38  Role-Playing     1837 non-null   uint8  \n",
            " 39  Shooter          1837 non-null   uint8  \n",
            " 40  Simulation       1837 non-null   uint8  \n",
            " 41  Sports           1837 non-null   uint8  \n",
            " 42  Strategy         1837 non-null   uint8  \n",
            "dtypes: float64(7), uint8(36)\n",
            "memory usage: 179.4 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n"
      ],
      "metadata": {
        "id": "dn4PH82cWUYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ALL IMPORTS\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "9UfyCIbLYYSE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide the data into different datasets, training and testing"
      ],
      "metadata": {
        "id": "XjmpH05aWe3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features_regr, response_regr = data_csv.drop('JP_Sales', axis=1),data_csv['JP_Sales']"
      ],
      "metadata": {
        "id": "zemhmMObWct4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part a Regression Part 2"
      ],
      "metadata": {
        "id": "jLANQFzryrJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 6.1.2\n",
        "\n",
        "from matplotlib.pyplot import figure, plot, xlabel, ylabel, legend, show, boxplot, semilogx, xscale\n",
        "from scipy.io import loadmat\n",
        "from sklearn import model_selection, tree\n",
        "import numpy as np\n",
        "\n",
        "X_lin_regr = features_regr.to_numpy()\n",
        "Y_lin_regr = response_regr.to_numpy()\n",
        "N, M = X_lin_regr.shape\n",
        "\n",
        "# store the predicted values in arrays\n",
        "lin_predictions_test = []\n",
        "ann_predictions_test = []\n",
        "baseline_reg_predictions_test = []\n",
        "test_reg_true_values = []\n",
        "\n",
        "# Add offset attribute\n",
        "X_lin_regr = np.concatenate((np.ones((X_lin_regr.shape[0],1)),X_lin_regr),1)\n",
        "M = M+1\n",
        "\n",
        "K = 10\n",
        "\n",
        "# Values of lambda\n",
        "lambdas = np.power(2.,range(-6,10))\n",
        "#lambdas = np.arange(1, 1000, 10)\n",
        "\n",
        "# Initialize variables\n",
        "#T = len(lambdas)\n",
        "w = np.empty((M,K))\n",
        "mu = np.empty((K, M-1))\n",
        "sigma = np.empty((K, M-1))\n",
        "w_noreg = np.empty((M,K))\n",
        "\n",
        "# K-fold crossvalidation\n",
        "K = 10\n",
        "CV = model_selection.KFold(n_splits=K,shuffle=False)\n",
        "\n",
        "# Initialize variable\n",
        "Error_train = np.empty((len(lambdas),K))\n",
        "Error_test = np.empty((len(lambdas),K))\n",
        "Error_train_base = np.empty((1,K))\n",
        "Error_test_base = np.empty((len(lambdas),K))\n",
        "\n",
        "k=0\n",
        "for train_index, test_index in CV.split(X_lin_regr):\n",
        "    # extract training and test set for current CV fold\n",
        "    X_train = X_lin_regr[train_index]\n",
        "    y_train = Y_lin_regr[train_index]\n",
        "    X_test = X_lin_regr[test_index]\n",
        "    y_test = Y_lin_regr[test_index] \n",
        "\n",
        "    # Standardize outer fold based on training set, and save the mean and standard\n",
        "    # deviations since they're part of the model (they would be needed for\n",
        "    # making new predictions) - for brevity we won't always store these in the scripts\n",
        "    mu[k, 1:7] = np.mean(X_train[:, 1:7], 0)\n",
        "    sigma[k, 1:7] = np.std(X_train[:, 1:7], 0)\n",
        "    \n",
        "    X_train[:, 1:7] = (X_train[:, 1:7] - mu[k, 1:7] ) / sigma[k, 1:7]\n",
        "    X_test[:, 1:7] = (X_test[:, 1:7] - mu[k, 1:7] ) / sigma[k, 1:7]\n",
        "    \n",
        "    Xty = X_train.T @ y_train\n",
        "    XtX = X_train.T @ X_train\n",
        "\n",
        "    for i, lambdaValue in enumerate(lambdas):   \n",
        "        # Estimate weights for the optimal value of lambda, on entire training set\n",
        "        lambdaI = lambdaValue * np.eye(M)\n",
        "        lambdaI[0,0] = 0 # Do no regularize the bias term\n",
        "        w[:,k] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
        "\n",
        "        if lambdaValue == 32 and k == K-1:\n",
        "          print(k)\n",
        "          print(\"coefficient values for lambda at 32\")\n",
        "          for m in range(M):\n",
        "              print('{:>15}'.format(np.round(w[m,-1],2)))\n",
        "        # Compute mean squared error with regularization with optimal lambda\n",
        "        Error_train[i,k] = np.square(y_train-X_train @ w[:,k]).sum(axis=0)/y_train.shape[0]\n",
        "        Error_test[i,k] = np.square(y_test-X_test @ w[:,k]).sum(axis=0)/y_test.shape[0]\n",
        "    k+=1\n",
        "\n",
        "# f = figure()\n",
        "# boxplot(Error_test.T)\n",
        "# xlabel('Model complexity (lambda)')\n",
        "# ylabel('Test error across CV folds, K={0})'.format(K))\n",
        "\n",
        "# f = figure()\n",
        "plot(lambdas, Error_train.mean(1))\n",
        "plot(lambdas, Error_test.mean(1))\n",
        "xscale('log', basex=2)\n",
        "xlabel('Lambda Value')\n",
        "ylabel('Error (misclassification rate, CV K={0})'.format(K))\n",
        "legend(['Error_train','Error_test'])\n",
        "\n",
        "print(lambdas)\n",
        "print(Error_test.mean(1))\n",
        "print(np.argmin(Error_test.mean(1)))\n",
        "    \n",
        "show()"
      ],
      "metadata": {
        "id": "w0SJsXI0yuY1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6a1d95a-89fe-4efc-fa19-0604e9bbd979"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "coefficient values for lambda at 32\n",
            "         114.19\n",
            "          -12.7\n",
            "           1.52\n",
            "           14.7\n",
            "            5.8\n",
            "           -4.1\n",
            "          12.41\n",
            "            0.0\n",
            "           17.2\n",
            "          -3.82\n",
            "            0.0\n",
            "           -6.6\n",
            "            0.0\n",
            "          -6.78\n",
            "           51.3\n",
            "          21.52\n",
            "          13.99\n",
            "          25.05\n",
            "          22.88\n",
            "          -1.89\n",
            "          16.96\n",
            "           12.2\n",
            "          -4.79\n",
            "         -13.41\n",
            "          -8.64\n",
            "           3.53\n",
            "         -19.55\n",
            "            3.6\n",
            "         -68.88\n",
            "          -29.5\n",
            "         -24.38\n",
            "          14.23\n",
            "           6.64\n",
            "           28.6\n",
            "           8.56\n",
            "         -19.99\n",
            "         -10.15\n",
            "         -39.49\n",
            "          56.96\n",
            "         -16.98\n",
            "          -0.28\n",
            "         -26.49\n",
            "          -1.61\n",
            "[1.5625e-02 3.1250e-02 6.2500e-02 1.2500e-01 2.5000e-01 5.0000e-01\n",
            " 1.0000e+00 2.0000e+00 4.0000e+00 8.0000e+00 1.6000e+01 3.2000e+01\n",
            " 6.4000e+01 1.2800e+02 2.5600e+02 5.1200e+02]\n",
            "[12947.29199613 12946.50793653 12944.9577591  12941.92485111\n",
            " 12936.1004399  12925.25587815 12906.0260576  12874.4308582\n",
            " 12828.20911801 12770.56627911 12712.28168842 12673.12378449\n",
            " 12686.06531313 12793.52427416 13020.08259924 13333.90181282]\n",
            "11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1fn48c+TBBIghH3fdwRkkcii1EJVoIqAiIr7VnH92dZWhdqqtepX1FLrUhVXUAuKCyIWFRXFWkESQJYIyCIY9oQtEAhZnt8fMyGXkNw7ubk39yZ53q/XvGbmzMydJwnkyZxz5hxRVYwxxphgxEQ6AGOMMZWXJRFjjDFBsyRijDEmaJZEjDHGBM2SiDHGmKBZEjHGGBO0uEgHUNEaN26s7du3j3QYxhhTqaSmpmaoapPi5dUuibRv356UlJRIh2GMMZWKiGwpqdyqs4wxxgTNkogxxpigWRIxxhgTtGrXJlKS3Nxc0tPTOXr0aKRDqXISEhJo3bo1NWrUiHQoxpgwsCQCpKenU7duXdq3b4+IRDqcKkNVyczMJD09nQ4dOkQ6HGNMGFh1FnD06FEaNWpkCSTERIRGjRrZE54xVZglEZclkPCw76sxUSAvB75/C8Iw9YclEWOMqerm3w3vT4T00L8jZ0kkSsTGxtK3b9/jy6OPPhr2ez755JNkZ2eX+br77ruPzz77LAwRGWNCLnU6pL4GQ34PbU4P+cdbw3qUqFWrFitWrPB7Tn5+PrGxsaXue72u0JNPPsmVV15J7dq1PV8D8OCDDwa8pzEmCqSnwn/+CB2Hwq/+EpZbWBIp5q8friFt+8GQfmaPlkncf0HPoK5t3749l156KQsWLODuu+9m0qRJJ+yrKo888giqyvnnn8+UKVMASExM5KabbuKzzz7j2WefZciQISd87lNPPcX27dsZNmwYjRs3ZuHChSdd88UXX/Dhhx9y5MgRzjjjDF544QVEhGuvvZZRo0Yxfvx42rdvzzXXXMOHH35Ibm4us2fPpnv37uX+nhljyunQHnj7KkhsDhe9AjGB/+AMhlVnRYkjR46cUJ311ltvHT/WqFEjli1bxoQJE07YP+uss7jnnnv44osvWLFiBUuXLmXOnDkAHD58mIEDB/L999+flEAA7rjjDlq2bMnChQtZuHBhidfcfvvtLF26lNWrV3PkyBHmzZtXYuyNGzdm2bJl3HLLLTzxxBOh/tYYY8oqPw/euQ6yM+HS16FOo7DdyvOTiIg0AFoCR4CfVLUgbFFFULBPDOXlrzrr0ksvLXF/6dKlDB06lCZNnIE1r7jiChYtWsTYsWOJjY3loosuKlMMxa9ZuHAhjz32GNnZ2ezdu5eePXtywQUXnHTduHHjAOjfvz/vvfdeme5pjAmDzx+An76Gsc9By75hvZXfJCIi9YDbgMuAmsAeIAFoJiKLgX+p6sKwRmioU6eO3/2SJCQkeGovKe2ao0ePcuutt5KSkkKbNm144IEHSn3fIz4+HnCSUF5eXpnuaYwJsdXvwf+ehtNvhL6Xh/12gaqz3gF+Bn6hqt1UdYiqJqtqG+BRYIyI3BD2KE2JBgwYwFdffUVGRgb5+fnMnDmTX/7yl56vr1u3LllZWSUeK0wYjRs35tChQ7zzzjshidkYE0a70uCD26HNQBjxSIXc0u+TiKqe6+dYKpAa8oiqqcI2kUIjR44M2M23RYsWPProowwbNux4w/qYMWM833PixImMHDnyeNuIr/r163PjjTfSq1cvmjdvzumnh75roDEmhI7sh7euhPhEuHg6xNWskNuKBniD0a3SGgm0cou2AZ+o6v4wxxYWycnJWnxSqh9++IFTTjklQhFVffb9NSbMCgpg1uWwYQFcMw/aDQ75LUQkVVWTi5f7rc4SkauBZcBQoLa7DANS3WPGGGMibdHjsH4+jPi/sCQQfwL1zroX6F/8qcPtqbUEmBGuwEzoXHjhhWzevPmEsilTpjBixIgIRWSMCZn1n8CX/we9J8CAGyv89oGSiAAl1XcVuMdMJfD+++9HOgRjTDhkboT3boTmvWDUPyACA54GSiIPA8tE5FOcXloAbYFzgb+FMzBjjDF+HDsMb10FEgOXvgE1Tx6+qCL4bRNR1elAMvAVkOMuXwLJqvpauIMzxhhTAlWYewfsToOLXoYG7SMWSsA31lV1HzCrAmIxxhjjxeLnYPU7cPZ90PnsiIYS9NhZIrIqlIEYY4zx4Kf/wqd/hu6jYMidkY4m4LAn40o7BDQPfTjVV2xsLKeeeurx/QkTJjBp0qSw3vPJJ59k4sSJJQ4FH8icOXPo2rUrPXr0CENkxpgSHdgGs6+Fhh2dcbGiYObQQNVZbwFvUnIPrYTQh1N9Rdt8IoHMmTOHUaNGWRIxpqLk5cDbV0PuEbj2I0hIinREQOAkshJ4QlVXFz8gIueEJ6QImz8Jdoa4pq75qfDr4GYqrMj5RD799FPuv/9+cnJy6NSpE6+++iqJiYlMmjSJuXPnEhcXx/Dhwxk3bhxz587lq6++4qGHHuLdd9+lU6dO5f42GWP8mH8PbEuBS16HJt0iHc1xgZLI74DSZmi6MMSxVGvFx86aPHny8SHfC+cPAZg0adLx/e3btzNo0CBSU1Np0KABw4cPZ86cOYwdO/b43CB///vfS7zfHXfcwdSpU1m4cCGNGzcmIyODhx56iM8++4w6deowZcoUpk6dym233cb777/P2rVrERH2799P/fr1GT169PGJqYwxYbZsBqS+6kxx22N0pKM5QaABGL/2cyz0M75HgyCfGMor0vOJLF68mLS0NM4880wAjh07xuDBg6lXrx4JCQnccMMNjBo1ilGjRgXz5RljgrUtFT76I3QcFrYpbsvDc+8sEbnSd20qTkXMJ6KqnHvuuaxYsYIVK1aQlpbGyy+/TFxcHN999x3jx49n3rx5jBw5sszxG2OCdDgD3roaEpvB+PBNcVseZenie2extYmwUM4nMmjQIL755hs2bNgAOFPlrl+/nkOHDnHgwAHOO+88/vGPf/D999+fdK0xJgyOT3Gb4UxxW7thpCMqUTDviXjuUyYir4jIbhFZ7VP2NxFZKSIrRORTEWnplouIPCUiG9zjp/lcc42I/Ogu1/iU9xeRVe41T4lEQX+3IBWfY91L917f+UT69OlD//79g5pPZNiwYTRp0oTXXnuNyy67jN69ezN48GDWrl1LVlYWo0aNonfv3gwZMoSpU6cCThfkxx9/nH79+rFx48agv25jTCk+fwA2L3LGxArzFLfloqqeFmCZu15ehmvOAk4DVvuUJfls3wE8726fB8zHSVKDgCVueUNgk7tu4G43cI99554r7rW/DhRT//79tbi0tLSTykzo2PfXmDL6/i3V+5NU5/0h0pEcB6RoCb9Tg35j3WOCWgTsLVbm29urDkXvoIwBZrjxLgbqi0gLYASwQFX3qjMEywJgpHssSVUXu1/gDGBsOL8eY4wJu5RX4f2boN2QCpvitjwCjp0VDiLyMHA1cABnkitwZk782ee0dLfMX3l6CeWmGJtPxJhKQBW+fgK+eAi6jICLX6uwKW7LoyxJZL27Xlfem6rqvcC9IjIZuB24v7yf6Y+ITAQmArRt27a0mKjETSp+RXI+EQ0w/bIxBmd6208mw5LnncmlxjwDsTUiHZUnnquzVHWC79qd3bC83gQKX2bYBrTxOdbaLfNX3rqE8pJin6aqyaqaXPhOha+EhAQyMzPtF16IqSqZmZkkJNgIOcaUKu+YM7HUkudh8O3OmFiVJIFA4AEYX1LV35RQ3ganIbtXWW8oIl1U9Ud3dwyw1t2eC9wuIrOAgcABVd0hIp8Aj/gkreHAZFXdKyIHRWQQzlS9VwNPlzUegNatW5Oens6ePXuCudz4kZCQQOvWrQOfaEx1VDix1MbP4ZwH4MzfRcWgimURqDorTkTeAK5W1QIAEekBzAMeDPThIjITGAo0FpF0nGqr80SkG84Uu1uAm93T/4PTQ2sDkA1cB+Ami78BS93zHlTVwsb6W4HXgFo4SW1+oJhKUqNGDTp06OD/pG/+6Y6pJT4/5MJtnzWFq+JlJZ0X4+xLjHuscL+kMt99n/NOKot1XkiSWIiJcddxPmWxzrnH9+NKKHPLJRZi4yC2prvUOHk7poZzH2NM2WTvhTcvhu3LYPTTcNrVkY4oKOKvCsd97+IFnK61E3CeEN4CblHVeRUSYYglJydrSkoQI7Z8cLszjn9hZzJVZ1tx14XfR/U5Fqis4MRydcuOHys4uSwaxcSVnmRO2q7pTONZMxFq1Ha2a9Rxy+oUbdeo4+yXdDw2Iv1BjAmdA+nw+jjY95PzJvop0T+ckIikqmpy8fJAY2cpMFFEnsKZFrcdcLHbBbd6GfNMpCNwlJhsfJNOPhTkO9sF+UX7BXknl6lbXlBQrKzYdfnHID/XXZd1u1jZkX1wcBscy4bcw84670jZvgexNd0EVMdJRrUaQO1Gzhu9tRuVsDR0lvh69tRkIm/POnj9QsjJgqveg/ZDAl8TxQK1iTyN87e2AD2AZcDlInI5gKreEfYIzYmOV2NVoV+GBfmQm31iYsnNhmOHfLYPF62Pb2fDsSwnMe3f4lQLZGc6CaskElss0fhs1/LZTmoJDdpBfN2K/T6Yqi89Bd4c71QDX/sRtOgd6YjKLVC9QEop28aETkys8ws7FL+0VZ3kk53pLnuLrX3KMzZA9hJnX/NP/qxaDaB+O6jf1kkq9d2lgVtWo1b54zXVx4bPnEb0xKZw1fvO7IRVQKDqrOkVFYgxISFSlJAatPd2jSocPVCUXA78DPu3Ok83+7bA7h9g/SeQn3PidXWaFiUU3+RSvx3Ua1MpXhQzFWTVO/D+zdCkO1z5LtRtFumIQsZaKI0RgVr1naVRJ2hz+snnFBTA4d1OUtm/pSjB7N/izPeQ9oHTflT0oU61WP120KgjNO/tzHDZrCck1KuwL81EgSUvOLMStjsDLptZ5X7+lkSM8SImBuo2d5a2A08+np8HWdudJ5h9W058klk3H5a/UXRu/XZOQmneG5r3crbrtal07weYAFRh4SOw6DHoPgouehlqVL0XbwM1rJ+uqkv9nWOMwel2XL+tsxTvbaMKWTud94x2roRdq53ttR9xvMt4Qj0nqTRzk0rzU52qD6sSq5wK8uGjPzhT2va7CkY9WWW7pgf6qqaJSCIwC5ipqmkVEJMxVYsIJLVwlq7Di8pzDsHuNDe5uEvqa0VdnmNqOImkuU9iadYraicnMq68HHj3N/DDXBhyJ5x9X5V+ygzUsN7Pfbt8AvCOiOQCM4FZqvpTBcRnTNUVnwhtBjhLoYJ82LvJeWIpTCwbF8L3M4vOqdfWuabtIGdp2iMqp02tlo4ehLeucCaTGvEIDL4t0hGFnd831k86WaQPTkK5BNipqmeGK7BwCfqNdWMi6dBuJ6HsWg3bl8PWxZC1wzkWnwStTy9KKq36Oy9imop1aA+8eRHsWgNj/gV9Lo10RCEV1BvrxT4gBmgKNMOZTGp36MIzxviV2BQ6n+0s4LSz7N/qJJOfFzvrhY8A6gxD07w3tB3sdAJoM6hKdSmNSvt+ct5CP7gDJsw8sdqyigv4JCIivwAuw5k1cBVO+8h7qnog/OGFnj2JmCrryD74eWlRUtmWCnlHnWMNOzrJpPBppXHXKl1PX2H2bYHvpsGy151xPS6fXXLvvSogqCcREfkZZ6TdWcADqmpPH8ZEq1oNnL+AC/8KzjsGO76Hrd/Cz0vgx0/g+3+75zaENgPdpDIYWvaFuPjIxV6ZqMKWb2Dxc7DuP4BAj9Ew9E/QpGuko6twgaqzhgOZxZOHiDQBslT1aNgiM8aUT1xN58XJwpcnVSFzo5NUCqvB1ruzJ8TGO20phUmlzQDn5UtTJPcorH4HFj8Pu1Y5SfvM38Lpv4F61XfOnEBDwU8DPlbV94qVXwgMV9VbwhxfyFl1ljE+Du0pqv7a+q3z5FKQB4jzdn1hUmk7qPr+ojy4A1JehpRXITsDmpwCg26GUy9xpiioJkqrzgqURFJVtX8px9aoas8QxlghLIkY48exw05bSmFS+fk7Z0BLcLoWF7aptB3svMNSlYfWT0+FJc/BmvedrtddRzrJo8Mvq2V7UrC9s/yl2Sr8r8eYaqpmHehwlrOAM5zLrtVFSWXzV7DqbedYQv0Tk0rLfpW/XSU/1xkHbcnzkL4UataF02+EATc646qZkwRKIrtFZICqfudbKCKnAzYhuTFVXWyc0+jesq/zV7gq7NtclFS2Lob1H7vnxkOr05yk0rIfNO7m9AqrDEO3HM50hihZ+rIzBlqDDjByCvS9HBKSIh1dVAuURO4C3haR14BUtywZuBrnpUNjTHUi4iSGhh2dX7AAhzNOTCr/e7poRGOJhYYdnITSuAs06eZ0L27cJTpGs921xulltWq20x2641AY9Q/oMrxqV9WFUKBhT74TkQHAbcC1bvEaYKB19zXGAFCnsTNHeOE84ceyIWMdZPzoTAWbsd5ZfvwUCnKLrktsXiyxuEtSy9C2Oag6M2HmZDnjlR3Lcl4OXPoy/PQ1xCVA70th4M3QrEfo7ltNlGnYk6rAGtaNiZD8PGd4fN/EkrEe9qyHHJ93l2smOsnF9+mlbgun0T8ny2noz8kqtu0mh8Lt48fcci04OZ6kVk5bx2nX2KCWHpR72BNjjCmX2DincbpRJ+C8onJVZ2ywjHVFSSVjvfOUsHKW/88Un6mVayY664Qk52kmPskZ5LKwPD7RaSiPr+u849E6GWJrhPVLrg4siRhjIkvEGdurbrOiXmGFcrIgc4OTZGrW8UkWboKIS6iW3W2jiSURY0z0iq/r9PQyUSuoJCIijwAHgJdUNTO0IRljjKksgu3D9h2QB/wjhLEYY4ypZIJ6ElHVOaEOxBhjTOXj6UlERLqKyOcistrd7y0ifw5vaMYYY6Kd1+qsF4HJQC6Aqq7E3lg3xphqz2sSqV18/CycNhFjjDHVmNckkiEinQAFEJHxwI6wRWWMMaZS8NqwfhswDeguItuAzcAVYYvKGGNMpeD1SURV9RygCdBdVYcEulZEXhGR3YWN8W7Z4yKyVkRWisj7IlLfLW8vIkdEZIW7PO9zTX8RWSUiG0TkKRHn9VQRaSgiC0TkR3fdoKxfvDHGmPLxmkTeBVDVw6qa5Za9E+Ca14CRxcoWAL1UtTewHqexvtBGVe3rLjf7lD8H3Ah0cZfCz5wEfK6qXYDP3X1jjDEVyG91loh0B3oC9URknM+hJCDB37WqukhE2hcr+9RndzEwPsD9WwBJqrrY3Z8BjAXmA2OAoe6p04EvgXv8fZ4xxpjQCtQm0g0YBdQHLvApz8J5OiiP64G3fPY7iMhy4CDwZ1X9GmgFpPuck+6WATRT1cLG/Z1As3LGY4wxpowCTUr1AfCBiAxW1W9DdVMRuReni/CbbtEOoK2qZopIf2COiPT0+nmqqiJS6sQoIjIRmAjQtm3b4AM3xhhzAq+9s5aLyG04VVvHq7FU9fqy3lBErsV5ujlb3RmxVDUHyHG3U0VkI9AV2Aa09rm8tVsGsEtEWqjqDrfaq9SZFlV1Gk7vMpKTk6vXLFzGGBNGXhvWXweaAyOAr3B+mWf5vaIEIjISuBsYrarZPuVNRCTW3e6I04C+ya2uOigig9xeWVcDH7iXzQWucbev8Sk3xhhTQbwmkc6q+hfgsKpOB84HBvq7QERmAt8C3UQkXURuAJ4B6gILinXlPQtYKSIrcHp93ayqe91jtwIvARuAjTiN6gCPAueKyI/AOe6+McaYCuS1OivXXe8XkV44DdlN/V2gqpeVUPxyKee+i9uNuIRjKUCvEsozgbP9xWCMMSa8vCaRae7LfH/GqUZKBP4StqiMMcZUCgGTiIjEAAdVdR+wCOgY9qiMMcZUCgHbRFS1AKcx3BhjjDmB14b1z0TkjyLSxh2zqqGINAxrZMYYY6Ke1zaRS931bT5lilVtGWNMteYpiahqh3AHYowxpvLxWp1ljDHGnMSSiDHGmKBZEjHGGBM0rw3riEgroJ3vNaq6KBxBGWOMqRw8JRERmYLTQysNyHeLFeflQ2OMMdWU1yeRsUA3d8h2Y4wxlUxefgFxsaFvwfD6iZuAGiG/uzHGmLBL3bKXs6d+xbqdZZ7BIyCvTyLZwAoR+Rx38igAVb0j5BEZY4wJmfwC5b4P1pCTW0DrBrVC/vlek8hcdzHGGFOJzPxuK2u2H+Tpy/pRJ95zXyrPvL6xPl1EauJMWQuwTlVz/V1jjDEmsvYdPsYTn65jUMeGjOrdIiz38No7aygwHfgJEKCNiFxjXXyNMSZ6Pf7pOrKO5vHX0b1wZhgPPa/PNn8HhqvqOgAR6QrMBPqHJSpjjDHlsir9ADO/28p1Z3SgW/O6YbuP195ZNQoTCICqrsd6axljTFQqKFDum7uaRnVq8rtzu4T1Xl6fRFJE5CXgDXf/CiAlPCEZY4wpj3eXpbN8636euLgPSQnh/XvfaxK5BWcukcIuvV8D/wpLRMYYY4J24EguUz5ey2lt6zOuX6uw389r76wcYKq7GGOMiVJPfraezMPHeO26AcTEhKcx3ZffJCIib6vqJSKyCmesrBOoau+wRWaMMaZM1u48yIxvt3D5gLb0alWvQu4Z6Enkt+56VLgDMcYYEzxV5f4P1lA3IY4/Du9WYff12ztLVXe4m7eq6hbfBbg1/OEZY4zx4sOVO1iyeS93jehGgzo1K+y+Xrv4nltC2a9DGYgxxpjgHM7J4+GP0ujVKokJp7et0HsHahO5BeeJo6OIrPQ5VBf4JpyBGWOM8ebpLzaw62AO/7qiP7EV0JjuK1CbyL+B+cD/AZN8yrNUdW/YojLGGOPJxj2HePm/mxjfvzX92zWo8Pv7TSKqegA4AFwGICJNgQQgUUQSVXVr+EM0xhhTElXlgblrSIiL5Z6R3SMSg6c2ERG5QER+BDYDX+EMxDg/jHEZY4wJ4NO0XXz9Ywa/P7crTerGRyQGrw3rDwGDgPWq2gE4G1gctqiMMcb4dTQ3nwc/TKNbs7pcPbhdxOLwmkRyVTUTiBGRGFVdCCSHMS5jjDF+PPflRrbtP8IDo3uGZe50r7zeeb+IJAKLgDdF5J/AYX8XiMgrIrJbRFb7lD0uImtFZKWIvC8i9X2OTRaRDSKyTkRG+JSPdMs2iMgkn/IOIrLELX/LnTTLGGOqvK2Z2Tz31UYu6NOSwZ0aRTQWr0lkDM48678HPgY2AhcEuOY1YGSxsgVAL3e4lPXAZAAR6QFMAHq61/xLRGJFJBZ4FuedlB7AZe65AFOAf6hqZ2AfcIPHr8UYYyq1v32URlyM8KfzItOY7strEmkK1FTVPFWdDryI865IqdxZD/cWK/tUVfPc3cVAa3d7DDBLVXNUdTOwARjgLhtUdZOqHgNmAWPEmaLrV8A77vXTgbEevxZjjKm0Fq7bzYK0Xfy/X3WhRb1akQ7HcxKZDRT47Oe7ZeVxPUU9vFoBP/scS3fLSitvBOz3SUiF5cYYU2Xl5DmN6R0b1+H6Ie0jHQ7gPYnEuU8CALjbQbdBiMi9QB7wZrCfUcb7TRSRFBFJ2bNnT0Xc0hhjQu7l/25mc8Zh7h/dk/i42EiHA3hPIntEZHThjoiMATKCuaGIXIszKvAVqlo4vPw2oI3Paa3dstLKM4H6IhJXrLxEqjpNVZNVNblJkybBhG2MMRG148ARnv58A8N7NOOXXaPn95jXJHIz8CcR2SoiPwP3ADeV9WYiMhK4Gxitqtk+h+YCE0QkXkQ6AF2A74ClQBe3J1ZNnMb3uW7yWQiMd6+/BvigrPEYY0xl8fBHP1Cgyl9G9Qh8cgXyOrPhRmCQ280XVT0U6BoRmQkMBRqLSDpwP05vrHhggdM2zmJVvVlV14jI20AaTjXXbaqa737O7cAnQCzwiqqucW9xDzBLRB4ClgMve/uSjTGmcvnfxgzmrdzB787pQpuGtSMdzgmkqEaphIMiV6rqGyJyZ0nHVbXSTZebnJysKSkpkQ7DGGM8yc0v4Pynvib7WD6f3flLEmpEpi1ERFJV9aSXzAM9iRSmPL/deY0xxoTHjG+3sH7XIaZd1T9iCcSfQEmkk7tOU9Xyduk1xhhTBruzjvLkgvX8smsTzu3RLNLhlChQw/p57ot9kysiGGOMMUWmzF/H0bx87r+gB247ctQJ9CTyMc6QIokictCnXABV1aSwRWaMMdVY6pa9vLssnVuGdqJjk8RIh1Mqv08iqnqXqtYHPlLVJJ+lriUQY4wJj/wC5b4P1tA8KYHbh3WOdDh+eXpPRFXHhDsQY4wxjn9/t5U12w9y7/mnUCfe05sYEeM3iYjIf911logcdNeFy0F/1xpjjCm7rZnZPPqfHzizcyNG9W4R6XACCjTH+hB3bV18jTEmzPILlDvfXkGMCI+N7xO1jem+vM6x3klE4t3toSJyh++EUsYYY8pv2qJNpGzZx1/H9KRV/cgP8+6F17Gz3gXyRaQzMA1nUMR/hy0qY4ypZtK2H2TqgnWcd2pzLuxXeWa28JpECty5Oy4EnlbVu4Dor6wzxphK4GhuPr9/awX1a9fk4bGnVopqrEJek0iuiFyGM1ruPLesRnhCMsaY6mXqgvWs25XFY+N706BO0FM1RYTXJHIdMBh4WFU3u8O1vx6+sIwxpnpYvCmTF7/exOUD2zKsW9NIh1NmXoeCTwPuABCRBkBdVZ0SzsCMMaaqyzqayx/e/p62DWtz73mnRDqcoHjtnfWliCSJSENgGfCiiFS6YeCNMSaaPPhhGjsOHGHqJX2j/qXC0nitzqqnqgeBccAMVR0InBO+sIwxpmr7ZM1OZqemc+vQzvRv1yDS4QTNaxKJE5EWwCUUNawbY4wJwp6sHCa/t4qeLZO44+wukQ6nXLwmkQdxpqjdoKpLRaQj8GP4wjLGmKpJVZn83koO5eTx5KV9qRnn9ddwdPLasD4bmO2zvwm4KFxBGWNMVfV2ys989sNu/nz+KXRpVvlHlPKUREQkAbgB6AkkFJar6vVhissYY6qcrZnZPPhhGoM7NuL6MztEOpyQ8Poc9TrQHBgBfAW0BrLCFZQxxlQ1+QXKH2Y7gys+cXfPEWwAABPsSURBVEkfYmIqz1vp/nhNIp1V9S/AYVWdDpwPDAxfWMYYU7VMW7SJpT9VrsEVvfA87Im73i8ivYB6QOV7tdIYYyKgcHDFX/eqXIMreuH17ZZp7pvqfwHmAonAfWGLyhhjqoicvHzufHsF9WrV5OELK9fgil547Z31krv5FdAxfOEYY0zVMvXT9azdmcUr1ybTsJINruiF3yQiInf6O66qNvSJMcaUYsmmTKa5gyv+qnuzSIcTFoGeRCp/J2ZjjImArKO53FnJB1f0ItAc63+tqECMMaYqKRxccfbNZ1TawRW98DqK73TfOdVFpIGIvBK+sIwxpvL61B1c8ZahnSr14IpeeO3i21tV9xfuqOo+oF94QjLGmMor41DR4Iq/PbtrpMMJO6/PWDEi0sBNHrjzilTd5zNjjAmCqjLp3VVk5eQxswoMruiF10Twd+BbEZkNCDAeeDhsURljTCXkDK64iz+ffwpdq8Dgil54SpOqOgNnQqpdwE5gnKr6nWNdRF4Rkd0istqn7GIRWSMiBSKS7FPeXkSOiMgKd3ne51h/EVklIhtE5Clx39QRkYYiskBEfnTXVbvi0RgT1ari4IpeeG1Y7wRsVNVngNXAOb4N7aV4DRhZrGw1TjJaVML5G1W1r7vc7FP+HHAj0MVdCj9zEvC5qnYBPnf3jTGmwlXVwRW98Fph9y6QLyKdgReANsC//V2gqouAvcXKflDVdV6Dc2dTTFLVxaqqwAxgrHt4DDDd3Z7uU26MMRXqxa+dwRUfGF21Blf0wmsSKVDVPJyniGdU9S6gRYhj6SAiy0XkKxH5hVvWCkj3OSfdLQNopqo73O2dQNV8HdQYE9U+Xr2Dxz9xBlccd1rVGlzRC68N67kichlwNXCBW1YjhHHsANqqaqaI9AfmiEhPrxerqoqIlnZcRCYCEwHatm1b7mCNMQZg4drd/L+Zy+nTuh5PXNynyg2u6IXXJ5HrgMHAw6q6WUQ64ExUFRKqmqOqme52KrAR6Apsw5kAq1Brtwxgl1vdVVjttdvP509T1WRVTW7SpEmowjbGVGP/25DBTW+k0q15XV69bkCVfivdH6+9s9JU9Q5Vnenub1bVKaEKQkSaiEisu90RpwF9k1tddVBEBrm9sq4GPnAvmwtc425f41NujDFhlfLTXn4zI4X2jWoz4/qB1KsVyoqZyiXQKL5vq+olIrIK8K0uEpxapN5+rp0JDAUai0g6cD9OQ/vTQBPgIxFZoaojgLOAB0UkFygAblbVwkb5W3F6etUC5rsLwKPA2yJyA7AFuMTzV22MMUFamb6f615dSrOkBN74zcAqObx7WYjT6amUgyItVHWHiLQr6biqbglbZGGSnJysKSkpkQ7DGFMJrd15kAnTFlOnZhyzbx5My2rUE0tEUlU1uXh5oFF8d7jrLe6HJAW6xhhjqqKNew5x5UtLiI+LYeaNg6pVAvHHU0IQkZuAvwJHKarWUmyWQ2NMNfDz3myueHEJqvDmbwbRtlHtSIcUNbw+VfwR6KWqGeEMxhhjos2OA0e4/KXFHMnNZ9bEQXRumhjpkKKK1y6+G4HscAZijDHRZk9WDle8uIR9h3OZcf0ATmmRFOmQoo7XJ5HJwP9EZAmQU1ioqneEJSpjjImwfYePcdXLS9hx4CgzbhhAnzaBhgusnrwmkReAL4BVOF1wjTGmyjp4NJerX/mOTRmHefXa0zm9fcNIhxS1vCaRGqp6Z1gjMcaYKHA4J4/rXl3K2p0HeeGq/pzZuXGkQ4pqXttE5ovIRBFp4c7j0dCd3dAYY6qMo7n53DgjheVb9/HPCf34VXcb1zUQr08il7nryT5l1sXXGFNlHMsr4JY3Uvl2UyZTL+nDeaeGeqDyqslTElHV6jNNlzGm2snLL+C3s5azcN0eHrnwVC7s1zrwRQYIUJ0lIkMCHE8SkV6hDckYYypOfoHyx9nfM3/1Tv4yqgeXD7TpIsoi0JPIRSLyGPAxkArsARKAzsAwoB3wh7BGaIwxYaKq/HnOKuas2M5dI7pxwxCrdCmrQGNn/d5tQL8IuBhnNsMjwA/AC6r63/CHaIwxoaeqPDgvjZnf/cztwzpz27DOkQ6pUgrYJuIOyf6iuxhjTJXwxKfrePWbn7j+zA78YXjXSIdTaXnt4muMMVXGM1/8yLMLN3L5wLb8ZdQp1XJa21CxYd2NMdXGnqwcHvhwDR+t3MG4fq14aEwvSyDlFDCJiEgMMEhV/1cB8RhjTMipKu8u28bf5qVx5Fg+d57blVuHdiImxhJIeXlpEykQkWeBfhUQjzHGhNTPe7P50/ur+PrHDJLbNeDRi06lc9O6kQ6ryvBanfW5iFwEvKf+5tM1xpgokV+gvPrNZv7+6XpiBB4c05MrB7azp48Q85pEbgLuBPJF5AgggKqqDa5vjIk6a3ce5J53V/H9z/v5VfemPDS2l01nGyZehz2xZz9jTNTLycvnmS828NyXG0mqVYN/TujL6D4trfE8jDz3zhKR0cBZ7u6XqjovPCEZY0zZpfy0l3veXcnGPYcZ168Vfx7Vg4Z1akY6rCrPUxIRkUeB04E33aLfisiZqjrZz2XGGBN2WUdzeezjdby+eAut6tfitetOZ2i3ppEOq9rw+iRyHtBXVQsARGQ6sJwTh4Y3xpgK9cXaXdz7/mp2HjzKtWe0564R3agTb6+/VaSyfLfrA3vd7XphiMUYYzzJPJTDXz9MY+732+naLJFnrziD09o2iHRY1ZLXJPIIsFxEFuL0zDoLmBS2qIwxpgSqyvvLnZcGD+Xk8btzunDr0M7UjLMRnCLF6xvrBcAgnHYRgHtUdWc4AzPGGF/p+7L50/urWbR+D6e1rc+Ui3rTpZl1HI00r2+s362qbwNzKyAmY4w5Lr9AmfHtTzz+yToAHrigB1cNbk+svTQYFbxWZ30mIn8E3gIOFxa6w8QbY0xIqSprth9kzvJtfLhyO7sO5jC0WxMevvBUWtlLg1HFaxK51F3f5lOmQMfQhmOMqc62ZB7mgxXb+WDFNjbuOUyNWOGXXZvy4JjWDO/RzF4ajEJe20QmqepbFRCPMaaayTiUw7zvt/PB99tZvnU/AAM6NOSGIR0579Tm1K9tLwxGM69tInfhVGUZY0y5Hc7J49O0ncxZvp3/bsggv0Dp3rwu94zszui+La3KqhIJW5uIiLwCjAJ2q2ovt+xi4AHgFGCAqqb4nD8ZuAHIB+5Q1U/c8pHAP4FY4CVVfdQt7wDMAhoBqcBVqnrM49djjKlgufkFLFq/hzkrtrMgbSdHcwtoVb8WE8/qyNi+rejW3HpaVUbhbBN5DXgGmOFTthoYB7zge6KI9AAmAD2BljhJq3DS42eBc4F0YKmIzFXVNGAK8A9VnSUiz+MkoOc8fj3GmApQUKCkbt3HnOXb+M+qHezLzqV+7RqMO601Y/u2IrldAxuavZLzOopvh7J+sKouEpH2xcp+AEpqHBsDzFLVHGCziGwABrjHNqjqJve6WcAYEfkB+BVwuXvOdJwnHEsixkSB9buymLN8Gx+s2M62/UdIqBHDOac0Y2zfVpzVtYm9HFiF+E0i7vshj7nbF6vqbJ9jj6jqn0IURytgsc9+ulsG8HOx8oE4VVj7VTWvhPONMRWkoEDZujebtTsP8sOOrOPrrXuziREY0qUJfxjeleE9m5NoY1pVSYF+qhOAx9ztycBsn2MjgVAlkbASkYnARIC2bdtGOBpjKqf92cdYuzOLtTsOOuudWazbmcWR3HwARKBDozr0apXEdWe2Z1TvljSpGx/hqE24BUoiUsp2SfvlsQ1o47Pf2i2jlPJMoL6IxLlPI77nn0RVpwHTAJKTk216X2P8yM0vYHPGYX4oTBbueseBo8fPqV+7Bt2b1+XS09twSou6dG+eRNdmdalVMzaCkZtICJREtJTtkvbLYy7wbxGZitOw3gX4DidRdXF7Ym3DeTK6XFXVHQxyPE4PrWuAD0IYjzFV2tHcfDIPH2PvoWNkHMrhx91ZbsLIYsPuQxzLLwAgLkbo3DSRgR0a0r1FEt2b1+WUFkk0rRtvL/4ZIHAS6SMiB3F+mddyt3H3E/xdKCIzgaFAYxFJB+7HGUr+aaAJ8JGIrFDVEaq6RkTeBtKAPOA2Vc13P+d24BOcLr6vqOoa9xb3ALNE5CGcuU1eLsPXbUyVoaocPpbP3kPHyDycw97Dx5wE4S6Zh46xt1h59rH8kz6nWVI83Zsn8Yuujene3Hm66NQk0RrBjV+iWr1qd5KTkzUlJSXwicaEUF5+ATl5znI0N9/dzudobgE57n5ReQnn5OWT466zj+UfTw77sp3EcCyvoMT7xsfF0KhOTRom1qRhnXhn210a1alJgzo1aZxYkw6NE20qWeOXiKSqanLxcusu4dGLizbxw46DgU+MoFD/ORCOPzBOqhPVQMfV73EUFEXV+azj2yd8tm+ZHj9WuA8nXlugSkEB5KuSX6AUHF87vZHyVY+v8wt8t/E5t6g8L1/JKyjf9zI+Lob4uBgSasRSq2YsDWrXpEW9BHq2TKJhopsQatekUbFkUbtmrFU7mbCyJOLRj7uzWLol+gctlpD2d3B63ITaST00it3kpFuK311EnK9axPn6Cz+usJzCYz7HxS0suq7o/BgRYmKgRkwMMSLExgixIsTECDECsTFyUvnxdQzEiiCFx2OEuBghoUbs8STgu46vEUNCXCzxNWKIj4slwV07x2KPJw9LBCZaWRLx6LHxfSIdgjHGRB1rMTPGGBM0SyLGGGOCZknEGGNM0CyJGGOMCZolEWOMMUGzJGKMMSZolkSMMcYEzZKIMcaYoFW7sbNEZA+wJdJxuBoDGZEOIoBojzHa4wOLMRSiPT6I/hjLG187VW1SvLDaJZFoIiIpJQ1oFk2iPcZojw8sxlCI9vgg+mMMV3xWnWWMMSZolkSMMcYEzZJIZE2LdAAeRHuM0R4fWIyhEO3xQfTHGJb4rE3EGGNM0OxJxBhjTNAsiRhjjAmaJRFjjDFBsyQSRURkqIh8LSLPi8jQSMdTEhE5xY3vHRG5JdLxFCciHUXkZRF5J9Kx+IrWuApF+88VKs3/j1+48b0kIv+LdDzFiUgPEXlbRJ4TkfGh+ExLImEkIm1EZKGIpInIGhH5bYBLFDgEJADp4Y+w7DGq6g+qejNwCXBmFMa3SVVvCHdcpSkt3kjH5SG+Cv25BhMjEfj/URo/38ev3e/jPGB6tMUH/Bp4WlVvAa4Oyc1U1ZYwLUAL4DR3uy6wHugBnIrzj8x3aQrEuOc2A96Mxhjd80YD84HLozE+99x3oulnHum4vMRXkT/XIH/mFf7/oxw/57eButEWn/t75lngceCbUNwrzm+GMeWiqjuAHe52loj8ALRS1QXAKD+X7gPiKyDEoGJU1bnAXBH5CPh3tMUXSaXFC6RFNDCXv/gq8ucaTIyqWvg9rLD/H6Xx930UkbbAAVXNirb43O/hbSISC7wXintZEqkgItIe6Acs8XPOOGAEUB94pkICO/H+7Qkc41BgHM5/4v9URFw+925P4PgaAQ8D/URksqr+X8VEV2Is7XHjjaa4ChWLbygR+rn6UyzGiP7/KE0J/y5vAF6NVDzFFfsetgf+BNTBeRopv0g+ElaXBUgEUoFxkY6lssYY7fFVtnijPT6LsfLEZw3rYSYiNYB3cepwQ/L4GGrRHmO0x1dctMcb7fGBxRgKFRWfDXsSRiIiOD009qrq7yIdT0miPcZoj6+4aI832uMDizEUKjI+SyJhJCJDgK+BVUCBW/wnVY2mOueojjHa4ysu2uON9vjAYgyFiozPkogxxpigWZuIMcaYoFkSMcYYEzRLIsYYY4JmScQYY0zQLIkYY4wJmiURY4wxQbMkYqo9ETkUhs/8SUQah/LeIvKqiNxUrGysiMz3c81roZo3wpiSWBIxpvKYCUwoVjbBLTcmIiyJGFMCEblARJaIyHIR+UxEmrnlD4jIdHFm2NsiIuNE5DERWSUiH7vjFRW62y3/TkQ6u9d3EJFv3fKHfO6XKCKfi8gy99iYEsL6HOguIi3ca+oA5wBzROQ+EVkqIqtFZJo77EXxr+n405GIJIvIl4WfIyKvuHEuL+XexpTIkogxJfsvMEhV+wGzgLt9jnUCfoUzidMbwEJVPRU4Apzvc94Bt/wZ4Em37J/Ac275Dp9zjwIXquppwDDg78UTgarm4wyod4lbdAHwpaoeBJ5R1dNVtRdQi7LNtXIv8IWqDnDv/biboIwJyJKIMSVrDXwiIquAu4CePsfmq2ouzrhEscDHbvkqoL3PeTN91oPd7TN9yl/3OVeAR0RkJfAZzgRHzUqIy7dKy7cqa5j75LQKJ8H1LOHa0gwHJonICuBLnOln25bhelON2aRUxpTsaWCqqs51J2x6wOdYDoCqFohIrhYNQFfAif+n1MN2oSuAJkB/Vc0VkZ9wfpkX9z+ghYj0Ac4AJohIAvAvIFlVfxaRB0q5No+iPxx9jwtwkaquK+EaY/yyJxFjSlYP2OZuXxPkZ1zqs/7W3f6GoieJK4rdb7ebQIYB7Ur6QDdhvYUzzPd8VT1KUULIEJFEoLTeWD8B/d3ti3zKPwH+X2H1mYj0C/ylGeOwJGIM1BaRdJ/lTpwnj9kikgpkBPm5Ddzqqd8Cv3fLfoszx/UqnCqrQm8CyW751cBaP587E+jjrlHV/cCLwGqchLC0lOv+CvxTRFKAfJ/yvwE1gJUissbdN8YTGwreGGNM0OxJxBhjTNAsiRhjjAmaJRFjjDFBsyRijDEmaJZEjDHGBM2SiDHGmKBZEjHGGBM0SyLGGGOC9v8BG5Uj3/hleLMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Linear Regression"
      ],
      "metadata": {
        "id": "ibr_eAlwyvuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.linear_model as lm\n",
        "# Fit ordinary least squares regression model\n",
        "model = lm.LinearRegression(fit_intercept=False)\n",
        "model = model.fit(X_lin_regr,Y_lin_regr)\n",
        "# Compute model output:\n",
        "y_est = model.predict(X_lin_regr)\n",
        "# Plot original data and the model output\n",
        "f = figure()\n",
        "\n",
        "plot(Y_lin_regr,y_est,'.')\n",
        "xlabel('true'); ylabel('estimated')\n",
        "legend(['Training data', 'Data generator', 'Regression fit (model)'])\n",
        "\n",
        "show()"
      ],
      "metadata": {
        "id": "It8pJf-Dyxj2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2f1598bc-35fa-4d86-dbec-fcdd591b0715"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression b part 1"
      ],
      "metadata": {
        "id": "LdbjQ3nFyypn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exercise 8.1.1\n",
        "\n",
        "from matplotlib.pylab import (figure, semilogx, loglog, xlabel, ylabel, legend, \n",
        "                           title, subplot, show, grid)\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import sklearn.linear_model as lm\n",
        "from sklearn import model_selection\n",
        "from toolbox_02450 import rlr_validate\n",
        "\n",
        "def linear_regression_validate(X,y,lambdas,cvf=10):\n",
        "    CV = model_selection.KFold(cvf, shuffle=False)\n",
        "    M = X.shape[1]\n",
        "    w = np.empty((M,cvf,len(lambdas)))\n",
        "    train_error = np.empty((cvf,len(lambdas)))\n",
        "    test_error = np.empty((cvf,len(lambdas)))\n",
        "    f = 0\n",
        "    y = y.squeeze()\n",
        "    for train_index, test_index in CV.split(X,y):\n",
        "        X_train = X[train_index]\n",
        "        y_train = y[train_index]\n",
        "        X_test = X[test_index]\n",
        "        y_test = y[test_index]\n",
        "        \n",
        "        # Standardize the training and set set based on training set moments\n",
        "        mu[f, 1:7] = np.mean(X_train[:, 1:7], 0)\n",
        "        sigma[f, 1:7] = np.std(X_train[:, 1:7], 0)\n",
        "        \n",
        "        X_train[:, 1:7] = (X_train[:, 1:7] - mu[f, 1:7] ) / sigma[f, 1:7]\n",
        "        X_test[:, 1:7] = (X_test[:, 1:7] - mu[f, 1:7] ) / sigma[f, 1:7]\n",
        "        \n",
        "        # precompute terms\n",
        "        Xty = X_train.T @ y_train\n",
        "        XtX = X_train.T @ X_train\n",
        "        for l in range(0,len(lambdas)):\n",
        "            # Compute parameters for current value of lambda and current CV fold\n",
        "            # note: \"linalg.lstsq(a,b)\" is substitue for Matlab's left division operator \"\\\"\n",
        "            lambdaI = lambdas[l] * np.eye(M)\n",
        "            lambdaI[0,0] = 0 # remove bias regularization\n",
        "            w[:,f,l] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
        "            # Evaluate training and test performance\n",
        "            train_error[f,l] = np.power(y_train-X_train @ w[:,f,l].T,2).mean(axis=0)\n",
        "            test_error[f,l] = np.power(y_test-X_test @ w[:,f,l].T,2).mean(axis=0)\n",
        "    \n",
        "        f=f+1\n",
        "\n",
        "    opt_val_err = np.min(np.mean(test_error,axis=0))\n",
        "    opt_lambda = lambdas[np.argmin(np.mean(test_error,axis=0))]\n",
        "    train_err_vs_lambda = np.mean(train_error,axis=0)\n",
        "    test_err_vs_lambda = np.mean(test_error,axis=0)\n",
        "    mean_w_vs_lambda = np.squeeze(np.mean(w,axis=1))\n",
        "    \n",
        "    return opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda\n",
        "\n",
        "## Crossvalidation\n",
        "# Create crossvalidation partition for evaluation\n",
        "K = 10\n",
        "CV = model_selection.KFold(K, shuffle=False)\n",
        "#CV = model_selection.KFold(K, shuffle=False)\n",
        "\n",
        "# Values of lambda\n",
        "lambdas = np.power(2.,range(-6,10))\n",
        "\n",
        "# Initialize variables\n",
        "#T = len(lambdas)\n",
        "Error_train_rlr = np.empty((K,1))\n",
        "Error_test_rlr = np.empty((K,1))\n",
        "Error_train_nofeatures = np.empty((K,1))\n",
        "Error_test_nofeatures = np.empty((K,1))\n",
        "w_rlr = np.empty((M,K))\n",
        "mu = np.empty((K, M-1))\n",
        "sigma = np.empty((K, M-1))\n",
        "w_noreg = np.empty((M,K))\n",
        "\n",
        "k=0\n",
        "for train_index, test_index in CV.split(X_lin_regr, Y_lin_regr):\n",
        "    \n",
        "    # extract training and test set for current CV fold\n",
        "    X_train = X_lin_regr[train_index]\n",
        "    y_train = Y_lin_regr[train_index]\n",
        "    X_test = X_lin_regr[test_index]\n",
        "    y_test = Y_lin_regr[test_index]\n",
        "    internal_cross_validation = 10    \n",
        "    \n",
        "    opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda = linear_regression_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
        "\n",
        "    mu[k, 1:7] = np.mean(X_train[:, 1:7], 0)\n",
        "    sigma[k, 1:7] = np.std(X_train[:, 1:7], 0)\n",
        "    \n",
        "    X_train[:, 1:7] = (X_train[:, 1:7] - mu[k, 1:7] ) / sigma[k, 1:7]\n",
        "    X_test[:, 1:7] = (X_test[:, 1:7] - mu[k, 1:7] ) / sigma[k, 1:7]\n",
        "\n",
        "    # Standardize outer fold based on training set, and save the mean and standard\n",
        "    # deviations since they're part of the model (they would be needed for\n",
        "    # making new predictions) - for brevity we won't always store these in the scripts \n",
        "    \n",
        "    Xty = X_train.T @ y_train\n",
        "    XtX = X_train.T @ X_train\n",
        "\n",
        "    # Estimate weights for the optimal value of lambda, on entire training set\n",
        "    lambdaI = opt_lambda * np.eye(M)\n",
        "    lambdaI[0,0] = 0 # Do no regularize the bias term\n",
        "    w_rlr[:,k] = np.linalg.solve(XtX+lambdaI,Xty).squeeze()\n",
        "\n",
        "    lin_predictions_test.append(X_test @ w_rlr[:,k])\n",
        "    test_reg_true_values.append(y_test)\n",
        "\n",
        "    # Compute mean squared error with regularization with optimal lambda\n",
        "    Error_train_rlr[k] = np.square(y_train-X_train @ w_rlr[:,k]).sum(axis=0)/y_train.shape[0]\n",
        "    Error_test_rlr[k] = np.square(y_test-X_test @ w_rlr[:,k]).sum(axis=0)/y_test.shape[0]\n",
        "\n",
        "    Error_test_nofeatures[k] = np.square(y_test-y_test.mean()).sum(axis=0)/y_test.shape[0]\n",
        "\n",
        "    dummy_clf = DummyRegressor(strategy=\"mean\") #use uniform strategy\n",
        "    dummy_clf.fit(X_train,y_train)\n",
        "    y_test_predict_baseline_reg = dummy_clf.predict(X_test)\n",
        "    baseline_reg_predictions_test.append(y_test_predict_baseline_reg)\n",
        "    \n",
        "    print(k, opt_lambda)\n",
        "\n",
        "    k+=1\n",
        "print(Error_test_rlr)\n",
        "print(Error_test_nofeatures)"
      ],
      "metadata": {
        "id": "K3_YOhKvy2CU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f9c97f-60e6-4407-fe31-12bca8be5bd9"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 16.0\n",
            "1 64.0\n",
            "2 16.0\n",
            "3 32.0\n",
            "4 32.0\n",
            "5 32.0\n",
            "6 32.0\n",
            "7 16.0\n",
            "8 16.0\n",
            "9 8.0\n",
            "[[21671.62215619]\n",
            " [18212.24487289]\n",
            " [18753.59140676]\n",
            " [18676.96037174]\n",
            " [16692.10652017]\n",
            " [11284.60496809]\n",
            " [ 5242.41876256]\n",
            " [ 4688.76138118]\n",
            " [ 4638.67985545]\n",
            " [ 8581.05713506]]\n",
            "[[16194.53863422]\n",
            " [22243.47530718]\n",
            " [22544.69517958]\n",
            " [22418.40441871]\n",
            " [18468.900638  ]\n",
            " [14470.88846881]\n",
            " [ 6712.46455577]\n",
            " [ 4318.2716713 ]\n",
            " [ 2157.54426827]\n",
            " [  670.20215593]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import for baseline model"
      ],
      "metadata": {
        "id": "rqyj88W9y6VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_regr, X_test_regr, y_train_regr, y_test_regr = train_test_split(features_regr, response_regr, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "GQZvgb6Jy6qT"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline model**"
      ],
      "metadata": {
        "id": "5soSWv06WFBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy_clf = DummyRegressor(strategy=\"mean\") #use uniform strategy\n",
        "# dummy_clf.fit(X_train,y_train)\n",
        "# y_test_predict = dummy_clf.predict(X_test_regr)\n",
        "# dummy_clf.score(X_test_regr,y_test_regr)"
      ],
      "metadata": {
        "id": "5lL9Rbe9WJXS"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN"
      ],
      "metadata": {
        "id": "Tg6NOTvDqNdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import torch\n",
        "from sklearn import model_selection\n",
        "from toolbox_02450 import train_neural_net, draw_neural_net\n",
        "from scipy import stats\n",
        "\n",
        "K1 = 10\n",
        "K2 = 10\n",
        "M = 42\n",
        "\n",
        "CV1 = model_selection.KFold(n_splits=K1,shuffle=False)\n",
        "CV2 = model_selection.KFold(n_splits=K2,shuffle=False)\n",
        "\n",
        "# Parameters for NN\n",
        "n_hidden_units = [25]    # number of hidden units\n",
        "#n_hidden_units = [1,5,10,25]\n",
        "n_replicates = 1\n",
        "max_iter = 10000\n",
        "\n",
        "#features_regr[0:6]=(features_regr[0:6]-features_regr[0:6].mean())/features_regr[0:6].std()\n",
        "\n",
        "X = features_regr.to_numpy()\n",
        "y = response_regr.to_numpy()\n",
        "\n",
        "y = y.reshape([1837,1])\n",
        "errors = []\n",
        "print(\"X shape: \", np.shape(X), \"Y shape: \", np.shape(y))\n",
        "\n",
        "for i, (par_index, test_index) in enumerate(CV1.split(X,y)):\n",
        "\n",
        "    mu[i, 0:6] = np.mean(X[:, 0:6], 0)\n",
        "    sigma[i, 0:6] = np.std(X[:, 0:6], 0)\n",
        "    \n",
        "    X[:, 0:6] = (X[:, 0:6] - mu[i, 0:6] ) / sigma[i, 0:6]\n",
        "    \n",
        "    X_par, X_test, y_par, y_test = torch.Tensor(X[par_index,:]), torch.Tensor(X[test_index,:]), torch.Tensor(y[par_index]), torch.Tensor(y[test_index])\n",
        "\n",
        "    e_gen_lvl3 = []\n",
        "    errors_matrix = np.zeros((len(n_hidden_units),K2))\n",
        "    nets = np.zeros((len(n_hidden_units),K2))\n",
        "    \n",
        "    for j, (train_index, val_index) in enumerate(CV2.split(X_par,y_par)):\n",
        "        X_train, X_val,y_train,y_val = torch.Tensor(X_par[train_index,:]), torch.Tensor(X_par[val_index,:]), torch.Tensor(y_par[train_index]), torch.Tensor(y_par[val_index])        \n",
        "        for n in range(0,len(n_hidden_units)):\n",
        "\n",
        "            print(\"N = \",n,\" J = \", j, \"I = \", i)\n",
        "            \n",
        "            model = lambda: torch.nn.Sequential(\n",
        "                    torch.nn.Linear(M, n_hidden_units[n]), #M features to n_hidden_units\n",
        "                    torch.nn.Tanh(),   # 1st transfer function,\n",
        "                    torch.nn.Linear(n_hidden_units[n], 1), # n_hidden_units to 1 output neuron\n",
        "                    # no final tranfer function, i.e. \"linear output\"\n",
        "                    )\n",
        "            loss_fn = torch.nn.MSELoss() # notice how this is now a mean-squared-error loss\n",
        "            net, final_loss, learning_curve = train_neural_net(model,\n",
        "                                                       loss_fn,\n",
        "                                                       X=X_train,\n",
        "                                                       y=y_train,\n",
        "                                                       n_replicates=n_replicates,\n",
        "                                                       max_iter = max_iter)\n",
        "    \n",
        "            print('\\n\\tBest loss: {}\\n'.format(final_loss))\n",
        "\n",
        "            y_val_est = net(X_val)\n",
        "            squared_error = (y_val_est.float()-y_val.float())**2 # squared error\n",
        "            mean_squared_error = (sum(squared_error).type(torch.float)/len(y_val)).data.numpy() #mean\n",
        "            errors_matrix[n][j] = mean_squared_error\n",
        "\n",
        "        e_gen_lvl3 = np.sum(errors_matrix, axis=1)\n",
        "        e_gen_lvl3 = e_gen_lvl3 * (len(X_val)/len(X_par))\n",
        "        min_value = min(e_gen_lvl3)\n",
        "        e_gen_lvl3 = e_gen_lvl3.tolist()\n",
        "        index_min = e_gen_lvl3.index(min_value)\n",
        "        print('Optimal N: ', n_hidden_units[index_min])\n",
        "\n",
        "        \n",
        "        model = lambda: torch.nn.Sequential(\n",
        "                    torch.nn.Linear(M, n_hidden_units[index_min]), \n",
        "                    torch.nn.Tanh(),\n",
        "                    torch.nn.Linear(n_hidden_units[index_min], 1), \n",
        "                    # no final tranfer function, i.e. \"linear output\"\n",
        "                    )\n",
        "        loss_fn = torch.nn.MSELoss() # notice how this is now a mean-squared-error loss\n",
        "            \n",
        "        net, final_loss, learning_curve = train_neural_net(model,\n",
        "                                                       loss_fn,\n",
        "                                                       X=X_par,\n",
        "                                                       y=y_par,\n",
        "                                                       n_replicates=n_replicates,\n",
        "                                                       max_iter = max_iter)\n",
        "        print('\\n\\tBest loss outter loop: {}\\n'.format(final_loss))\n",
        "        y_test_est = net(X_test)\n",
        "        # Determine errors\n",
        "        squared_error = (y_test_est.float()-y_test.float())**2 # squared error\n",
        "        mean_squared_error = (sum(squared_error).type(torch.float)/len(y_test)).data.numpy() #mean\n",
        "        errors.append(mean_squared_error)\n",
        "        y_test_est = y_test_est.detach().numpy()\n",
        "        ann_predictions_test.append(y_test_est)\n",
        "        print(\"OUTTER FOLDER:\", i, \"OUTTER MSE: \", mean_squared_error)\n",
        "\n",
        "\n",
        "errors_array = np.array(errors)\n",
        "e_gen = errors_array.sum() * (len(X_test)/(len(X_par)+len(X_train)))\n",
        "print(\"ERROR TEST: \", errors, \"GENERALIZED ERROR: \", e_gen)"
      ],
      "metadata": {
        "id": "t4ZPIw6kqP9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0141c9ce-11f9-4903-e04e-201b7ddb968b"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape:  (1837, 42) Y shape:  (1837, 1)\n",
            "N =  0  J =  0 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17247.402\t0.00019281342\n",
            "\t\t2000\t14657.049\t0.0001439613\n",
            "\t\t3000\t12892.584\t0.00011428775\n",
            "\t\t4000\t11601.02\t0.000101004625\n",
            "\t\t5000\t10501.582\t9.6144424e-05\n",
            "\t\t6000\t9557.898\t9.603373e-05\n",
            "\t\t7000\t8735.623\t8.562444e-05\n",
            "\t\t8000\t8054.372\t7.468212e-05\n",
            "\t\t9000\t7517.2446\t6.436608e-05\n",
            "\t\t10000\t7115.5527\t4.6591955e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7115.5527\t4.6591955e-05\n",
            "\n",
            "\tBest loss: 7115.552734375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18425.34\t0.000186317\n",
            "\t\t2000\t15773.397\t0.00014225353\n",
            "\t\t3000\t13909.186\t0.00011393768\n",
            "\t\t4000\t12477.087\t0.000103147206\n",
            "\t\t5000\t11260.694\t0.00010206269\n",
            "\t\t6000\t10239.087\t9.222003e-05\n",
            "\t\t7000\t9370.227\t8.576548e-05\n",
            "\t\t8000\t8711.479\t6.411747e-05\n",
            "\t\t9000\t8229.05\t5.4111766e-05\n",
            "\t\t10000\t7804.512\t5.1987954e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7804.512\t5.1987954e-05\n",
            "\n",
            "\tBest loss outter loop: 7804.51220703125\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [22499.97]\n",
            "N =  0  J =  1 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17231.398\t0.00019219934\n",
            "\t\t2000\t14683.349\t0.00014649601\n",
            "\t\t3000\t12841.053\t0.00012288176\n",
            "\t\t4000\t11470.342\t0.00010564515\n",
            "\t\t5000\t10355.922\t9.5045274e-05\n",
            "\t\t6000\t9402.804\t9.6371536e-05\n",
            "\t\t7000\t8585.069\t8.007448e-05\n",
            "\t\t8000\t7998.5815\t6.0187715e-05\n",
            "\t\t9000\t7501.9893\t6.085255e-05\n",
            "\t\t10000\t7058.6543\t5.9348487e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7058.6543\t5.9348487e-05\n",
            "\n",
            "\tBest loss: 7058.654296875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18504.898\t0.00018762625\n",
            "\t\t2000\t15835.119\t0.0001441036\n",
            "\t\t3000\t13934.947\t0.00011744045\n",
            "\t\t4000\t12502.258\t0.00010293956\n",
            "\t\t5000\t11305.467\t9.630406e-05\n",
            "\t\t6000\t10272.7705\t9.44839e-05\n",
            "\t\t7000\t9415.158\t7.965243e-05\n",
            "\t\t8000\t8744.421\t6.9682435e-05\n",
            "\t\t9000\t8241.101\t5.4032644e-05\n",
            "\t\t10000\t7837.075\t4.977843e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7837.075\t4.977843e-05\n",
            "\n",
            "\tBest loss outter loop: 7837.0751953125\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [21841.355]\n",
            "N =  0  J =  2 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16980.906\t0.00019250455\n",
            "\t\t2000\t14479.819\t0.00014592535\n",
            "\t\t3000\t12718.453\t0.00011777143\n",
            "\t\t4000\t11410.971\t0.000101403224\n",
            "\t\t5000\t10339.412\t9.727454e-05\n",
            "\t\t6000\t9384.436\t9.614398e-05\n",
            "\t\t7000\t8598.869\t8.1308586e-05\n",
            "\t\t8000\t8008.5913\t5.791784e-05\n",
            "\t\t9000\t7552.419\t6.897924e-05\n",
            "\t\t10000\t7115.0303\t5.3045645e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7115.0303\t5.3045645e-05\n",
            "\n",
            "\tBest loss: 7115.0302734375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18451.988\t0.00018678863\n",
            "\t\t2000\t15800.961\t0.00014225255\n",
            "\t\t3000\t13921.11\t0.0001153129\n",
            "\t\t4000\t12480.861\t0.00010577578\n",
            "\t\t5000\t11301.348\t9.504324e-05\n",
            "\t\t6000\t10287.14\t9.008085e-05\n",
            "\t\t7000\t9445.946\t8.0219776e-05\n",
            "\t\t8000\t8772.769\t6.511649e-05\n",
            "\t\t9000\t8266.416\t4.914222e-05\n",
            "\t\t10000\t7906.5537\t3.8781593e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7906.5537\t3.8781593e-05\n",
            "\n",
            "\tBest loss outter loop: 7906.5537109375\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [22616.877]\n",
            "N =  0  J =  3 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17190.94\t0.00018969877\n",
            "\t\t2000\t14707.925\t0.00013868416\n",
            "\t\t3000\t13031.201\t0.00010850182\n",
            "\t\t4000\t11724.521\t9.8608376e-05\n",
            "\t\t5000\t10638.405\t9.674357e-05\n",
            "\t\t6000\t9656.7705\t9.6870506e-05\n",
            "\t\t7000\t8781.5\t8.9402274e-05\n",
            "\t\t8000\t8082.902\t7.6230535e-05\n",
            "\t\t9000\t7563.2607\t6.229615e-05\n",
            "\t\t10000\t7125.678\t5.4747823e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7125.678\t5.4747823e-05\n",
            "\n",
            "\tBest loss: 7125.67822265625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18552.568\t0.00018640759\n",
            "\t\t2000\t15881.867\t0.00014392538\n",
            "\t\t3000\t13969.568\t0.00011686987\n",
            "\t\t4000\t12526.728\t0.00010188113\n",
            "\t\t5000\t11339.037\t9.688004e-05\n",
            "\t\t6000\t10298.241\t9.169035e-05\n",
            "\t\t7000\t9418.288\t8.4602165e-05\n",
            "\t\t8000\t8748.046\t6.552373e-05\n",
            "\t\t9000\t8196.563\t6.588169e-05\n",
            "\t\t10000\t7774.995\t5.689491e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7774.995\t5.689491e-05\n",
            "\n",
            "\tBest loss outter loop: 7774.9951171875\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [23225.662]\n",
            "N =  0  J =  4 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17229.898\t0.00018587049\n",
            "\t\t2000\t14769.154\t0.0001426704\n",
            "\t\t3000\t13038.419\t0.0001154058\n",
            "\t\t4000\t11716.899\t0.00010267234\n",
            "\t\t5000\t10606.977\t9.951554e-05\n",
            "\t\t6000\t9580.858\t9.9778044e-05\n",
            "\t\t7000\t8725.844\t8.739885e-05\n",
            "\t\t8000\t8058.147\t7.652529e-05\n",
            "\t\t9000\t7524.2256\t6.4436135e-05\n",
            "\t\t10000\t7083.5415\t5.4315307e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7083.5415\t5.4315307e-05\n",
            "\n",
            "\tBest loss: 7083.54150390625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18499.986\t0.00018799266\n",
            "\t\t2000\t15826.842\t0.00014164986\n",
            "\t\t3000\t13942.549\t0.000114295304\n",
            "\t\t4000\t12512.964\t0.000101056845\n",
            "\t\t5000\t11336.591\t9.74177e-05\n",
            "\t\t6000\t10339.219\t8.584973e-05\n",
            "\t\t7000\t9514.066\t7.9645455e-05\n",
            "\t\t8000\t8863.335\t6.599348e-05\n",
            "\t\t9000\t8283.635\t6.719311e-05\n",
            "\t\t10000\t7833.061\t4.936763e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7833.061\t4.936763e-05\n",
            "\n",
            "\tBest loss outter loop: 7833.06103515625\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [23403.312]\n",
            "N =  0  J =  5 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18771.115\t0.00018350962\n",
            "\t\t2000\t16122.468\t0.00014044564\n",
            "\t\t3000\t14253.464\t0.000108788474\n",
            "\t\t4000\t12792.174\t0.000104575716\n",
            "\t\t5000\t11547.315\t9.817674e-05\n",
            "\t\t6000\t10467.808\t9.580168e-05\n",
            "\t\t7000\t9544.415\t8.563257e-05\n",
            "\t\t8000\t8841.732\t6.858427e-05\n",
            "\t\t9000\t8280.691\t6.745283e-05\n",
            "\t\t10000\t7783.961\t5.507316e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7783.961\t5.507316e-05\n",
            "\n",
            "\tBest loss: 7783.9609375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18444.305\t0.00018549034\n",
            "\t\t2000\t15795.246\t0.00014168593\n",
            "\t\t3000\t13915.843\t0.00011640895\n",
            "\t\t4000\t12474.861\t0.00010167854\n",
            "\t\t5000\t11294.172\t0.00010029056\n",
            "\t\t6000\t10273.986\t8.801036e-05\n",
            "\t\t7000\t9437.832\t7.915072e-05\n",
            "\t\t8000\t8761.007\t6.4980995e-05\n",
            "\t\t9000\t8281.463\t5.082158e-05\n",
            "\t\t10000\t7863.271\t4.719108e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7863.271\t4.719108e-05\n",
            "\n",
            "\tBest loss outter loop: 7863.27099609375\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [23010.328]\n",
            "N =  0  J =  6 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19581.93\t0.00018059868\n",
            "\t\t2000\t16839.498\t0.00013730708\n",
            "\t\t3000\t14855.799\t0.000116667994\n",
            "\t\t4000\t13287.41\t0.00010912865\n",
            "\t\t5000\t11958.842\t0.00010337124\n",
            "\t\t6000\t10783.695\t9.842813e-05\n",
            "\t\t7000\t9856.18\t8.530167e-05\n",
            "\t\t8000\t9118.585\t7.710306e-05\n",
            "\t\t9000\t8528.197\t7.0876566e-05\n",
            "\t\t10000\t8087.3823\t4.6185265e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8087.3823\t4.6185265e-05\n",
            "\n",
            "\tBest loss: 8087.38232421875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18532.236\t0.00018756023\n",
            "\t\t2000\t15846.973\t0.000142086\n",
            "\t\t3000\t13955.449\t0.000116288495\n",
            "\t\t4000\t12504.934\t0.000102761376\n",
            "\t\t5000\t11351.708\t9.29014e-05\n",
            "\t\t6000\t10324.684\t9.249579e-05\n",
            "\t\t7000\t9445.366\t8.818444e-05\n",
            "\t\t8000\t8747.613\t6.6308334e-05\n",
            "\t\t9000\t8206.283\t5.6998615e-05\n",
            "\t\t10000\t7792.2075\t4.8310656e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7792.2075\t4.8310656e-05\n",
            "\n",
            "\tBest loss outter loop: 7792.20751953125\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [22820.36]\n",
            "N =  0  J =  7 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20012.951\t0.00018217304\n",
            "\t\t2000\t17162.805\t0.0001408644\n",
            "\t\t3000\t15122.943\t0.0001162213\n",
            "\t\t4000\t13511.813\t0.00011006228\n",
            "\t\t5000\t12148.967\t0.00010271809\n",
            "\t\t6000\t11022.856\t9.212961e-05\n",
            "\t\t7000\t10065.971\t8.332999e-05\n",
            "\t\t8000\t9328.638\t7.11803e-05\n",
            "\t\t9000\t8749.58\t6.0601913e-05\n",
            "\t\t10000\t8202.601\t6.1309685e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8202.601\t6.1309685e-05\n",
            "\n",
            "\tBest loss: 8202.6005859375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18558.727\t0.00018813416\n",
            "\t\t2000\t15870.161\t0.00014114023\n",
            "\t\t3000\t13973.817\t0.00011690421\n",
            "\t\t4000\t12513.122\t0.00010324032\n",
            "\t\t5000\t11340.724\t9.471327e-05\n",
            "\t\t6000\t10313.696\t9.089029e-05\n",
            "\t\t7000\t9477.94\t7.850674e-05\n",
            "\t\t8000\t8806.341\t6.8749e-05\n",
            "\t\t9000\t8248.717\t6.58203e-05\n",
            "\t\t10000\t7792.7993\t5.162753e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7792.7993\t5.162753e-05\n",
            "\n",
            "\tBest loss outter loop: 7792.79931640625\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [22512.95]\n",
            "N =  0  J =  8 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20271.555\t0.00018505038\n",
            "\t\t2000\t17326.062\t0.00014449586\n",
            "\t\t3000\t15211.473\t0.00012042296\n",
            "\t\t4000\t13583.847\t0.00010955057\n",
            "\t\t5000\t12221.65\t0.00010282627\n",
            "\t\t6000\t11072.68\t9.594769e-05\n",
            "\t\t7000\t10124.31\t7.918508e-05\n",
            "\t\t8000\t9412.871\t6.7846304e-05\n",
            "\t\t9000\t8830.86\t5.739043e-05\n",
            "\t\t10000\t8387.117\t4.7270787e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8387.117\t4.7270787e-05\n",
            "\n",
            "\tBest loss: 8387.1171875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18525.896\t0.00018825672\n",
            "\t\t2000\t15835.912\t0.00014335659\n",
            "\t\t3000\t13951.126\t0.000115624694\n",
            "\t\t4000\t12519.291\t0.000103969345\n",
            "\t\t5000\t11343.031\t9.6071235e-05\n",
            "\t\t6000\t10292.197\t9.5064504e-05\n",
            "\t\t7000\t9444.324\t7.713198e-05\n",
            "\t\t8000\t8797.639\t6.171375e-05\n",
            "\t\t9000\t8282.082\t6.638043e-05\n",
            "\t\t10000\t7836.9595\t4.6788817e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7836.9595\t4.6788817e-05\n",
            "\n",
            "\tBest loss outter loop: 7836.95947265625\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [23255.418]\n",
            "N =  0  J =  9 I =  0\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20413.951\t0.00019007205\n",
            "\t\t2000\t17355.188\t0.00015145374\n",
            "\t\t3000\t15145.589\t0.00012526572\n",
            "\t\t4000\t13455.503\t0.00011233686\n",
            "\t\t5000\t12110.975\t0.00010021865\n",
            "\t\t6000\t10985.188\t9.9733734e-05\n",
            "\t\t7000\t10013.515\t8.971444e-05\n",
            "\t\t8000\t9242.842\t7.828503e-05\n",
            "\t\t9000\t8681.618\t5.252831e-05\n",
            "\t\t10000\t8218.692\t5.1090905e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8218.692\t5.1090905e-05\n",
            "\n",
            "\tBest loss: 8218.6923828125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18600.398\t0.00018739786\n",
            "\t\t2000\t15913.161\t0.00014174051\n",
            "\t\t3000\t14005.94\t0.000117681746\n",
            "\t\t4000\t12528.8\t0.00010622831\n",
            "\t\t5000\t11308.832\t9.670709e-05\n",
            "\t\t6000\t10298.712\t8.9315996e-05\n",
            "\t\t7000\t9448.403\t7.854546e-05\n",
            "\t\t8000\t8792.766\t6.49684e-05\n",
            "\t\t9000\t8293.004\t4.9220165e-05\n",
            "\t\t10000\t7869.4863\t5.379221e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7869.4863\t5.379221e-05\n",
            "\n",
            "\tBest loss outter loop: 7869.486328125\n",
            "\n",
            "OUTTER FOLDER: 0 OUTTER MSE:  [22013.2]\n",
            "N =  0  J =  0 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17161.018\t0.00019332874\n",
            "\t\t2000\t14570.332\t0.00014475097\n",
            "\t\t3000\t12789.564\t0.00011986486\n",
            "\t\t4000\t11486.567\t9.82709e-05\n",
            "\t\t5000\t10447.023\t9.608572e-05\n",
            "\t\t6000\t9536.297\t8.6319786e-05\n",
            "\t\t7000\t8785.58\t8.280373e-05\n",
            "\t\t8000\t8143.151\t7.0930255e-05\n",
            "\t\t9000\t7638.408\t5.343801e-05\n",
            "\t\t10000\t7239.5186\t5.1189385e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7239.5186\t5.1189385e-05\n",
            "\n",
            "\tBest loss: 7239.5185546875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18189.602\t0.00019678132\n",
            "\t\t2000\t15436.264\t0.00014826925\n",
            "\t\t3000\t13475.535\t0.00012492145\n",
            "\t\t4000\t12028.971\t9.984661e-05\n",
            "\t\t5000\t10972.47\t8.6768596e-05\n",
            "\t\t6000\t10055.866\t9.428852e-05\n",
            "\t\t7000\t9258.62\t7.203494e-05\n",
            "\t\t8000\t8647.567\t5.9171376e-05\n",
            "\t\t9000\t8214.873\t4.1605348e-05\n",
            "\t\t10000\t7903.8506\t3.5150242e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7903.8506\t3.5150242e-05\n",
            "\n",
            "\tBest loss outter loop: 7903.8505859375\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [16983.314]\n",
            "N =  0  J =  1 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16833.904\t0.00020717467\n",
            "\t\t2000\t14196.717\t0.00015316722\n",
            "\t\t3000\t12338.733\t0.00012859586\n",
            "\t\t4000\t10981.702\t0.00010590005\n",
            "\t\t5000\t9937.813\t9.580148e-05\n",
            "\t\t6000\t9031.379\t9.590206e-05\n",
            "\t\t7000\t8277.814\t8.281052e-05\n",
            "\t\t8000\t7676.817\t7.383955e-05\n",
            "\t\t9000\t7276.8413\t5.0054627e-05\n",
            "\t\t10000\t6963.1494\t3.8917096e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t6963.1494\t3.8917096e-05\n",
            "\n",
            "\tBest loss: 6963.1494140625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17842.273\t0.00019853217\n",
            "\t\t2000\t15151.853\t0.00014750815\n",
            "\t\t3000\t13279.031\t0.000121623176\n",
            "\t\t4000\t11886.464\t9.7429336e-05\n",
            "\t\t5000\t10863.813\t8.898448e-05\n",
            "\t\t6000\t9984.533\t7.863107e-05\n",
            "\t\t7000\t9239.437\t7.482648e-05\n",
            "\t\t8000\t8612.051\t7.347448e-05\n",
            "\t\t9000\t8121.072\t4.4250206e-05\n",
            "\t\t10000\t7796.0312\t3.300599e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7796.0312\t3.300599e-05\n",
            "\n",
            "\tBest loss outter loop: 7796.03125\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17123.088]\n",
            "N =  0  J =  2 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16271.992\t0.00020334925\n",
            "\t\t2000\t13753.983\t0.00015483172\n",
            "\t\t3000\t12003.523\t0.000124053\n",
            "\t\t4000\t10739.53\t9.846921e-05\n",
            "\t\t5000\t9746.185\t9.598188e-05\n",
            "\t\t6000\t8909.054\t8.4286534e-05\n",
            "\t\t7000\t8201.965\t7.476689e-05\n",
            "\t\t8000\t7613.425\t6.669517e-05\n",
            "\t\t9000\t7186.2295\t6.67193e-05\n",
            "\t\t10000\t6878.464\t4.1312705e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t6878.464\t4.1312705e-05\n",
            "\n",
            "\tBest loss: 6878.4638671875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18036.012\t0.00019813197\n",
            "\t\t2000\t15312.856\t0.00015035654\n",
            "\t\t3000\t13365.859\t0.00012382807\n",
            "\t\t4000\t11948.45\t9.9293684e-05\n",
            "\t\t5000\t10874.761\t8.78175e-05\n",
            "\t\t6000\t10027.996\t7.965345e-05\n",
            "\t\t7000\t9238.206\t7.3356736e-05\n",
            "\t\t8000\t8617.569\t6.8328656e-05\n",
            "\t\t9000\t8147.965\t4.536251e-05\n",
            "\t\t10000\t7817.6377\t4.05342e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7817.6377\t4.05342e-05\n",
            "\n",
            "\tBest loss outter loop: 7817.6376953125\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17478.559]\n",
            "N =  0  J =  3 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16768.232\t0.00020193153\n",
            "\t\t2000\t14206.356\t0.00014818415\n",
            "\t\t3000\t12456.593\t0.000118600954\n",
            "\t\t4000\t11180.212\t9.799418e-05\n",
            "\t\t5000\t10190.253\t8.614644e-05\n",
            "\t\t6000\t9297.033\t9.0956564e-05\n",
            "\t\t7000\t8535.788\t7.5389195e-05\n",
            "\t\t8000\t8007.3833\t5.695103e-05\n",
            "\t\t9000\t7572.337\t4.9390957e-05\n",
            "\t\t10000\t7226.0176\t3.9798713e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7226.0176\t3.9798713e-05\n",
            "\n",
            "\tBest loss: 7226.017578125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18053.082\t0.00019967498\n",
            "\t\t2000\t15318.496\t0.00015011\n",
            "\t\t3000\t13374.932\t0.00012447404\n",
            "\t\t4000\t11962.95\t9.835718e-05\n",
            "\t\t5000\t10900.333\t9.334423e-05\n",
            "\t\t6000\t9967.863\t8.1211445e-05\n",
            "\t\t7000\t9215.156\t8.233464e-05\n",
            "\t\t8000\t8596.703\t6.4291955e-05\n",
            "\t\t9000\t8147.5073\t5.303536e-05\n",
            "\t\t10000\t7787.3594\t3.8936287e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7787.3594\t3.8936287e-05\n",
            "\n",
            "\tBest loss outter loop: 7787.359375\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17471.816]\n",
            "N =  0  J =  4 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16457.855\t0.00019719785\n",
            "\t\t2000\t13984.468\t0.00014711425\n",
            "\t\t3000\t12276.098\t0.000117083764\n",
            "\t\t4000\t11042.269\t9.771508e-05\n",
            "\t\t5000\t10060.249\t9.3471026e-05\n",
            "\t\t6000\t9168.659\t9.372084e-05\n",
            "\t\t7000\t8454.808\t7.333954e-05\n",
            "\t\t8000\t7886.239\t6.4635715e-05\n",
            "\t\t9000\t7481.1626\t4.9340248e-05\n",
            "\t\t10000\t7166.5947\t4.4761346e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7166.5947\t4.4761346e-05\n",
            "\n",
            "\tBest loss: 7166.5947265625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18077.174\t0.00019789691\n",
            "\t\t2000\t15350.82\t0.0001487128\n",
            "\t\t3000\t13406.271\t0.00012389179\n",
            "\t\t4000\t11989.849\t0.00010114956\n",
            "\t\t5000\t10910.8955\t9.110619e-05\n",
            "\t\t6000\t10002.273\t8.093208e-05\n",
            "\t\t7000\t9188.895\t7.6619406e-05\n",
            "\t\t8000\t8584.378\t5.8696936e-05\n",
            "\t\t9000\t8083.6895\t6.535206e-05\n",
            "\t\t10000\t7656.5215\t4.055814e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7656.5215\t4.055814e-05\n",
            "\n",
            "\tBest loss outter loop: 7656.521484375\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17266.77]\n",
            "N =  0  J =  5 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18338.86\t0.0001952865\n",
            "\t\t2000\t15630.497\t0.00014205484\n",
            "\t\t3000\t13693.904\t0.000119721306\n",
            "\t\t4000\t12264.453\t9.562101e-05\n",
            "\t\t5000\t11203.053\t0.00010250061\n",
            "\t\t6000\t10175.468\t8.9725996e-05\n",
            "\t\t7000\t9382.272\t7.566474e-05\n",
            "\t\t8000\t8743.529\t6.622763e-05\n",
            "\t\t9000\t8253.322\t5.513574e-05\n",
            "\t\t10000\t7889.254\t3.65768e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7889.254\t3.65768e-05\n",
            "\n",
            "\tBest loss: 7889.25390625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17947.56\t0.00019671506\n",
            "\t\t2000\t15235.59\t0.0001512471\n",
            "\t\t3000\t13321.515\t0.0001237272\n",
            "\t\t4000\t11912.503\t9.9347395e-05\n",
            "\t\t5000\t10870.963\t9.224916e-05\n",
            "\t\t6000\t9975.9375\t8.486499e-05\n",
            "\t\t7000\t9205.387\t7.6376076e-05\n",
            "\t\t8000\t8610.723\t5.5001976e-05\n",
            "\t\t9000\t8182.271\t4.4635293e-05\n",
            "\t\t10000\t7845.6333\t3.758916e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7845.6333\t3.758916e-05\n",
            "\n",
            "\tBest loss outter loop: 7845.63330078125\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17521.438]\n",
            "N =  0  J =  6 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18895.303\t0.0001897433\n",
            "\t\t2000\t16122.631\t0.00014383523\n",
            "\t\t3000\t14166.81\t0.00012013601\n",
            "\t\t4000\t12707.179\t9.835992e-05\n",
            "\t\t5000\t11572.15\t9.231307e-05\n",
            "\t\t6000\t10490.472\t9.317484e-05\n",
            "\t\t7000\t9633.742\t7.987236e-05\n",
            "\t\t8000\t8960.767\t6.2006926e-05\n",
            "\t\t9000\t8461.747\t5.1700597e-05\n",
            "\t\t10000\t8019.366\t4.468962e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8019.366\t4.468962e-05\n",
            "\n",
            "\tBest loss: 8019.3662109375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18029.475\t0.0001982038\n",
            "\t\t2000\t15288.438\t0.0001497665\n",
            "\t\t3000\t13375.665\t0.00012329934\n",
            "\t\t4000\t11976.927\t9.799785e-05\n",
            "\t\t5000\t10960.496\t8.0538455e-05\n",
            "\t\t6000\t10065.737\t8.837602e-05\n",
            "\t\t7000\t9273.325\t7.792242e-05\n",
            "\t\t8000\t8671.269\t5.687011e-05\n",
            "\t\t9000\t8204.931\t4.939145e-05\n",
            "\t\t10000\t7862.008\t3.5709923e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7862.008\t3.5709923e-05\n",
            "\n",
            "\tBest loss outter loop: 7862.0078125\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [16967.547]\n",
            "N =  0  J =  7 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19499.682\t0.00019187336\n",
            "\t\t2000\t16605.32\t0.00015029633\n",
            "\t\t3000\t14513.007\t0.00012379602\n",
            "\t\t4000\t12958.869\t0.00010021692\n",
            "\t\t5000\t11794.308\t8.999493e-05\n",
            "\t\t6000\t10757.757\t8.859101e-05\n",
            "\t\t7000\t9867.161\t8.075379e-05\n",
            "\t\t8000\t9181.652\t6.306763e-05\n",
            "\t\t9000\t8691.019\t4.662912e-05\n",
            "\t\t10000\t8349.526\t3.4502078e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8349.526\t3.4502078e-05\n",
            "\n",
            "\tBest loss: 8349.5263671875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18089.684\t0.00019732838\n",
            "\t\t2000\t15340.138\t0.00015142566\n",
            "\t\t3000\t13402.435\t0.00012436433\n",
            "\t\t4000\t12000.237\t9.7156604e-05\n",
            "\t\t5000\t10929.829\t9.166303e-05\n",
            "\t\t6000\t10015.808\t8.676936e-05\n",
            "\t\t7000\t9175.88\t8.247422e-05\n",
            "\t\t8000\t8563.19\t5.8272013e-05\n",
            "\t\t9000\t8125.389\t4.4226694e-05\n",
            "\t\t10000\t7763.8726\t3.8550977e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7763.8726\t3.8550977e-05\n",
            "\n",
            "\tBest loss outter loop: 7763.87255859375\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17320.906]\n",
            "N =  0  J =  8 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19798.805\t0.00019627225\n",
            "\t\t2000\t16810.092\t0.000149395\n",
            "\t\t3000\t14651.897\t0.0001279534\n",
            "\t\t4000\t13029.842\t0.00010289322\n",
            "\t\t5000\t11832.55\t9.1106886e-05\n",
            "\t\t6000\t10817.904\t9.297234e-05\n",
            "\t\t7000\t9869.663\t8.261298e-05\n",
            "\t\t8000\t9168.368\t6.24135e-05\n",
            "\t\t9000\t8676.458\t4.7945334e-05\n",
            "\t\t10000\t8313.454\t4.663251e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8313.454\t4.663251e-05\n",
            "\n",
            "\tBest loss: 8313.4541015625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18078.465\t0.00019777479\n",
            "\t\t2000\t15319.001\t0.00014978641\n",
            "\t\t3000\t13376.881\t0.00012372604\n",
            "\t\t4000\t11970.885\t0.00010073885\n",
            "\t\t5000\t10963.216\t8.568404e-05\n",
            "\t\t6000\t10024.434\t9.000634e-05\n",
            "\t\t7000\t9232.613\t7.488178e-05\n",
            "\t\t8000\t8644.815\t5.6931174e-05\n",
            "\t\t9000\t8224.2295\t4.571363e-05\n",
            "\t\t10000\t7902.3745\t4.0779196e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7902.3745\t4.0779196e-05\n",
            "\n",
            "\tBest loss outter loop: 7902.37451171875\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17569.67]\n",
            "N =  0  J =  9 I =  1\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19892.006\t0.00020075093\n",
            "\t\t2000\t16771.584\t0.00015893501\n",
            "\t\t3000\t14543.086\t0.00013139451\n",
            "\t\t4000\t12907.885\t0.00010651269\n",
            "\t\t5000\t11706.494\t9.167081e-05\n",
            "\t\t6000\t10646.486\t9.5019386e-05\n",
            "\t\t7000\t9814.596\t7.2531e-05\n",
            "\t\t8000\t9151.779\t6.241993e-05\n",
            "\t\t9000\t8677.566\t4.4900946e-05\n",
            "\t\t10000\t8340.773\t3.4655357e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8340.773\t3.4655357e-05\n",
            "\n",
            "\tBest loss: 8340.7734375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18019.504\t0.00019874683\n",
            "\t\t2000\t15276.8545\t0.00015058302\n",
            "\t\t3000\t13369.907\t0.00012327942\n",
            "\t\t4000\t11953.24\t9.68851e-05\n",
            "\t\t5000\t10930.331\t8.540583e-05\n",
            "\t\t6000\t10048.49\t9.027671e-05\n",
            "\t\t7000\t9197.64\t8.227912e-05\n",
            "\t\t8000\t8544.771\t6.0454553e-05\n",
            "\t\t9000\t8080.3315\t5.4503416e-05\n",
            "\t\t10000\t7711.307\t3.792734e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7711.307\t3.792734e-05\n",
            "\n",
            "\tBest loss outter loop: 7711.30712890625\n",
            "\n",
            "OUTTER FOLDER: 1 OUTTER MSE:  [17463.342]\n",
            "N =  0  J =  0 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17038.31\t0.00019426244\n",
            "\t\t2000\t14520.472\t0.00014726497\n",
            "\t\t3000\t12756.787\t0.00011657569\n",
            "\t\t4000\t11443.418\t9.881205e-05\n",
            "\t\t5000\t10385.591\t9.787619e-05\n",
            "\t\t6000\t9459.368\t9.7550015e-05\n",
            "\t\t7000\t8674.441\t7.87993e-05\n",
            "\t\t8000\t8087.5835\t5.9163198e-05\n",
            "\t\t9000\t7625.4565\t5.7050194e-05\n",
            "\t\t10000\t7233.177\t4.8804297e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7233.177\t4.8804297e-05\n",
            "\n",
            "\tBest loss: 7233.1767578125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17707.145\t0.00019640842\n",
            "\t\t2000\t15056.074\t0.00014792764\n",
            "\t\t3000\t13211.439\t0.000117294025\n",
            "\t\t4000\t11839.002\t9.979918e-05\n",
            "\t\t5000\t10781.332\t8.9936875e-05\n",
            "\t\t6000\t9842.818\t8.660784e-05\n",
            "\t\t7000\t9111.968\t7.019379e-05\n",
            "\t\t8000\t8547.376\t5.8722544e-05\n",
            "\t\t9000\t8106.843\t4.745958e-05\n",
            "\t\t10000\t7794.687\t3.3888624e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7794.687\t3.3888624e-05\n",
            "\n",
            "\tBest loss outter loop: 7794.68701171875\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17554.783]\n",
            "N =  0  J =  1 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16603.514\t0.00020616854\n",
            "\t\t2000\t14009.2\t0.00015709862\n",
            "\t\t3000\t12196.06\t0.00012497672\n",
            "\t\t4000\t10875.912\t0.00010253117\n",
            "\t\t5000\t9835.087\t9.4022325e-05\n",
            "\t\t6000\t8913.534\t0.00010297534\n",
            "\t\t7000\t8162.465\t7.8836965e-05\n",
            "\t\t8000\t7629.144\t5.8750476e-05\n",
            "\t\t9000\t7208.035\t4.6807007e-05\n",
            "\t\t10000\t6910.929\t3.553744e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t6910.929\t3.553744e-05\n",
            "\n",
            "\tBest loss: 6910.92919921875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17623.416\t0.00019612277\n",
            "\t\t2000\t15000.956\t0.00014899173\n",
            "\t\t3000\t13155.792\t0.000118458025\n",
            "\t\t4000\t11816.713\t9.676498e-05\n",
            "\t\t5000\t10775.284\t8.89906e-05\n",
            "\t\t6000\t9901.807\t7.968239e-05\n",
            "\t\t7000\t9167.299\t7.775848e-05\n",
            "\t\t8000\t8526.654\t6.436203e-05\n",
            "\t\t9000\t8082.34\t4.6334895e-05\n",
            "\t\t10000\t7766.444\t3.514345e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7766.444\t3.514345e-05\n",
            "\n",
            "\tBest loss outter loop: 7766.44384765625\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17005.613]\n",
            "N =  0  J =  2 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16405.475\t0.00020151652\n",
            "\t\t2000\t13900.624\t0.000151794\n",
            "\t\t3000\t12110.976\t0.00012553215\n",
            "\t\t4000\t10805.102\t0.000102931954\n",
            "\t\t5000\t9828.86\t8.64328e-05\n",
            "\t\t6000\t9015.0205\t8.881956e-05\n",
            "\t\t7000\t8283.905\t7.791706e-05\n",
            "\t\t8000\t7728.4473\t6.387063e-05\n",
            "\t\t9000\t7329.7437\t4.5363722e-05\n",
            "\t\t10000\t7025.2373\t3.488973e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7025.2373\t3.488973e-05\n",
            "\n",
            "\tBest loss: 7025.2373046875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17715.588\t0.0001956536\n",
            "\t\t2000\t15056.107\t0.000149289\n",
            "\t\t3000\t13201.789\t0.00011841512\n",
            "\t\t4000\t11858.278\t9.6425836e-05\n",
            "\t\t5000\t10795.559\t9.153679e-05\n",
            "\t\t6000\t9876.581\t8.3049425e-05\n",
            "\t\t7000\t9100.571\t7.639734e-05\n",
            "\t\t8000\t8510.261\t6.001127e-05\n",
            "\t\t9000\t8094.928\t4.5961275e-05\n",
            "\t\t10000\t7764.461\t3.3957658e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7764.461\t3.3957658e-05\n",
            "\n",
            "\tBest loss outter loop: 7764.4609375\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17375.504]\n",
            "N =  0  J =  3 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16510.207\t0.00019941072\n",
            "\t\t2000\t14023.657\t0.00014879169\n",
            "\t\t3000\t12295.402\t0.00011824986\n",
            "\t\t4000\t11033.301\t0.00010053777\n",
            "\t\t5000\t10010.869\t9.5004885e-05\n",
            "\t\t6000\t9139.586\t8.9425244e-05\n",
            "\t\t7000\t8424.089\t7.128879e-05\n",
            "\t\t8000\t7882.7217\t5.5993547e-05\n",
            "\t\t9000\t7495.7573\t4.4489334e-05\n",
            "\t\t10000\t7201.037\t3.2478532e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7201.037\t3.2478532e-05\n",
            "\n",
            "\tBest loss: 7201.037109375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17623.717\t0.00019545475\n",
            "\t\t2000\t15001.637\t0.0001483342\n",
            "\t\t3000\t13168.082\t0.00011693875\n",
            "\t\t4000\t11849.174\t9.592312e-05\n",
            "\t\t5000\t10805.65\t9.262597e-05\n",
            "\t\t6000\t9866.908\t8.362562e-05\n",
            "\t\t7000\t9090.938\t7.5619035e-05\n",
            "\t\t8000\t8513.513\t5.8497328e-05\n",
            "\t\t9000\t8074.4043\t4.765024e-05\n",
            "\t\t10000\t7743.633\t3.392289e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7743.633\t3.392289e-05\n",
            "\n",
            "\tBest loss outter loop: 7743.6328125\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17096.797]\n",
            "N =  0  J =  4 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16118.404\t0.00019287116\n",
            "\t\t2000\t13739.212\t0.00014433959\n",
            "\t\t3000\t12111.581\t0.00011182196\n",
            "\t\t4000\t10943.298\t9.4405324e-05\n",
            "\t\t5000\t9931.8955\t9.477718e-05\n",
            "\t\t6000\t9065.741\t9.12306e-05\n",
            "\t\t7000\t8338.263\t7.436454e-05\n",
            "\t\t8000\t7810.4624\t5.6449036e-05\n",
            "\t\t9000\t7414.968\t4.464482e-05\n",
            "\t\t10000\t7110.348\t3.660079e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7110.348\t3.660079e-05\n",
            "\n",
            "\tBest loss: 7110.34814453125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17490.543\t0.00019448693\n",
            "\t\t2000\t14888.365\t0.00014808554\n",
            "\t\t3000\t13079.788\t0.000117354815\n",
            "\t\t4000\t11755.354\t9.918034e-05\n",
            "\t\t5000\t10718.511\t9.183035e-05\n",
            "\t\t6000\t9815.263\t8.5756714e-05\n",
            "\t\t7000\t9026.311\t8.0920065e-05\n",
            "\t\t8000\t8426.953\t5.909816e-05\n",
            "\t\t9000\t8006.1416\t4.4580487e-05\n",
            "\t\t10000\t7689.4287\t3.6828835e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7689.4287\t3.6828835e-05\n",
            "\n",
            "\tBest loss outter loop: 7689.4287109375\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17010.645]\n",
            "N =  0  J =  5 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17829.607\t0.0001906796\n",
            "\t\t2000\t15246.7705\t0.00014249195\n",
            "\t\t3000\t13420.292\t0.00011234056\n",
            "\t\t4000\t12086.24\t9.6546115e-05\n",
            "\t\t5000\t11014.466\t9.450456e-05\n",
            "\t\t6000\t10058.704\t8.416675e-05\n",
            "\t\t7000\t9285.074\t7.21452e-05\n",
            "\t\t8000\t8724.523\t5.2493844e-05\n",
            "\t\t9000\t8322.14\t4.1186442e-05\n",
            "\t\t10000\t7992.8286\t4.2150266e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7992.8286\t4.2150266e-05\n",
            "\n",
            "\tBest loss: 7992.82861328125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17776.758\t0.0001958591\n",
            "\t\t2000\t15127.336\t0.00014671459\n",
            "\t\t3000\t13252.441\t0.000119141325\n",
            "\t\t4000\t11868.496\t0.00010267728\n",
            "\t\t5000\t10783.053\t8.974143e-05\n",
            "\t\t6000\t9894.578\t8.260234e-05\n",
            "\t\t7000\t9123.689\t7.556165e-05\n",
            "\t\t8000\t8534.913\t6.3155705e-05\n",
            "\t\t9000\t8108.4287\t4.227193e-05\n",
            "\t\t10000\t7764.3564\t3.798263e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7764.3564\t3.798263e-05\n",
            "\n",
            "\tBest loss outter loop: 7764.3564453125\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17087.74]\n",
            "N =  0  J =  6 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18559.643\t0.00018728331\n",
            "\t\t2000\t15891.101\t0.000142183\n",
            "\t\t3000\t14008.597\t0.0001151504\n",
            "\t\t4000\t12595.225\t9.814885e-05\n",
            "\t\t5000\t11420.783\t9.379292e-05\n",
            "\t\t6000\t10404.158\t9.6669246e-05\n",
            "\t\t7000\t9570.149\t7.438349e-05\n",
            "\t\t8000\t8936.1045\t5.7807258e-05\n",
            "\t\t9000\t8460.052\t4.674786e-05\n",
            "\t\t10000\t8122.0054\t3.7812988e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8122.0054\t3.7812988e-05\n",
            "\n",
            "\tBest loss: 8122.00537109375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17701.734\t0.00019382143\n",
            "\t\t2000\t15073.387\t0.00014847021\n",
            "\t\t3000\t13219.673\t0.00011818109\n",
            "\t\t4000\t11846.759\t0.00010393706\n",
            "\t\t5000\t10779.594\t8.759637e-05\n",
            "\t\t6000\t9865.248\t8.5124295e-05\n",
            "\t\t7000\t9102.058\t7.359573e-05\n",
            "\t\t8000\t8489.994\t6.6940134e-05\n",
            "\t\t9000\t8013.155\t5.3437103e-05\n",
            "\t\t10000\t7628.27\t4.064434e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7628.27\t4.064434e-05\n",
            "\n",
            "\tBest loss outter loop: 7628.27001953125\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17411.424]\n",
            "N =  0  J =  7 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19268.227\t0.00019032735\n",
            "\t\t2000\t16447.254\t0.00014663576\n",
            "\t\t3000\t14414.592\t0.0001190194\n",
            "\t\t4000\t12884.762\t0.00010693115\n",
            "\t\t5000\t11645.46\t9.625947e-05\n",
            "\t\t6000\t10651.924\t8.433798e-05\n",
            "\t\t7000\t9817.74\t7.80772e-05\n",
            "\t\t8000\t9119.152\t6.84253e-05\n",
            "\t\t9000\t8571.269\t5.4229844e-05\n",
            "\t\t10000\t8193.747\t3.9686653e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8193.747\t3.9686653e-05\n",
            "\n",
            "\tBest loss: 8193.7470703125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17727.291\t0.00019431299\n",
            "\t\t2000\t15060.38\t0.00015021901\n",
            "\t\t3000\t13211.078\t0.00011796236\n",
            "\t\t4000\t11882.158\t9.541035e-05\n",
            "\t\t5000\t10807.583\t9.513899e-05\n",
            "\t\t6000\t9893.677\t9.050495e-05\n",
            "\t\t7000\t9119.02\t7.217395e-05\n",
            "\t\t8000\t8527.844\t6.0574548e-05\n",
            "\t\t9000\t8101.134\t4.3214015e-05\n",
            "\t\t10000\t7780.0566\t3.960039e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7780.0566\t3.960039e-05\n",
            "\n",
            "\tBest loss outter loop: 7780.056640625\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17012.244]\n",
            "N =  0  J =  8 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19448.408\t0.00019398531\n",
            "\t\t2000\t16568.705\t0.00014803582\n",
            "\t\t3000\t14458.583\t0.00012432947\n",
            "\t\t4000\t12922.969\t9.860648e-05\n",
            "\t\t5000\t11773.946\t8.8823705e-05\n",
            "\t\t6000\t10752.293\t9.263154e-05\n",
            "\t\t7000\t9811.4375\t8.091384e-05\n",
            "\t\t8000\t9109.592\t6.7639616e-05\n",
            "\t\t9000\t8559.364\t5.2708132e-05\n",
            "\t\t10000\t8159.9756\t4.583424e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8159.9756\t4.583424e-05\n",
            "\n",
            "\tBest loss: 8159.9755859375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17750.986\t0.00019647335\n",
            "\t\t2000\t15090.764\t0.00014939906\n",
            "\t\t3000\t13224.775\t0.000119390534\n",
            "\t\t4000\t11874.071\t9.6462056e-05\n",
            "\t\t5000\t10799.454\t9.186542e-05\n",
            "\t\t6000\t9859.654\t8.477647e-05\n",
            "\t\t7000\t9115.876\t6.823566e-05\n",
            "\t\t8000\t8538.133\t5.5927023e-05\n",
            "\t\t9000\t8130.646\t4.083534e-05\n",
            "\t\t10000\t7793.5376\t4.4418342e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7793.5376\t4.4418342e-05\n",
            "\n",
            "\tBest loss outter loop: 7793.53759765625\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17470.998]\n",
            "N =  0  J =  9 I =  2\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19627.896\t0.00019877667\n",
            "\t\t2000\t16568.11\t0.00015794042\n",
            "\t\t3000\t14390.396\t0.00012675032\n",
            "\t\t4000\t12797.297\t0.0001088826\n",
            "\t\t5000\t11578.261\t9.0746435e-05\n",
            "\t\t6000\t10610.999\t8.549138e-05\n",
            "\t\t7000\t9718.447\t7.7568744e-05\n",
            "\t\t8000\t9066.579\t5.7190813e-05\n",
            "\t\t9000\t8609.171\t4.5371067e-05\n",
            "\t\t10000\t8245.603\t5.4832093e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8245.603\t5.4832093e-05\n",
            "\n",
            "\tBest loss: 8245.6025390625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17630.787\t0.00019570859\n",
            "\t\t2000\t14997.439\t0.0001501984\n",
            "\t\t3000\t13159.085\t0.00011776063\n",
            "\t\t4000\t11823.566\t9.720437e-05\n",
            "\t\t5000\t10758.1875\t9.067489e-05\n",
            "\t\t6000\t9855.473\t9.273809e-05\n",
            "\t\t7000\t9050.766\t7.6601944e-05\n",
            "\t\t8000\t8479.224\t6.633422e-05\n",
            "\t\t9000\t8038.0522\t4.6347213e-05\n",
            "\t\t10000\t7734.4536\t3.4720662e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7734.4536\t3.4720662e-05\n",
            "\n",
            "\tBest loss outter loop: 7734.45361328125\n",
            "\n",
            "OUTTER FOLDER: 2 OUTTER MSE:  [17318.537]\n",
            "N =  0  J =  0 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16903.246\t0.00019442836\n",
            "\t\t2000\t14387.589\t0.00014529999\n",
            "\t\t3000\t12658.406\t0.00011547625\n",
            "\t\t4000\t11378.068\t9.92079e-05\n",
            "\t\t5000\t10322.055\t0.00010358647\n",
            "\t\t6000\t9325.53\t0.00010219554\n",
            "\t\t7000\t8521.771\t8.467941e-05\n",
            "\t\t8000\t7867.9497\t7.521049e-05\n",
            "\t\t9000\t7356.618\t5.966582e-05\n",
            "\t\t10000\t6926.4355\t5.4278447e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t6926.4355\t5.4278447e-05\n",
            "\n",
            "\tBest loss: 6926.435546875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17665.213\t0.00019499571\n",
            "\t\t2000\t15017.231\t0.00014792015\n",
            "\t\t3000\t13176.381\t0.0001193844\n",
            "\t\t4000\t11830.977\t9.796876e-05\n",
            "\t\t5000\t10759.988\t9.229308e-05\n",
            "\t\t6000\t9813.252\t9.2739065e-05\n",
            "\t\t7000\t9044.991\t7.244075e-05\n",
            "\t\t8000\t8496.241\t6.0799845e-05\n",
            "\t\t9000\t8077.278\t4.400655e-05\n",
            "\t\t10000\t7735.2676\t3.4022694e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7735.2676\t3.4022694e-05\n",
            "\n",
            "\tBest loss outter loop: 7735.267578125\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [18093.28]\n",
            "N =  0  J =  1 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16677.57\t0.00020736037\n",
            "\t\t2000\t14043.098\t0.00015539862\n",
            "\t\t3000\t12227.759\t0.00012385433\n",
            "\t\t4000\t10892.961\t0.000109182736\n",
            "\t\t5000\t9839.737\t9.824469e-05\n",
            "\t\t6000\t8972.727\t8.6735374e-05\n",
            "\t\t7000\t8281.15\t7.1222195e-05\n",
            "\t\t8000\t7767.873\t5.5752884e-05\n",
            "\t\t9000\t7377.315\t5.2946678e-05\n",
            "\t\t10000\t7070.087\t3.356348e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7070.087\t3.356348e-05\n",
            "\n",
            "\tBest loss: 7070.0869140625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17680.803\t0.00019570718\n",
            "\t\t2000\t15024.04\t0.00014752822\n",
            "\t\t3000\t13201.147\t0.00011627608\n",
            "\t\t4000\t11862.27\t9.7628035e-05\n",
            "\t\t5000\t10798.491\t9.422448e-05\n",
            "\t\t6000\t9835.923\t8.954731e-05\n",
            "\t\t7000\t9045.6045\t8.301427e-05\n",
            "\t\t8000\t8417.618\t6.28757e-05\n",
            "\t\t9000\t7980.3086\t4.203285e-05\n",
            "\t\t10000\t7677.1724\t3.7523598e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7677.1724\t3.7523598e-05\n",
            "\n",
            "\tBest loss outter loop: 7677.17236328125\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [17578.139]\n",
            "N =  0  J =  2 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16247.971\t0.00020611307\n",
            "\t\t2000\t13722.472\t0.00015262606\n",
            "\t\t3000\t11942.582\t0.0001249312\n",
            "\t\t4000\t10642.677\t0.00010670445\n",
            "\t\t5000\t9644.617\t8.656525e-05\n",
            "\t\t6000\t8826.707\t8.839134e-05\n",
            "\t\t7000\t8106.8354\t7.895636e-05\n",
            "\t\t8000\t7527.1724\t7.128611e-05\n",
            "\t\t9000\t7073.0913\t5.1151314e-05\n",
            "\t\t10000\t6762.128\t4.0579376e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t6762.128\t4.0579376e-05\n",
            "\n",
            "\tBest loss: 6762.1279296875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17812.844\t0.00019612002\n",
            "\t\t2000\t15135.549\t0.00014824755\n",
            "\t\t3000\t13260.399\t0.00011877532\n",
            "\t\t4000\t11886.568\t0.0001011248\n",
            "\t\t5000\t10817.193\t9.054137e-05\n",
            "\t\t6000\t9930.909\t7.856402e-05\n",
            "\t\t7000\t9151.728\t7.479671e-05\n",
            "\t\t8000\t8548.858\t6.1453626e-05\n",
            "\t\t9000\t8062.21\t4.826733e-05\n",
            "\t\t10000\t7766.5146\t2.9862387e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7766.5146\t2.9862387e-05\n",
            "\n",
            "\tBest loss outter loop: 7766.5146484375\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [18168.713]\n",
            "N =  0  J =  3 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16761.17\t0.00019700795\n",
            "\t\t2000\t14250.478\t0.0001466978\n",
            "\t\t3000\t12522.447\t0.000115170515\n",
            "\t\t4000\t11248.001\t0.00010235146\n",
            "\t\t5000\t10203.437\t9.397758e-05\n",
            "\t\t6000\t9321.511\t8.9041816e-05\n",
            "\t\t7000\t8588.615\t7.310652e-05\n",
            "\t\t8000\t8030.1978\t6.0133152e-05\n",
            "\t\t9000\t7627.1\t4.423535e-05\n",
            "\t\t10000\t7334.5254\t3.5482142e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7334.5254\t3.5482142e-05\n",
            "\n",
            "\tBest loss: 7334.525390625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17849.898\t0.00019593173\n",
            "\t\t2000\t15149.393\t0.00014978761\n",
            "\t\t3000\t13273.232\t0.00011851339\n",
            "\t\t4000\t11905.26\t0.00010170415\n",
            "\t\t5000\t10805.511\t9.109105e-05\n",
            "\t\t6000\t9872.966\t9.128816e-05\n",
            "\t\t7000\t9090.545\t6.907026e-05\n",
            "\t\t8000\t8531.826\t6.0202932e-05\n",
            "\t\t9000\t8109.2246\t4.4495475e-05\n",
            "\t\t10000\t7801.8237\t3.3294393e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7801.8237\t3.3294393e-05\n",
            "\n",
            "\tBest loss outter loop: 7801.82373046875\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [17764.207]\n",
            "N =  0  J =  4 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16332.154\t0.00019512906\n",
            "\t\t2000\t13889.874\t0.00014474221\n",
            "\t\t3000\t12213.121\t0.00011424994\n",
            "\t\t4000\t11006.368\t9.342085e-05\n",
            "\t\t5000\t10031.483\t9.344704e-05\n",
            "\t\t6000\t9170.696\t8.209495e-05\n",
            "\t\t7000\t8462.096\t7.212251e-05\n",
            "\t\t8000\t7881.5728\t6.603675e-05\n",
            "\t\t9000\t7418.5444\t6.1405364e-05\n",
            "\t\t10000\t7066.816\t4.580785e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7066.816\t4.580785e-05\n",
            "\n",
            "\tBest loss: 7066.81591796875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17666.562\t0.00019586491\n",
            "\t\t2000\t15009.338\t0.00014721739\n",
            "\t\t3000\t13182.151\t0.0001175546\n",
            "\t\t4000\t11847.813\t9.601654e-05\n",
            "\t\t5000\t10809.314\t8.871046e-05\n",
            "\t\t6000\t9904.229\t8.3014784e-05\n",
            "\t\t7000\t9083.113\t7.837162e-05\n",
            "\t\t8000\t8492.963\t6.32377e-05\n",
            "\t\t9000\t8067.9297\t4.2484116e-05\n",
            "\t\t10000\t7750.6245\t3.7608963e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7750.6245\t3.7608963e-05\n",
            "\n",
            "\tBest loss outter loop: 7750.62451171875\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [18000.246]\n",
            "N =  0  J =  5 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17982.814\t0.00019328957\n",
            "\t\t2000\t15329.399\t0.00014325247\n",
            "\t\t3000\t13485.46\t0.000114114526\n",
            "\t\t4000\t12144.887\t9.6079944e-05\n",
            "\t\t5000\t11060.744\t8.74003e-05\n",
            "\t\t6000\t10094.926\t8.918444e-05\n",
            "\t\t7000\t9263.603\t7.7898796e-05\n",
            "\t\t8000\t8678.022\t5.7838533e-05\n",
            "\t\t9000\t8247.5205\t4.2861422e-05\n",
            "\t\t10000\t7917.779\t3.8479957e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7917.779\t3.8479957e-05\n",
            "\n",
            "\tBest loss: 7917.77880859375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17624.09\t0.00019456439\n",
            "\t\t2000\t14981.646\t0.00014625133\n",
            "\t\t3000\t13169.89\t0.000115736555\n",
            "\t\t4000\t11823.535\t0.00010182901\n",
            "\t\t5000\t10747.497\t9.3581344e-05\n",
            "\t\t6000\t9847.695\t8.07151e-05\n",
            "\t\t7000\t9092.969\t7.4743104e-05\n",
            "\t\t8000\t8500.201\t6.0771523e-05\n",
            "\t\t9000\t8074.1626\t4.3418833e-05\n",
            "\t\t10000\t7762.3535\t3.1387994e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7762.3535\t3.1387994e-05\n",
            "\n",
            "\tBest loss outter loop: 7762.353515625\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [17417.63]\n",
            "N =  0  J =  6 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18690.973\t0.00018931025\n",
            "\t\t2000\t15972.433\t0.00014390402\n",
            "\t\t3000\t14049.658\t0.00011585627\n",
            "\t\t4000\t12610.768\t9.996347e-05\n",
            "\t\t5000\t11486.479\t8.764633e-05\n",
            "\t\t6000\t10431.208\t9.950742e-05\n",
            "\t\t7000\t9556.417\t8.041642e-05\n",
            "\t\t8000\t8926.76\t5.8086538e-05\n",
            "\t\t9000\t8450.108\t4.437616e-05\n",
            "\t\t10000\t8095.5586\t3.5282857e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8095.5586\t3.5282857e-05\n",
            "\n",
            "\tBest loss: 8095.55859375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17854.28\t0.00019544626\n",
            "\t\t2000\t15159.519\t0.00014975197\n",
            "\t\t3000\t13279.802\t0.00011926349\n",
            "\t\t4000\t11926.47\t9.60383e-05\n",
            "\t\t5000\t10868.412\t9.209113e-05\n",
            "\t\t6000\t9933.376\t8.581835e-05\n",
            "\t\t7000\t9103.22\t7.991468e-05\n",
            "\t\t8000\t8495.947\t6.218111e-05\n",
            "\t\t9000\t8036.622\t4.9757527e-05\n",
            "\t\t10000\t7671.672\t4.2323667e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7671.672\t4.2323667e-05\n",
            "\n",
            "\tBest loss outter loop: 7671.671875\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [17752.271]\n",
            "N =  0  J =  7 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19157.195\t0.00019041111\n",
            "\t\t2000\t16341.097\t0.00014681155\n",
            "\t\t3000\t14346.119\t0.000118566575\n",
            "\t\t4000\t12851.539\t0.00010318103\n",
            "\t\t5000\t11630.843\t9.604465e-05\n",
            "\t\t6000\t10628.231\t8.728201e-05\n",
            "\t\t7000\t9766.886\t7.8583675e-05\n",
            "\t\t8000\t9100.578\t6.352215e-05\n",
            "\t\t9000\t8594.865\t5.6353147e-05\n",
            "\t\t10000\t8202.785\t3.9881015e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8202.785\t3.9881015e-05\n",
            "\n",
            "\tBest loss: 8202.78515625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17761.13\t0.00019526194\n",
            "\t\t2000\t15093.758\t0.00014691157\n",
            "\t\t3000\t13246.253\t0.000115806484\n",
            "\t\t4000\t11882.353\t9.8202574e-05\n",
            "\t\t5000\t10816.1\t8.892563e-05\n",
            "\t\t6000\t9893.338\t8.695516e-05\n",
            "\t\t7000\t9158.062\t7.474498e-05\n",
            "\t\t8000\t8527.3125\t6.596016e-05\n",
            "\t\t9000\t8055.3384\t5.103595e-05\n",
            "\t\t10000\t7694.768\t4.061036e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7694.768\t4.061036e-05\n",
            "\n",
            "\tBest loss outter loop: 7694.76806640625\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [17439.828]\n",
            "N =  0  J =  8 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19175.049\t0.0001915575\n",
            "\t\t2000\t16309.376\t0.00014769565\n",
            "\t\t3000\t14300.922\t0.00011914606\n",
            "\t\t4000\t12801.143\t0.00010221431\n",
            "\t\t5000\t11607.775\t9.497378e-05\n",
            "\t\t6000\t10613.345\t8.400054e-05\n",
            "\t\t7000\t9729.381\t7.888658e-05\n",
            "\t\t8000\t9049.672\t6.6145294e-05\n",
            "\t\t9000\t8549.526\t4.8999766e-05\n",
            "\t\t10000\t8158.28\t4.081672e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8158.28\t4.081672e-05\n",
            "\n",
            "\tBest loss: 8158.27978515625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17765.09\t0.00019609761\n",
            "\t\t2000\t15089.644\t0.00014953954\n",
            "\t\t3000\t13227.716\t0.000116485426\n",
            "\t\t4000\t11874.214\t0.00010303897\n",
            "\t\t5000\t10833.758\t8.454483e-05\n",
            "\t\t6000\t9936.738\t8.942496e-05\n",
            "\t\t7000\t9144.454\t7.635107e-05\n",
            "\t\t8000\t8509.654\t6.3343155e-05\n",
            "\t\t9000\t8052.9487\t4.668588e-05\n",
            "\t\t10000\t7717.3877\t3.4607645e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7717.3877\t3.4607645e-05\n",
            "\n",
            "\tBest loss outter loop: 7717.3876953125\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [17525.506]\n",
            "N =  0  J =  9 I =  3\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19504.23\t0.0001974342\n",
            "\t\t2000\t16485.557\t0.00015541493\n",
            "\t\t3000\t14342.64\t0.00012499405\n",
            "\t\t4000\t12771.76\t0.00010818293\n",
            "\t\t5000\t11569.85\t9.815432e-05\n",
            "\t\t6000\t10557.725\t8.472048e-05\n",
            "\t\t7000\t9721.918\t7.322238e-05\n",
            "\t\t8000\t9127.171\t5.4136584e-05\n",
            "\t\t9000\t8704.938\t3.915099e-05\n",
            "\t\t10000\t8365.356\t4.02733e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8365.356\t4.02733e-05\n",
            "\n",
            "\tBest loss: 8365.3564453125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17661.475\t0.00019514751\n",
            "\t\t2000\t15006.543\t0.00014880617\n",
            "\t\t3000\t13188.723\t0.00011520116\n",
            "\t\t4000\t11832.656\t0.00010001773\n",
            "\t\t5000\t10792.53\t8.6134336e-05\n",
            "\t\t6000\t9911.721\t8.374012e-05\n",
            "\t\t7000\t9145.095\t7.0900474e-05\n",
            "\t\t8000\t8544.819\t6.033994e-05\n",
            "\t\t9000\t8083.754\t4.7474336e-05\n",
            "\t\t10000\t7742.0586\t3.859653e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7742.0586\t3.859653e-05\n",
            "\n",
            "\tBest loss outter loop: 7742.05859375\n",
            "\n",
            "OUTTER FOLDER: 3 OUTTER MSE:  [17682.889]\n",
            "N =  0  J =  0 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17090.604\t0.00018624275\n",
            "\t\t2000\t14637.59\t0.00013935045\n",
            "\t\t3000\t12955.665\t0.00011041549\n",
            "\t\t4000\t11695.173\t9.384669e-05\n",
            "\t\t5000\t10663.206\t9.010901e-05\n",
            "\t\t6000\t9736.354\t9.056328e-05\n",
            "\t\t7000\t8890.32\t8.226758e-05\n",
            "\t\t8000\t8256.48\t6.339315e-05\n",
            "\t\t9000\t7769.7686\t5.54251e-05\n",
            "\t\t10000\t7347.939\t5.069989e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7347.939\t5.069989e-05\n",
            "\n",
            "\tBest loss: 7347.93896484375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17707.525\t0.00018791444\n",
            "\t\t2000\t15153.272\t0.00014176033\n",
            "\t\t3000\t13375.022\t0.00011366972\n",
            "\t\t4000\t12064.726\t9.186257e-05\n",
            "\t\t5000\t11060.302\t9.128806e-05\n",
            "\t\t6000\t10088.528\t8.4789e-05\n",
            "\t\t7000\t9343.99\t7.5347736e-05\n",
            "\t\t8000\t8760.981\t5.8628335e-05\n",
            "\t\t9000\t8297.544\t4.5309735e-05\n",
            "\t\t10000\t7933.2573\t4.222059e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7933.2573\t4.222059e-05\n",
            "\n",
            "\tBest loss outter loop: 7933.25732421875\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14660.121]\n",
            "N =  0  J =  1 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16569.445\t0.0001977553\n",
            "\t\t2000\t14077.536\t0.00014898514\n",
            "\t\t3000\t12367.394\t0.00011732477\n",
            "\t\t4000\t11115.819\t9.9088815e-05\n",
            "\t\t5000\t10111.803\t8.671817e-05\n",
            "\t\t6000\t9218.939\t8.6537344e-05\n",
            "\t\t7000\t8532.5\t7.5189375e-05\n",
            "\t\t8000\t7965.9966\t6.110807e-05\n",
            "\t\t9000\t7490.0337\t6.355699e-05\n",
            "\t\t10000\t7103.0386\t4.529931e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7103.0386\t4.529931e-05\n",
            "\n",
            "\tBest loss: 7103.03857421875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17674.04\t0.00018871226\n",
            "\t\t2000\t15117.644\t0.00014241728\n",
            "\t\t3000\t13348.624\t0.00011213908\n",
            "\t\t4000\t12056.33\t9.297933e-05\n",
            "\t\t5000\t11030.024\t8.605031e-05\n",
            "\t\t6000\t10103.448\t8.8529385e-05\n",
            "\t\t7000\t9314.141\t7.800031e-05\n",
            "\t\t8000\t8711.832\t6.232155e-05\n",
            "\t\t9000\t8268.64\t4.3578613e-05\n",
            "\t\t10000\t7966.737\t3.1318206e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7966.737\t3.1318206e-05\n",
            "\n",
            "\tBest loss outter loop: 7966.73681640625\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14619.607]\n",
            "N =  0  J =  2 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t15891.548\t0.0001951325\n",
            "\t\t2000\t13556.817\t0.00014534508\n",
            "\t\t3000\t11930.245\t0.00011564919\n",
            "\t\t4000\t10731.847\t9.5264455e-05\n",
            "\t\t5000\t9774.883\t9.120521e-05\n",
            "\t\t6000\t8943.323\t8.494617e-05\n",
            "\t\t7000\t8283.206\t7.603758e-05\n",
            "\t\t8000\t7738.5513\t6.126367e-05\n",
            "\t\t9000\t7329.24\t4.6965593e-05\n",
            "\t\t10000\t7019.193\t4.5075267e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7019.193\t4.5075267e-05\n",
            "\n",
            "\tBest loss: 7019.19287109375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17808.56\t0.00018805447\n",
            "\t\t2000\t15229.3\t0.00014195022\n",
            "\t\t3000\t13452.353\t0.000113379254\n",
            "\t\t4000\t12123.9\t9.7051576e-05\n",
            "\t\t5000\t11055.999\t8.9292385e-05\n",
            "\t\t6000\t10156.527\t8.07605e-05\n",
            "\t\t7000\t9386.661\t7.8645986e-05\n",
            "\t\t8000\t8750.778\t6.0147282e-05\n",
            "\t\t9000\t8281.872\t5.282343e-05\n",
            "\t\t10000\t7907.243\t4.0445357e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7907.243\t4.0445357e-05\n",
            "\n",
            "\tBest loss outter loop: 7907.2431640625\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14694.652]\n",
            "N =  0  J =  3 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16379.644\t0.00019206035\n",
            "\t\t2000\t13994.831\t0.00014379637\n",
            "\t\t3000\t12354.15\t0.000112708774\n",
            "\t\t4000\t11134.487\t9.7431985e-05\n",
            "\t\t5000\t10134.361\t8.931915e-05\n",
            "\t\t6000\t9262.66\t8.6339736e-05\n",
            "\t\t7000\t8588.71\t6.7193985e-05\n",
            "\t\t8000\t8031.718\t5.714321e-05\n",
            "\t\t9000\t7621.1\t4.856244e-05\n",
            "\t\t10000\t7290.938\t4.500247e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7290.938\t4.500247e-05\n",
            "\n",
            "\tBest loss: 7290.93798828125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17656.55\t0.00018735108\n",
            "\t\t2000\t15107.054\t0.00014064298\n",
            "\t\t3000\t13359.595\t0.0001124855\n",
            "\t\t4000\t12076.1875\t9.112857e-05\n",
            "\t\t5000\t11047.98\t9.059446e-05\n",
            "\t\t6000\t10103.75\t8.5917556e-05\n",
            "\t\t7000\t9307.602\t7.721587e-05\n",
            "\t\t8000\t8666.088\t6.355189e-05\n",
            "\t\t9000\t8170.017\t5.701258e-05\n",
            "\t\t10000\t7806.3853\t4.6534256e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7806.3853\t4.6534256e-05\n",
            "\n",
            "\tBest loss outter loop: 7806.38525390625\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14624.031]\n",
            "N =  0  J =  4 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t16344.236\t0.00018978862\n",
            "\t\t2000\t13977.152\t0.00013706318\n",
            "\t\t3000\t12395.663\t0.000106660256\n",
            "\t\t4000\t11244.712\t9.1614536e-05\n",
            "\t\t5000\t10243.008\t9.361455e-05\n",
            "\t\t6000\t9383.726\t9.0948735e-05\n",
            "\t\t7000\t8615.753\t7.9676e-05\n",
            "\t\t8000\t8011.7656\t6.088087e-05\n",
            "\t\t9000\t7586.448\t4.8784244e-05\n",
            "\t\t10000\t7191.7246\t4.969658e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7191.7246\t4.969658e-05\n",
            "\n",
            "\tBest loss: 7191.724609375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18033.42\t0.00019014892\n",
            "\t\t2000\t15388.374\t0.00014441651\n",
            "\t\t3000\t13524.349\t0.00011624093\n",
            "\t\t4000\t12192.065\t9.3946364e-05\n",
            "\t\t5000\t11120.273\t9.228842e-05\n",
            "\t\t6000\t10179.381\t8.2305756e-05\n",
            "\t\t7000\t9414.416\t7.1257804e-05\n",
            "\t\t8000\t8849.52\t5.693841e-05\n",
            "\t\t9000\t8395.498\t4.827038e-05\n",
            "\t\t10000\t7982.1387\t4.581553e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7982.1387\t4.581553e-05\n",
            "\n",
            "\tBest loss outter loop: 7982.138671875\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14518.011]\n",
            "N =  0  J =  5 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17898.877\t0.00018328795\n",
            "\t\t2000\t15374.092\t0.00013889898\n",
            "\t\t3000\t13630.751\t0.0001078127\n",
            "\t\t4000\t12328.64\t9.520242e-05\n",
            "\t\t5000\t11235.445\t8.9343725e-05\n",
            "\t\t6000\t10287.982\t9.026329e-05\n",
            "\t\t7000\t9430.024\t7.994104e-05\n",
            "\t\t8000\t8756.649\t7.014266e-05\n",
            "\t\t9000\t8255.609\t4.8851707e-05\n",
            "\t\t10000\t7896.748\t3.8458777e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7896.748\t3.8458777e-05\n",
            "\n",
            "\tBest loss: 7896.748046875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17841.045\t0.00018902532\n",
            "\t\t2000\t15246.35\t0.00014275202\n",
            "\t\t3000\t13438.101\t0.00011429869\n",
            "\t\t4000\t12120.095\t9.4584735e-05\n",
            "\t\t5000\t11059.274\t9.209111e-05\n",
            "\t\t6000\t10086.993\t8.6157066e-05\n",
            "\t\t7000\t9285.209\t7.6560806e-05\n",
            "\t\t8000\t8676.539\t6.527594e-05\n",
            "\t\t9000\t8225.449\t5.0455375e-05\n",
            "\t\t10000\t7857.6704\t4.1694682e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7857.6704\t4.1694682e-05\n",
            "\n",
            "\tBest loss outter loop: 7857.67041015625\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14587.206]\n",
            "N =  0  J =  6 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18405.37\t0.00017973011\n",
            "\t\t2000\t15853.926\t0.00013106235\n",
            "\t\t3000\t14093.858\t0.00011008958\n",
            "\t\t4000\t12717.238\t9.52111e-05\n",
            "\t\t5000\t11586.607\t9.177656e-05\n",
            "\t\t6000\t10593.215\t8.69253e-05\n",
            "\t\t7000\t9752.549\t7.849895e-05\n",
            "\t\t8000\t9083.21\t6.224611e-05\n",
            "\t\t9000\t8586.842\t5.1174884e-05\n",
            "\t\t10000\t8228.649\t3.5364897e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8228.649\t3.5364897e-05\n",
            "\n",
            "\tBest loss: 8228.6494140625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17704.066\t0.00018773058\n",
            "\t\t2000\t15150.81\t0.00014242776\n",
            "\t\t3000\t13363.818\t0.0001128883\n",
            "\t\t4000\t12071.99\t9.318224e-05\n",
            "\t\t5000\t11027.867\t9.067114e-05\n",
            "\t\t6000\t10121.825\t8.344899e-05\n",
            "\t\t7000\t9326.972\t7.6427394e-05\n",
            "\t\t8000\t8672.52\t6.5193606e-05\n",
            "\t\t9000\t8216.281\t5.170012e-05\n",
            "\t\t10000\t7841.855\t4.0782594e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7841.855\t4.0782594e-05\n",
            "\n",
            "\tBest loss outter loop: 7841.85498046875\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14660.076]\n",
            "N =  0  J =  7 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19212.291\t0.00018417432\n",
            "\t\t2000\t16480.312\t0.00013994382\n",
            "\t\t3000\t14564.218\t0.00011162941\n",
            "\t\t4000\t13128.393\t9.579939e-05\n",
            "\t\t5000\t11917.322\t9.635779e-05\n",
            "\t\t6000\t10851.206\t8.8458e-05\n",
            "\t\t7000\t9980.144\t7.9644e-05\n",
            "\t\t8000\t9308.693\t6.294123e-05\n",
            "\t\t9000\t8815.685\t4.2757543e-05\n",
            "\t\t10000\t8449.737\t3.7906546e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8449.737\t3.7906546e-05\n",
            "\n",
            "\tBest loss: 8449.7373046875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17902.535\t0.00018957582\n",
            "\t\t2000\t15280.878\t0.00014409062\n",
            "\t\t3000\t13462.587\t0.00011271289\n",
            "\t\t4000\t12152.852\t9.2481954e-05\n",
            "\t\t5000\t11130.216\t8.746889e-05\n",
            "\t\t6000\t10206.098\t8.8021734e-05\n",
            "\t\t7000\t9392.561\t7.495813e-05\n",
            "\t\t8000\t8796.053\t5.7173478e-05\n",
            "\t\t9000\t8354.782\t4.7687477e-05\n",
            "\t\t10000\t8022.098\t3.5058176e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8022.098\t3.5058176e-05\n",
            "\n",
            "\tBest loss outter loop: 8022.09814453125\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14552.257]\n",
            "N =  0  J =  8 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19366.795\t0.00018512478\n",
            "\t\t2000\t16581.605\t0.00014544783\n",
            "\t\t3000\t14601.8955\t0.000115754425\n",
            "\t\t4000\t13156.872\t9.522099e-05\n",
            "\t\t5000\t11987.253\t9.718038e-05\n",
            "\t\t6000\t10923.969\t8.885204e-05\n",
            "\t\t7000\t10096.921\t7.195364e-05\n",
            "\t\t8000\t9418.304\t6.417858e-05\n",
            "\t\t9000\t8910.416\t4.6686506e-05\n",
            "\t\t10000\t8493.548\t4.0585226e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8493.548\t4.0585226e-05\n",
            "\n",
            "\tBest loss: 8493.5478515625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17772.877\t0.00018755315\n",
            "\t\t2000\t15188.982\t0.00014091289\n",
            "\t\t3000\t13403.274\t0.00011357583\n",
            "\t\t4000\t12097.81\t9.500107e-05\n",
            "\t\t5000\t11057.514\t8.875035e-05\n",
            "\t\t6000\t10154.811\t8.2024126e-05\n",
            "\t\t7000\t9394.527\t7.2448005e-05\n",
            "\t\t8000\t8848.737\t5.4405402e-05\n",
            "\t\t9000\t8386.047\t4.51809e-05\n",
            "\t\t10000\t7983.493\t4.5807756e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7983.493\t4.5807756e-05\n",
            "\n",
            "\tBest loss outter loop: 7983.4931640625\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14786.587]\n",
            "N =  0  J =  9 I =  4\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19735.836\t0.00019383169\n",
            "\t\t2000\t16759.28\t0.00015252749\n",
            "\t\t3000\t14645.344\t0.00012114424\n",
            "\t\t4000\t13112.975\t0.000101347476\n",
            "\t\t5000\t11910.413\t8.8297944e-05\n",
            "\t\t6000\t10910.751\t8.851222e-05\n",
            "\t\t7000\t10029.743\t7.681639e-05\n",
            "\t\t8000\t9287.775\t6.255732e-05\n",
            "\t\t9000\t8755.551\t5.4426793e-05\n",
            "\t\t10000\t8354.731\t3.588313e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8354.731\t3.588313e-05\n",
            "\n",
            "\tBest loss: 8354.7314453125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17766.281\t0.00018773266\n",
            "\t\t2000\t15187.69\t0.00014208193\n",
            "\t\t3000\t13393.019\t0.00011358989\n",
            "\t\t4000\t12099.122\t9.0068155e-05\n",
            "\t\t5000\t11033.341\t9.221906e-05\n",
            "\t\t6000\t10084.032\t8.6182365e-05\n",
            "\t\t7000\t9303.54\t6.717422e-05\n",
            "\t\t8000\t8742.351\t5.439728e-05\n",
            "\t\t9000\t8317.563\t4.1091702e-05\n",
            "\t\t10000\t7995.4224\t4.2502983e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7995.4224\t4.2502983e-05\n",
            "\n",
            "\tBest loss outter loop: 7995.42236328125\n",
            "\n",
            "OUTTER FOLDER: 4 OUTTER MSE:  [14579.094]\n",
            "N =  0  J =  0 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17900.0\t0.0001822948\n",
            "\t\t2000\t15398.682\t0.00013671177\n",
            "\t\t3000\t13672.292\t0.00010848492\n",
            "\t\t4000\t12351.815\t9.549809e-05\n",
            "\t\t5000\t11191.497\t0.00010190851\n",
            "\t\t6000\t10166.195\t9.451389e-05\n",
            "\t\t7000\t9310.625\t8.253917e-05\n",
            "\t\t8000\t8597.104\t7.451083e-05\n",
            "\t\t9000\t7965.7\t6.760709e-05\n",
            "\t\t10000\t7489.7964\t5.9321985e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7489.7964\t5.9321985e-05\n",
            "\n",
            "\tBest loss: 7489.79638671875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18672.455\t0.00018625658\n",
            "\t\t2000\t16004.214\t0.00014160524\n",
            "\t\t3000\t14127.184\t0.000109760804\n",
            "\t\t4000\t12782.51\t9.365559e-05\n",
            "\t\t5000\t11685.921\t8.8573644e-05\n",
            "\t\t6000\t10682.142\t8.446504e-05\n",
            "\t\t7000\t9884.172\t6.96496e-05\n",
            "\t\t8000\t9228.816\t7.385457e-05\n",
            "\t\t9000\t8722.833\t4.6347115e-05\n",
            "\t\t10000\t8330.924\t4.149465e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8330.924\t4.149465e-05\n",
            "\n",
            "\tBest loss outter loop: 8330.923828125\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11051.492]\n",
            "N =  0  J =  1 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17430.648\t0.00019470706\n",
            "\t\t2000\t14879.416\t0.00014292558\n",
            "\t\t3000\t13106.202\t0.00011235069\n",
            "\t\t4000\t11799.925\t9.764734e-05\n",
            "\t\t5000\t10730.657\t9.209038e-05\n",
            "\t\t6000\t9790.882\t8.427492e-05\n",
            "\t\t7000\t9005.7705\t7.806884e-05\n",
            "\t\t8000\t8370.96\t6.4742526e-05\n",
            "\t\t9000\t7861.29\t5.372408e-05\n",
            "\t\t10000\t7501.012\t4.5174154e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7501.012\t4.5174154e-05\n",
            "\n",
            "\tBest loss: 7501.01220703125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18703.893\t0.00018594359\n",
            "\t\t2000\t16023.148\t0.00013948818\n",
            "\t\t3000\t14166.887\t0.00010828163\n",
            "\t\t4000\t12807.239\t9.339853e-05\n",
            "\t\t5000\t11711.394\t8.846438e-05\n",
            "\t\t6000\t10731.124\t8.6991124e-05\n",
            "\t\t7000\t9934.6875\t7.1162875e-05\n",
            "\t\t8000\t9228.229\t6.772239e-05\n",
            "\t\t9000\t8682.452\t5.2523264e-05\n",
            "\t\t10000\t8268.312\t3.897447e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8268.312\t3.897447e-05\n",
            "\n",
            "\tBest loss outter loop: 8268.3115234375\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [10704.066]\n",
            "N =  0  J =  2 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17161.262\t0.00019309846\n",
            "\t\t2000\t14668.625\t0.00014404737\n",
            "\t\t3000\t12879.682\t0.000116297335\n",
            "\t\t4000\t11614.561\t9.222822e-05\n",
            "\t\t5000\t10603.098\t9.246148e-05\n",
            "\t\t6000\t9692.395\t8.482897e-05\n",
            "\t\t7000\t8933.135\t7.4003576e-05\n",
            "\t\t8000\t8279.257\t7.383308e-05\n",
            "\t\t9000\t7776.144\t5.6384222e-05\n",
            "\t\t10000\t7462.616\t4.239704e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7462.616\t4.239704e-05\n",
            "\n",
            "\tBest loss: 7462.6162109375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18692.059\t0.00018689688\n",
            "\t\t2000\t16018.542\t0.00013715132\n",
            "\t\t3000\t14151.1\t0.00011061024\n",
            "\t\t4000\t12798.237\t9.0794056e-05\n",
            "\t\t5000\t11746.855\t8.46232e-05\n",
            "\t\t6000\t10784.575\t8.9004476e-05\n",
            "\t\t7000\t9915.599\t7.642046e-05\n",
            "\t\t8000\t9260.644\t5.9788268e-05\n",
            "\t\t9000\t8782.829\t4.9699447e-05\n",
            "\t\t10000\t8389.7\t4.07384e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8389.7\t4.07384e-05\n",
            "\n",
            "\tBest loss outter loop: 8389.7001953125\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [10987.019]\n",
            "N =  0  J =  3 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17427.904\t0.00019025669\n",
            "\t\t2000\t14920.103\t0.00014299391\n",
            "\t\t3000\t13176.833\t0.000110266614\n",
            "\t\t4000\t11918.3\t9.4301824e-05\n",
            "\t\t5000\t10870.997\t9.135071e-05\n",
            "\t\t6000\t9956.341\t8.709143e-05\n",
            "\t\t7000\t9135.381\t7.493054e-05\n",
            "\t\t8000\t8561.898\t5.7140347e-05\n",
            "\t\t9000\t8150.034\t4.511137e-05\n",
            "\t\t10000\t7790.9575\t4.2991705e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7790.9575\t4.2991705e-05\n",
            "\n",
            "\tBest loss: 7790.95751953125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18620.137\t0.00018625555\n",
            "\t\t2000\t15960.376\t0.00014144361\n",
            "\t\t3000\t14117.505\t0.00010852203\n",
            "\t\t4000\t12736.328\t9.736822e-05\n",
            "\t\t5000\t11626.442\t8.57515e-05\n",
            "\t\t6000\t10688.951\t8.231026e-05\n",
            "\t\t7000\t9883.924\t7.4492e-05\n",
            "\t\t8000\t9197.762\t7.0812996e-05\n",
            "\t\t9000\t8681.19\t4.6681907e-05\n",
            "\t\t10000\t8287.904\t3.9707083e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8287.904\t3.9707083e-05\n",
            "\n",
            "\tBest loss outter loop: 8287.904296875\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11323.897]\n",
            "N =  0  J =  4 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17583.787\t0.00018723795\n",
            "\t\t2000\t15053.915\t0.00014036114\n",
            "\t\t3000\t13333.76\t0.0001061865\n",
            "\t\t4000\t12110.01\t9.1760965e-05\n",
            "\t\t5000\t11050.361\t9.1635244e-05\n",
            "\t\t6000\t10102.323\t8.921579e-05\n",
            "\t\t7000\t9254.197\t7.977163e-05\n",
            "\t\t8000\t8611.061\t6.373119e-05\n",
            "\t\t9000\t8127.234\t5.1785963e-05\n",
            "\t\t10000\t7737.871\t3.9753177e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7737.871\t3.9753177e-05\n",
            "\n",
            "\tBest loss: 7737.87109375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18623.516\t0.00018527826\n",
            "\t\t2000\t15964.278\t0.00013994133\n",
            "\t\t3000\t14125.983\t0.00010769661\n",
            "\t\t4000\t12754.178\t9.638988e-05\n",
            "\t\t5000\t11624.936\t8.693849e-05\n",
            "\t\t6000\t10676.289\t8.3505336e-05\n",
            "\t\t7000\t9836.894\t7.653555e-05\n",
            "\t\t8000\t9169.555\t6.389624e-05\n",
            "\t\t9000\t8653.354\t5.0781564e-05\n",
            "\t\t10000\t8287.198\t3.8060836e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8287.198\t3.8060836e-05\n",
            "\n",
            "\tBest loss outter loop: 8287.1982421875\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11359.609]\n",
            "N =  0  J =  5 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t17896.828\t0.00018265437\n",
            "\t\t2000\t15394.762\t0.00013566847\n",
            "\t\t3000\t13647.736\t0.00010832239\n",
            "\t\t4000\t12331.187\t9.842911e-05\n",
            "\t\t5000\t11195.363\t9.646618e-05\n",
            "\t\t6000\t10244.54\t8.292602e-05\n",
            "\t\t7000\t9386.675\t8.4991094e-05\n",
            "\t\t8000\t8695.263\t7.1648465e-05\n",
            "\t\t9000\t8170.634\t5.6350986e-05\n",
            "\t\t10000\t7787.9253\t4.0312687e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t7787.9253\t4.0312687e-05\n",
            "\n",
            "\tBest loss: 7787.92529296875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18615.193\t0.00018651478\n",
            "\t\t2000\t15965.366\t0.00014188861\n",
            "\t\t3000\t14105.641\t0.00010923625\n",
            "\t\t4000\t12748.75\t9.8575314e-05\n",
            "\t\t5000\t11645.301\t8.888257e-05\n",
            "\t\t6000\t10668.236\t7.990739e-05\n",
            "\t\t7000\t9894.317\t7.342691e-05\n",
            "\t\t8000\t9233.252\t5.6370005e-05\n",
            "\t\t9000\t8782.595\t4.5587025e-05\n",
            "\t\t10000\t8408.431\t3.774436e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8408.431\t3.774436e-05\n",
            "\n",
            "\tBest loss outter loop: 8408.4306640625\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11091.43]\n",
            "N =  0  J =  6 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19415.402\t0.00017691826\n",
            "\t\t2000\t16769.717\t0.00013065933\n",
            "\t\t3000\t14923.326\t0.000105999396\n",
            "\t\t4000\t13497.972\t9.4261646e-05\n",
            "\t\t5000\t12310.554\t8.92352e-05\n",
            "\t\t6000\t11241.322\t8.590959e-05\n",
            "\t\t7000\t10306.698\t9.0667796e-05\n",
            "\t\t8000\t9561.379\t6.781381e-05\n",
            "\t\t9000\t8997.275\t5.133669e-05\n",
            "\t\t10000\t8562.751\t4.2766078e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8562.751\t4.2766078e-05\n",
            "\n",
            "\tBest loss: 8562.7509765625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18606.059\t0.00018639646\n",
            "\t\t2000\t15967.114\t0.00014003877\n",
            "\t\t3000\t14112.815\t0.00010855809\n",
            "\t\t4000\t12777.196\t9.109639e-05\n",
            "\t\t5000\t11698.014\t8.9316745e-05\n",
            "\t\t6000\t10692.29\t8.803758e-05\n",
            "\t\t7000\t9799.7\t7.6925644e-05\n",
            "\t\t8000\t9148.8\t6.0946048e-05\n",
            "\t\t9000\t8657.356\t5.0532504e-05\n",
            "\t\t10000\t8265.986\t4.737281e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8265.986\t4.737281e-05\n",
            "\n",
            "\tBest loss outter loop: 8265.986328125\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11332.413]\n",
            "N =  0  J =  7 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20181.488\t0.00018084545\n",
            "\t\t2000\t17370.58\t0.00013940452\n",
            "\t\t3000\t15351.096\t0.00011131415\n",
            "\t\t4000\t13842.079\t9.6221316e-05\n",
            "\t\t5000\t12617.789\t9.340787e-05\n",
            "\t\t6000\t11510.753\t8.46623e-05\n",
            "\t\t7000\t10601.439\t7.8568795e-05\n",
            "\t\t8000\t9859.226\t6.5171065e-05\n",
            "\t\t9000\t9286.359\t5.4154963e-05\n",
            "\t\t10000\t8870.853\t3.9189315e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8870.853\t3.9189315e-05\n",
            "\n",
            "\tBest loss: 8870.8525390625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18575.555\t0.00018680759\n",
            "\t\t2000\t15930.657\t0.00014176872\n",
            "\t\t3000\t14084.851\t0.00010995202\n",
            "\t\t4000\t12725.407\t9.584052e-05\n",
            "\t\t5000\t11571.59\t9.09675e-05\n",
            "\t\t6000\t10602.271\t8.703524e-05\n",
            "\t\t7000\t9765.978\t7.5991484e-05\n",
            "\t\t8000\t9100.911\t6.566563e-05\n",
            "\t\t9000\t8569.998\t5.3782125e-05\n",
            "\t\t10000\t8170.153\t3.9562223e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8170.153\t3.9562223e-05\n",
            "\n",
            "\tBest loss outter loop: 8170.15283203125\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11267.28]\n",
            "N =  0  J =  8 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20541.973\t0.00018432559\n",
            "\t\t2000\t17617.23\t0.00014232972\n",
            "\t\t3000\t15507.994\t0.00011321004\n",
            "\t\t4000\t13932.343\t9.791061e-05\n",
            "\t\t5000\t12700.29\t8.9725996e-05\n",
            "\t\t6000\t11674.848\t8.380697e-05\n",
            "\t\t7000\t10759.4795\t7.106237e-05\n",
            "\t\t8000\t10063.572\t6.0936996e-05\n",
            "\t\t9000\t9537.312\t4.8122816e-05\n",
            "\t\t10000\t9149.706\t3.639414e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9149.706\t3.639414e-05\n",
            "\n",
            "\tBest loss: 9149.7060546875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18549.814\t0.000185909\n",
            "\t\t2000\t15896.532\t0.0001404148\n",
            "\t\t3000\t14054.395\t0.00010880088\n",
            "\t\t4000\t12722.771\t9.340461e-05\n",
            "\t\t5000\t11620.714\t8.789431e-05\n",
            "\t\t6000\t10629.428\t8.396531e-05\n",
            "\t\t7000\t9800.406\t8.080565e-05\n",
            "\t\t8000\t9135.732\t6.1353865e-05\n",
            "\t\t9000\t8646.203\t5.104943e-05\n",
            "\t\t10000\t8262.43\t4.018405e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8262.43\t4.018405e-05\n",
            "\n",
            "\tBest loss outter loop: 8262.4296875\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11124.642]\n",
            "N =  0  J =  9 I =  5\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20563.941\t0.00018925562\n",
            "\t\t2000\t17526.748\t0.00015097408\n",
            "\t\t3000\t15368.843\t0.00011658544\n",
            "\t\t4000\t13807.661\t9.9572484e-05\n",
            "\t\t5000\t12584.006\t9.342585e-05\n",
            "\t\t6000\t11491.739\t8.692649e-05\n",
            "\t\t7000\t10535.175\t7.748737e-05\n",
            "\t\t8000\t9817.365\t6.634407e-05\n",
            "\t\t9000\t9257.294\t5.4219505e-05\n",
            "\t\t10000\t8822.014\t4.848254e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8822.014\t4.848254e-05\n",
            "\n",
            "\tBest loss: 8822.013671875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18547.668\t0.00018561473\n",
            "\t\t2000\t15915.263\t0.00013994286\n",
            "\t\t3000\t14078.643\t0.00010930701\n",
            "\t\t4000\t12737.22\t9.214883e-05\n",
            "\t\t5000\t11630.173\t9.017351e-05\n",
            "\t\t6000\t10659.775\t8.1802755e-05\n",
            "\t\t7000\t9849.442\t6.989517e-05\n",
            "\t\t8000\t9211.481\t6.190939e-05\n",
            "\t\t9000\t8701.604\t5.4427557e-05\n",
            "\t\t10000\t8286.728\t4.1951622e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8286.728\t4.1951622e-05\n",
            "\n",
            "\tBest loss outter loop: 8286.7275390625\n",
            "\n",
            "OUTTER FOLDER: 5 OUTTER MSE:  [11026.793]\n",
            "N =  0  J =  0 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19642.43\t0.00017944613\n",
            "\t\t2000\t16887.143\t0.00013807601\n",
            "\t\t3000\t14926.226\t0.00011572511\n",
            "\t\t4000\t13382.461\t0.00010149558\n",
            "\t\t5000\t12124.357\t9.9624864e-05\n",
            "\t\t6000\t11052.325\t9.373916e-05\n",
            "\t\t7000\t10097.64\t8.1811624e-05\n",
            "\t\t8000\t9354.261\t7.328176e-05\n",
            "\t\t9000\t8729.493\t6.208362e-05\n",
            "\t\t10000\t8289.08\t4.594501e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8289.08\t4.594501e-05\n",
            "\n",
            "\tBest loss: 8289.080078125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20022.809\t0.00018296095\n",
            "\t\t2000\t17177.36\t0.00014131342\n",
            "\t\t3000\t15154.933\t0.0001151385\n",
            "\t\t4000\t13669.971\t9.471851e-05\n",
            "\t\t5000\t12436.8\t9.1077236e-05\n",
            "\t\t6000\t11386.669\t9.55316e-05\n",
            "\t\t7000\t10456.978\t7.9560756e-05\n",
            "\t\t8000\t9695.092\t6.919501e-05\n",
            "\t\t9000\t9131.146\t5.1439587e-05\n",
            "\t\t10000\t8729.42\t3.7027687e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8729.42\t3.7027687e-05\n",
            "\n",
            "\tBest loss outter loop: 8729.419921875\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5996.8296]\n",
            "N =  0  J =  1 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19172.105\t0.00018965204\n",
            "\t\t2000\t16367.779\t0.00014675119\n",
            "\t\t3000\t14368.706\t0.00011926354\n",
            "\t\t4000\t12859.414\t0.00010053637\n",
            "\t\t5000\t11673.202\t9.435788e-05\n",
            "\t\t6000\t10642.628\t8.771441e-05\n",
            "\t\t7000\t9778.014\t8.1489976e-05\n",
            "\t\t8000\t9089.103\t7.09075e-05\n",
            "\t\t9000\t8597.502\t4.8839927e-05\n",
            "\t\t10000\t8223.969\t3.7878504e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8223.969\t3.7878504e-05\n",
            "\n",
            "\tBest loss: 8223.96875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19985.723\t0.00018369115\n",
            "\t\t2000\t17160.15\t0.00014145511\n",
            "\t\t3000\t15146.528\t0.00011417103\n",
            "\t\t4000\t13637.873\t9.658805e-05\n",
            "\t\t5000\t12440.466\t8.8224944e-05\n",
            "\t\t6000\t11420.77\t7.874629e-05\n",
            "\t\t7000\t10532.651\t8.5292944e-05\n",
            "\t\t8000\t9790.099\t6.114302e-05\n",
            "\t\t9000\t9258.209\t5.516337e-05\n",
            "\t\t10000\t8829.818\t4.0477324e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8829.818\t4.0477324e-05\n",
            "\n",
            "\tBest loss outter loop: 8829.818359375\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5724.0557]\n",
            "N =  0  J =  2 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18469.963\t0.00018755825\n",
            "\t\t2000\t15819.497\t0.00013967905\n",
            "\t\t3000\t13940.994\t0.00011851005\n",
            "\t\t4000\t12493.177\t9.8637865e-05\n",
            "\t\t5000\t11380.479\t8.86342e-05\n",
            "\t\t6000\t10419.527\t8.406359e-05\n",
            "\t\t7000\t9621.486\t7.855335e-05\n",
            "\t\t8000\t8946.354\t5.817762e-05\n",
            "\t\t9000\t8521.646\t4.3659882e-05\n",
            "\t\t10000\t8176.4297\t3.5710178e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8176.4297\t3.5710178e-05\n",
            "\n",
            "\tBest loss: 8176.4296875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19965.225\t0.00018309739\n",
            "\t\t2000\t17135.81\t0.00013914917\n",
            "\t\t3000\t15138.643\t0.00011306962\n",
            "\t\t4000\t13650.761\t9.449416e-05\n",
            "\t\t5000\t12452.01\t9.716049e-05\n",
            "\t\t6000\t11357.027\t8.623803e-05\n",
            "\t\t7000\t10538.802\t7.292088e-05\n",
            "\t\t8000\t9762.493\t6.831724e-05\n",
            "\t\t9000\t9206.93\t4.8152648e-05\n",
            "\t\t10000\t8750.897\t4.262774e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8750.897\t4.262774e-05\n",
            "\n",
            "\tBest loss outter loop: 8750.8974609375\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5905.073]\n",
            "N =  0  J =  3 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19110.549\t0.00018546115\n",
            "\t\t2000\t16359.735\t0.00014103479\n",
            "\t\t3000\t14417.761\t0.000114997914\n",
            "\t\t4000\t12949.978\t9.90794e-05\n",
            "\t\t5000\t11769.014\t9.6825286e-05\n",
            "\t\t6000\t10734.023\t8.560319e-05\n",
            "\t\t7000\t9864.751\t7.592351e-05\n",
            "\t\t8000\t9207.355\t6.193713e-05\n",
            "\t\t9000\t8720.202\t5.0280316e-05\n",
            "\t\t10000\t8375.108\t3.2181382e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8375.108\t3.2181382e-05\n",
            "\n",
            "\tBest loss: 8375.1083984375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20080.166\t0.00018370243\n",
            "\t\t2000\t17226.54\t0.00014113673\n",
            "\t\t3000\t15195.675\t0.00011393032\n",
            "\t\t4000\t13674.359\t9.540213e-05\n",
            "\t\t5000\t12440.708\t9.450187e-05\n",
            "\t\t6000\t11372.34\t8.380379e-05\n",
            "\t\t7000\t10449.913\t7.746548e-05\n",
            "\t\t8000\t9749.109\t6.610744e-05\n",
            "\t\t9000\t9245.952\t4.7315763e-05\n",
            "\t\t10000\t8824.36\t4.2715506e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8824.36\t4.2715506e-05\n",
            "\n",
            "\tBest loss outter loop: 8824.3603515625\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5859.3623]\n",
            "N =  0  J =  4 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19076.842\t0.00018425363\n",
            "\t\t2000\t16365.174\t0.00013651367\n",
            "\t\t3000\t14491.367\t0.000110977795\n",
            "\t\t4000\t13063.808\t9.754352e-05\n",
            "\t\t5000\t11904.875\t9.129158e-05\n",
            "\t\t6000\t10851.5205\t9.0884816e-05\n",
            "\t\t7000\t10004.764\t7.447069e-05\n",
            "\t\t8000\t9343.393\t5.894527e-05\n",
            "\t\t9000\t8847.5205\t5.121229e-05\n",
            "\t\t10000\t8419.769\t3.896927e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8419.769\t3.896927e-05\n",
            "\n",
            "\tBest loss: 8419.7685546875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20085.363\t0.00018384932\n",
            "\t\t2000\t17238.229\t0.00013900218\n",
            "\t\t3000\t15223.6\t0.00011198976\n",
            "\t\t4000\t13689.578\t0.000100217316\n",
            "\t\t5000\t12442.619\t8.97791e-05\n",
            "\t\t6000\t11341.303\t8.73907e-05\n",
            "\t\t7000\t10437.683\t7.6527234e-05\n",
            "\t\t8000\t9752.022\t6.4285414e-05\n",
            "\t\t9000\t9227.931\t4.963031e-05\n",
            "\t\t10000\t8827.63\t3.694761e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8827.63\t3.694761e-05\n",
            "\n",
            "\tBest loss outter loop: 8827.6298828125\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5642.2256]\n",
            "N =  0  J =  5 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t18574.383\t0.00017893591\n",
            "\t\t2000\t15999.582\t0.0001329814\n",
            "\t\t3000\t14208.233\t0.000108791166\n",
            "\t\t4000\t12831.41\t0.00010014702\n",
            "\t\t5000\t11658.653\t9.162821e-05\n",
            "\t\t6000\t10641.451\t8.781587e-05\n",
            "\t\t7000\t9789.454\t7.920046e-05\n",
            "\t\t8000\t9068.342\t7.053145e-05\n",
            "\t\t9000\t8516.994\t5.2397085e-05\n",
            "\t\t10000\t8131.271\t4.4855195e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8131.271\t4.4855195e-05\n",
            "\n",
            "\tBest loss: 8131.27099609375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20029.014\t0.00018251437\n",
            "\t\t2000\t17181.4\t0.00014059832\n",
            "\t\t3000\t15159.042\t0.00011323951\n",
            "\t\t4000\t13633.119\t9.805408e-05\n",
            "\t\t5000\t12390.744\t9.157333e-05\n",
            "\t\t6000\t11286.856\t8.824475e-05\n",
            "\t\t7000\t10407.608\t8.040721e-05\n",
            "\t\t8000\t9679.99\t6.385591e-05\n",
            "\t\t9000\t9157.996\t5.470074e-05\n",
            "\t\t10000\t8770.427\t3.462778e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8770.427\t3.462778e-05\n",
            "\n",
            "\tBest loss outter loop: 8770.4267578125\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5923.672]\n",
            "N =  0  J =  6 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20224.479\t0.00017756497\n",
            "\t\t2000\t17450.666\t0.00013496052\n",
            "\t\t3000\t15473.147\t0.000108101514\n",
            "\t\t4000\t13917.669\t0.00010306485\n",
            "\t\t5000\t12674.629\t8.836694e-05\n",
            "\t\t6000\t11564.669\t8.848908e-05\n",
            "\t\t7000\t10619.416\t8.045861e-05\n",
            "\t\t8000\t9848.723\t7.049513e-05\n",
            "\t\t9000\t9249.519\t5.1942574e-05\n",
            "\t\t10000\t8840.065\t4.3523305e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8840.065\t4.3523305e-05\n",
            "\n",
            "\tBest loss: 8840.0654296875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20037.5\t0.00018253451\n",
            "\t\t2000\t17195.54\t0.00013946077\n",
            "\t\t3000\t15188.715\t0.00011269691\n",
            "\t\t4000\t13653.014\t9.9055425e-05\n",
            "\t\t5000\t12438.6045\t8.9808076e-05\n",
            "\t\t6000\t11348.571\t9.180861e-05\n",
            "\t\t7000\t10404.348\t7.771087e-05\n",
            "\t\t8000\t9732.579\t6.320991e-05\n",
            "\t\t9000\t9159.211\t4.8190283e-05\n",
            "\t\t10000\t8788.842\t4.0443825e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8788.842\t4.0443825e-05\n",
            "\n",
            "\tBest loss outter loop: 8788.841796875\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5452.916]\n",
            "N =  0  J =  7 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21570.348\t0.00017725912\n",
            "\t\t2000\t18591.205\t0.00013508428\n",
            "\t\t3000\t16415.545\t0.000115754345\n",
            "\t\t4000\t14761.239\t9.823382e-05\n",
            "\t\t5000\t13374.8955\t9.885198e-05\n",
            "\t\t6000\t12198.231\t8.853599e-05\n",
            "\t\t7000\t11147.771\t8.084973e-05\n",
            "\t\t8000\t10373.649\t6.410439e-05\n",
            "\t\t9000\t9754.324\t6.0366216e-05\n",
            "\t\t10000\t9274.199\t4.2960084e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9274.199\t4.2960084e-05\n",
            "\n",
            "\tBest loss: 9274.19921875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20061.168\t0.0001823192\n",
            "\t\t2000\t17211.922\t0.00013910115\n",
            "\t\t3000\t15197.378\t0.00011481697\n",
            "\t\t4000\t13664.027\t9.7617936e-05\n",
            "\t\t5000\t12431.514\t9.4571755e-05\n",
            "\t\t6000\t11332.553\t8.935364e-05\n",
            "\t\t7000\t10444.735\t7.1614384e-05\n",
            "\t\t8000\t9783.573\t5.7491026e-05\n",
            "\t\t9000\t9254.795\t5.8876485e-05\n",
            "\t\t10000\t8821.891\t3.940681e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8821.891\t3.940681e-05\n",
            "\n",
            "\tBest loss outter loop: 8821.890625\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [6004.144]\n",
            "N =  0  J =  8 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22078.791\t0.00018087124\n",
            "\t\t2000\t18952.264\t0.00014260774\n",
            "\t\t3000\t16680.625\t0.0001187146\n",
            "\t\t4000\t14935.318\t0.00010035762\n",
            "\t\t5000\t13576.226\t9.724235e-05\n",
            "\t\t6000\t12395.817\t8.846392e-05\n",
            "\t\t7000\t11378.913\t8.4527645e-05\n",
            "\t\t8000\t10516.084\t6.4257554e-05\n",
            "\t\t9000\t9944.953\t4.389204e-05\n",
            "\t\t10000\t9555.067\t3.4952416e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9555.067\t3.4952416e-05\n",
            "\n",
            "\tBest loss: 9555.0673828125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19998.19\t0.00018240511\n",
            "\t\t2000\t17155.889\t0.00013966922\n",
            "\t\t3000\t15156.203\t0.000113325135\n",
            "\t\t4000\t13631.317\t9.906982e-05\n",
            "\t\t5000\t12408.673\t9.183446e-05\n",
            "\t\t6000\t11383.514\t8.234916e-05\n",
            "\t\t7000\t10497.057\t7.683855e-05\n",
            "\t\t8000\t9752.34\t6.41832e-05\n",
            "\t\t9000\t9208.459\t5.471911e-05\n",
            "\t\t10000\t8807.309\t3.814158e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8807.309\t3.814158e-05\n",
            "\n",
            "\tBest loss outter loop: 8807.30859375\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [5750.568]\n",
            "N =  0  J =  9 I =  6\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22094.367\t0.00018498536\n",
            "\t\t2000\t18860.895\t0.00014826765\n",
            "\t\t3000\t16527.748\t0.00012146655\n",
            "\t\t4000\t14779.527\t0.00010082083\n",
            "\t\t5000\t13423.743\t9.354633e-05\n",
            "\t\t6000\t12284.314\t8.3067156e-05\n",
            "\t\t7000\t11332.3\t7.720696e-05\n",
            "\t\t8000\t10532.443\t6.768063e-05\n",
            "\t\t9000\t9925.816\t5.4306187e-05\n",
            "\t\t10000\t9431.219\t4.038121e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9431.219\t4.038121e-05\n",
            "\n",
            "\tBest loss: 9431.21875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20066.86\t0.00018333775\n",
            "\t\t2000\t17216.246\t0.00013997353\n",
            "\t\t3000\t15186.545\t0.000115413175\n",
            "\t\t4000\t13655.539\t9.56051e-05\n",
            "\t\t5000\t12482.144\t8.918196e-05\n",
            "\t\t6000\t11429.958\t8.790885e-05\n",
            "\t\t7000\t10474.716\t8.240893e-05\n",
            "\t\t8000\t9743.865\t6.283607e-05\n",
            "\t\t9000\t9192.626\t5.7468882e-05\n",
            "\t\t10000\t8779.449\t3.870751e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8779.449\t3.870751e-05\n",
            "\n",
            "\tBest loss outter loop: 8779.44921875\n",
            "\n",
            "OUTTER FOLDER: 6 OUTTER MSE:  [6022.606]\n",
            "N =  0  J =  0 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20020.424\t0.00018025214\n",
            "\t\t2000\t17208.55\t0.00013867453\n",
            "\t\t3000\t15209.783\t0.00011677745\n",
            "\t\t4000\t13602.454\t0.00010731918\n",
            "\t\t5000\t12226.275\t0.00010222837\n",
            "\t\t6000\t11073.929\t9.9375444e-05\n",
            "\t\t7000\t10073.579\t8.5981e-05\n",
            "\t\t8000\t9344.742\t7.210253e-05\n",
            "\t\t9000\t8707.538\t6.291297e-05\n",
            "\t\t10000\t8240.505\t4.7756283e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8240.505\t4.7756283e-05\n",
            "\n",
            "\tBest loss: 8240.5048828125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20471.531\t0.00018362452\n",
            "\t\t2000\t17539.586\t0.00014273706\n",
            "\t\t3000\t15458.193\t0.00011458528\n",
            "\t\t4000\t13908.179\t9.871252e-05\n",
            "\t\t5000\t12662.92\t9.376895e-05\n",
            "\t\t6000\t11561.755\t8.969368e-05\n",
            "\t\t7000\t10613.781\t7.985736e-05\n",
            "\t\t8000\t9873.679\t6.240556e-05\n",
            "\t\t9000\t9320.388\t5.971934e-05\n",
            "\t\t10000\t8862.727\t4.848019e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8862.727\t4.848019e-05\n",
            "\n",
            "\tBest loss outter loop: 8862.7265625\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4802.706]\n",
            "N =  0  J =  1 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19538.771\t0.00018929126\n",
            "\t\t2000\t16669.379\t0.00014737617\n",
            "\t\t3000\t14623.853\t0.000119987\n",
            "\t\t4000\t13095.621\t0.00010170543\n",
            "\t\t5000\t11882.875\t9.7705255e-05\n",
            "\t\t6000\t10776.709\t9.5773925e-05\n",
            "\t\t7000\t9875.027\t7.752542e-05\n",
            "\t\t8000\t9237.663\t6.0359802e-05\n",
            "\t\t9000\t8697.316\t5.512801e-05\n",
            "\t\t10000\t8294.607\t4.2500393e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8294.607\t4.2500393e-05\n",
            "\n",
            "\tBest loss: 8294.607421875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20325.986\t0.00018253777\n",
            "\t\t2000\t17441.945\t0.00013883422\n",
            "\t\t3000\t15387.515\t0.000115746036\n",
            "\t\t4000\t13837.864\t9.9919635e-05\n",
            "\t\t5000\t12574.829\t8.961173e-05\n",
            "\t\t6000\t11525.208\t8.591162e-05\n",
            "\t\t7000\t10621.015\t7.603377e-05\n",
            "\t\t8000\t9959.119\t6.049758e-05\n",
            "\t\t9000\t9461.376\t4.5928875e-05\n",
            "\t\t10000\t9071.245\t3.9938313e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9071.245\t3.9938313e-05\n",
            "\n",
            "\tBest loss outter loop: 9071.2451171875\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4821.8496]\n",
            "N =  0  J =  2 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19160.64\t0.00018864466\n",
            "\t\t2000\t16386.258\t0.00014336845\n",
            "\t\t3000\t14371.062\t0.00012121417\n",
            "\t\t4000\t12839.751\t0.00010403617\n",
            "\t\t5000\t11629.137\t9.362391e-05\n",
            "\t\t6000\t10626.805\t8.187277e-05\n",
            "\t\t7000\t9776.857\t8.4096195e-05\n",
            "\t\t8000\t9106.687\t5.7046174e-05\n",
            "\t\t9000\t8647.315\t4.9123202e-05\n",
            "\t\t10000\t8269.447\t3.9323368e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8269.447\t3.9323368e-05\n",
            "\n",
            "\tBest loss: 8269.447265625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20509.744\t0.00018366324\n",
            "\t\t2000\t17563.44\t0.00014154268\n",
            "\t\t3000\t15474.507\t0.00011616801\n",
            "\t\t4000\t13889.118\t9.962124e-05\n",
            "\t\t5000\t12662.895\t9.600519e-05\n",
            "\t\t6000\t11574.965\t9.01818e-05\n",
            "\t\t7000\t10633.321\t8.421004e-05\n",
            "\t\t8000\t9871.342\t6.598132e-05\n",
            "\t\t9000\t9288.846\t5.0461204e-05\n",
            "\t\t10000\t8868.877\t3.908794e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8868.877\t3.908794e-05\n",
            "\n",
            "\tBest loss outter loop: 8868.876953125\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4825.7734]\n",
            "N =  0  J =  3 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19434.781\t0.0001854819\n",
            "\t\t2000\t16651.848\t0.00014307551\n",
            "\t\t3000\t14666.446\t0.000115644434\n",
            "\t\t4000\t13163.764\t9.932473e-05\n",
            "\t\t5000\t11968.394\t9.790456e-05\n",
            "\t\t6000\t10898.177\t8.5747386e-05\n",
            "\t\t7000\t10042.085\t7.487457e-05\n",
            "\t\t8000\t9345.508\t6.0185725e-05\n",
            "\t\t9000\t8857.729\t4.861778e-05\n",
            "\t\t10000\t8502.172\t3.7213373e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8502.172\t3.7213373e-05\n",
            "\n",
            "\tBest loss: 8502.171875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20507.92\t0.00018339398\n",
            "\t\t2000\t17576.264\t0.00014199487\n",
            "\t\t3000\t15482.261\t0.00011573147\n",
            "\t\t4000\t13895.065\t9.85246e-05\n",
            "\t\t5000\t12652.816\t9.523282e-05\n",
            "\t\t6000\t11534.619\t8.8381e-05\n",
            "\t\t7000\t10609.694\t7.85997e-05\n",
            "\t\t8000\t9890.965\t6.812098e-05\n",
            "\t\t9000\t9362.727\t4.4848373e-05\n",
            "\t\t10000\t8955.441\t3.8055896e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8955.441\t3.8055896e-05\n",
            "\n",
            "\tBest loss outter loop: 8955.44140625\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4682.909]\n",
            "N =  0  J =  4 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19501.883\t0.00018314188\n",
            "\t\t2000\t16720.025\t0.00014109082\n",
            "\t\t3000\t14744.726\t0.00011330893\n",
            "\t\t4000\t13279.291\t9.684314e-05\n",
            "\t\t5000\t12099.202\t9.692688e-05\n",
            "\t\t6000\t11037.834\t9.1031565e-05\n",
            "\t\t7000\t10115.213\t7.665001e-05\n",
            "\t\t8000\t9412.876\t6.442306e-05\n",
            "\t\t9000\t8881.918\t5.2553103e-05\n",
            "\t\t10000\t8506.142\t3.3752047e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8506.142\t3.3752047e-05\n",
            "\n",
            "\tBest loss: 8506.1416015625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20363.014\t0.00018364411\n",
            "\t\t2000\t17470.684\t0.00014084113\n",
            "\t\t3000\t15387.069\t0.00011644736\n",
            "\t\t4000\t13832.242\t9.812499e-05\n",
            "\t\t5000\t12624.321\t8.647613e-05\n",
            "\t\t6000\t11538.447\t8.632078e-05\n",
            "\t\t7000\t10627.587\t7.24036e-05\n",
            "\t\t8000\t9913.688\t6.0282327e-05\n",
            "\t\t9000\t9387.403\t5.877295e-05\n",
            "\t\t10000\t8934.618\t5.344532e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8934.618\t5.344532e-05\n",
            "\n",
            "\tBest loss outter loop: 8934.6181640625\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4618.3535]\n",
            "N =  0  J =  5 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19183.746\t0.00018526251\n",
            "\t\t2000\t16505.527\t0.00013807388\n",
            "\t\t3000\t14590.044\t0.00011377398\n",
            "\t\t4000\t13151.534\t9.585356e-05\n",
            "\t\t5000\t11971.786\t9.045516e-05\n",
            "\t\t6000\t10924.813\t9.054326e-05\n",
            "\t\t7000\t10014.94\t8.648439e-05\n",
            "\t\t8000\t9316.412\t6.110734e-05\n",
            "\t\t9000\t8811.452\t4.9759645e-05\n",
            "\t\t10000\t8394.47\t5.327815e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8394.47\t5.327815e-05\n",
            "\n",
            "\tBest loss: 8394.4697265625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20531.18\t0.00018366172\n",
            "\t\t2000\t17603.021\t0.00014277737\n",
            "\t\t3000\t15487.32\t0.00011708057\n",
            "\t\t4000\t13903.549\t9.67791e-05\n",
            "\t\t5000\t12680.66\t9.109685e-05\n",
            "\t\t6000\t11576.917\t8.527491e-05\n",
            "\t\t7000\t10702.275\t7.052982e-05\n",
            "\t\t8000\t10010.412\t6.291881e-05\n",
            "\t\t9000\t9444.989\t4.590517e-05\n",
            "\t\t10000\t9020.593\t3.7564543e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9020.593\t3.7564543e-05\n",
            "\n",
            "\tBest loss outter loop: 9020.5927734375\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [5018.044]\n",
            "N =  0  J =  6 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20680.227\t0.00017997801\n",
            "\t\t2000\t17802.787\t0.00013887223\n",
            "\t\t3000\t15734.92\t0.00011095703\n",
            "\t\t4000\t14165.799\t0.000100639416\n",
            "\t\t5000\t12861.969\t9.6493095e-05\n",
            "\t\t6000\t11727.156\t9.2092116e-05\n",
            "\t\t7000\t10753.786\t7.972574e-05\n",
            "\t\t8000\t9994.251\t6.614694e-05\n",
            "\t\t9000\t9440.28\t6.0822753e-05\n",
            "\t\t10000\t8981.674\t4.5772536e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8981.674\t4.5772536e-05\n",
            "\n",
            "\tBest loss: 8981.673828125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20389.016\t0.0001835057\n",
            "\t\t2000\t17470.115\t0.00014308104\n",
            "\t\t3000\t15400.671\t0.00011475963\n",
            "\t\t4000\t13853.349\t9.769359e-05\n",
            "\t\t5000\t12642.926\t8.820237e-05\n",
            "\t\t6000\t11551.268\t8.850721e-05\n",
            "\t\t7000\t10651.214\t7.655158e-05\n",
            "\t\t8000\t9936.76\t6.338514e-05\n",
            "\t\t9000\t9390.656\t4.918627e-05\n",
            "\t\t10000\t8985.032\t4.5755427e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8985.032\t4.5755427e-05\n",
            "\n",
            "\tBest loss outter loop: 8985.0322265625\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4812.2075]\n",
            "N =  0  J =  7 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21561.77\t0.00017669577\n",
            "\t\t2000\t18579.484\t0.00013516948\n",
            "\t\t3000\t16438.936\t0.00011321399\n",
            "\t\t4000\t14796.269\t9.89251e-05\n",
            "\t\t5000\t13425.341\t9.804423e-05\n",
            "\t\t6000\t12233.364\t9.2272414e-05\n",
            "\t\t7000\t11201.787\t8.333634e-05\n",
            "\t\t8000\t10345.98\t6.739029e-05\n",
            "\t\t9000\t9726.024\t5.712841e-05\n",
            "\t\t10000\t9224.432\t4.689686e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9224.432\t4.689686e-05\n",
            "\n",
            "\tBest loss: 9224.431640625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20308.217\t0.00018308201\n",
            "\t\t2000\t17414.793\t0.00014118096\n",
            "\t\t3000\t15375.785\t0.00011405637\n",
            "\t\t4000\t13825.492\t9.8172895e-05\n",
            "\t\t5000\t12603.771\t8.6694585e-05\n",
            "\t\t6000\t11558.126\t8.490667e-05\n",
            "\t\t7000\t10618.455\t7.531646e-05\n",
            "\t\t8000\t9902.66\t6.192712e-05\n",
            "\t\t9000\t9394.052\t4.4179098e-05\n",
            "\t\t10000\t8970.301\t4.3109154e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8970.301\t4.3109154e-05\n",
            "\n",
            "\tBest loss outter loop: 8970.30078125\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4698.8125]\n",
            "N =  0  J =  8 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22392.15\t0.00018095631\n",
            "\t\t2000\t19221.43\t0.00014152528\n",
            "\t\t3000\t16880.898\t0.0001183474\n",
            "\t\t4000\t15098.01\t0.00010238039\n",
            "\t\t5000\t13669.453\t0.00010415046\n",
            "\t\t6000\t12388.453\t9.285129e-05\n",
            "\t\t7000\t11346.054\t8.485848e-05\n",
            "\t\t8000\t10529.929\t6.918045e-05\n",
            "\t\t9000\t9930.726\t4.9461305e-05\n",
            "\t\t10000\t9488.104\t4.1579948e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9488.104\t4.1579948e-05\n",
            "\n",
            "\tBest loss: 9488.103515625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20607.486\t0.00018402394\n",
            "\t\t2000\t17646.17\t0.00014154309\n",
            "\t\t3000\t15533.983\t0.00011666605\n",
            "\t\t4000\t13965.618\t9.96349e-05\n",
            "\t\t5000\t12667.702\t9.481262e-05\n",
            "\t\t6000\t11602.441\t8.045881e-05\n",
            "\t\t7000\t10670.019\t7.925348e-05\n",
            "\t\t8000\t9915.464\t6.4309075e-05\n",
            "\t\t9000\t9363.014\t5.1104398e-05\n",
            "\t\t10000\t8954.121\t3.8061506e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8954.121\t3.8061506e-05\n",
            "\n",
            "\tBest loss outter loop: 8954.12109375\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4861.5117]\n",
            "N =  0  J =  9 I =  7\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22400.965\t0.00018567879\n",
            "\t\t2000\t19111.45\t0.00014887827\n",
            "\t\t3000\t16720.412\t0.00012240275\n",
            "\t\t4000\t14930.911\t0.000104833896\n",
            "\t\t5000\t13521.774\t9.9294666e-05\n",
            "\t\t6000\t12320.645\t9.20943e-05\n",
            "\t\t7000\t11222.444\t8.588008e-05\n",
            "\t\t8000\t10387.995\t6.410986e-05\n",
            "\t\t9000\t9825.435\t4.7009864e-05\n",
            "\t\t10000\t9399.93\t4.1866082e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9399.93\t4.1866082e-05\n",
            "\n",
            "\tBest loss: 9399.9296875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20483.23\t0.00018323371\n",
            "\t\t2000\t17553.756\t0.00014295556\n",
            "\t\t3000\t15455.359\t0.00011694363\n",
            "\t\t4000\t13891.656\t9.777564e-05\n",
            "\t\t5000\t12665.192\t9.2749935e-05\n",
            "\t\t6000\t11487.854\t9.392531e-05\n",
            "\t\t7000\t10527.004\t7.810403e-05\n",
            "\t\t8000\t9807.994\t6.7403e-05\n",
            "\t\t9000\t9252.541\t4.9814913e-05\n",
            "\t\t10000\t8831.94\t3.8698592e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8831.94\t3.8698592e-05\n",
            "\n",
            "\tBest loss outter loop: 8831.9404296875\n",
            "\n",
            "OUTTER FOLDER: 7 OUTTER MSE:  [4753.3896]\n",
            "N =  0  J =  0 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20611.96\t0.00018369983\n",
            "\t\t2000\t17619.688\t0.0001444154\n",
            "\t\t3000\t15480.532\t0.00012047452\n",
            "\t\t4000\t13804.211\t0.00010857996\n",
            "\t\t5000\t12442.669\t0.00010233393\n",
            "\t\t6000\t11245.597\t9.898728e-05\n",
            "\t\t7000\t10291.367\t8.103071e-05\n",
            "\t\t8000\t9549.098\t6.7696514e-05\n",
            "\t\t9000\t9005.698\t5.085497e-05\n",
            "\t\t10000\t8586.057\t3.9010676e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8586.057\t3.9010676e-05\n",
            "\n",
            "\tBest loss: 8586.056640625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20698.83\t0.0001875509\n",
            "\t\t2000\t17683.22\t0.00014455913\n",
            "\t\t3000\t15536.545\t0.00011859489\n",
            "\t\t4000\t13922.387\t0.00010015463\n",
            "\t\t5000\t12702.382\t8.263945e-05\n",
            "\t\t6000\t11649.415\t8.491189e-05\n",
            "\t\t7000\t10706.641\t7.797925e-05\n",
            "\t\t8000\t9988.872\t5.826457e-05\n",
            "\t\t9000\t9455.1045\t5.2259053e-05\n",
            "\t\t10000\t9074.263\t3.497493e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9074.263\t3.497493e-05\n",
            "\n",
            "\tBest loss outter loop: 9074.2626953125\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [4751.288]\n",
            "N =  0  J =  1 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20087.639\t0.00019403381\n",
            "\t\t2000\t17044.725\t0.00015157726\n",
            "\t\t3000\t14876.471\t0.00012392197\n",
            "\t\t4000\t13236.7295\t0.00010600591\n",
            "\t\t5000\t11967.307\t0.00010158483\n",
            "\t\t6000\t10902.132\t8.885087e-05\n",
            "\t\t7000\t10030.392\t7.836895e-05\n",
            "\t\t8000\t9357.331\t6.230104e-05\n",
            "\t\t9000\t8835.271\t5.2277956e-05\n",
            "\t\t10000\t8405.664\t4.5540135e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8405.664\t4.5540135e-05\n",
            "\n",
            "\tBest loss: 8405.6640625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20801.959\t0.0001869967\n",
            "\t\t2000\t17759.51\t0.00014569736\n",
            "\t\t3000\t15588.035\t0.000117827396\n",
            "\t\t4000\t13985.583\t9.9981364e-05\n",
            "\t\t5000\t12712.612\t9.785706e-05\n",
            "\t\t6000\t11581.998\t8.9874135e-05\n",
            "\t\t7000\t10668.127\t7.7253964e-05\n",
            "\t\t8000\t9984.619\t5.5257722e-05\n",
            "\t\t9000\t9468.167\t5.03306e-05\n",
            "\t\t10000\t9069.596\t4.1129897e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9069.596\t4.1129897e-05\n",
            "\n",
            "\tBest loss outter loop: 9069.595703125\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [5171.8296]\n",
            "N =  0  J =  2 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19699.93\t0.00020032939\n",
            "\t\t2000\t16772.535\t0.00014437444\n",
            "\t\t3000\t14629.564\t0.00012768156\n",
            "\t\t4000\t13017.049\t0.00010396941\n",
            "\t\t5000\t11751.515\t0.000100459\n",
            "\t\t6000\t10682.71\t9.341765e-05\n",
            "\t\t7000\t9792.063\t7.638735e-05\n",
            "\t\t8000\t9104.871\t6.42429e-05\n",
            "\t\t9000\t8619.344\t4.45245e-05\n",
            "\t\t10000\t8249.063\t3.776328e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8249.063\t3.776328e-05\n",
            "\n",
            "\tBest loss: 8249.0634765625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20870.623\t0.00018834608\n",
            "\t\t2000\t17809.133\t0.00014594928\n",
            "\t\t3000\t15633.697\t0.000118919656\n",
            "\t\t4000\t14006.126\t9.767372e-05\n",
            "\t\t5000\t12773.635\t9.4255716e-05\n",
            "\t\t6000\t11716.496\t7.9425634e-05\n",
            "\t\t7000\t10782.44\t7.027716e-05\n",
            "\t\t8000\t10009.8125\t7.14092e-05\n",
            "\t\t9000\t9412.401\t5.560838e-05\n",
            "\t\t10000\t8960.578\t4.2937976e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8960.578\t4.2937976e-05\n",
            "\n",
            "\tBest loss outter loop: 8960.578125\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [4912.262]\n",
            "N =  0  J =  3 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19884.033\t0.00019032536\n",
            "\t\t2000\t16944.137\t0.00014671526\n",
            "\t\t3000\t14851.814\t0.00012064358\n",
            "\t\t4000\t13283.501\t0.00010350115\n",
            "\t\t5000\t12032.1045\t9.219274e-05\n",
            "\t\t6000\t10982.808\t8.802046e-05\n",
            "\t\t7000\t10107.585\t7.863989e-05\n",
            "\t\t8000\t9431.226\t6.2330604e-05\n",
            "\t\t9000\t8917.796\t4.7633344e-05\n",
            "\t\t10000\t8564.954\t3.1696116e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8564.954\t3.1696116e-05\n",
            "\n",
            "\tBest loss: 8564.9541015625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20847.115\t0.00018659171\n",
            "\t\t2000\t17809.693\t0.00014682175\n",
            "\t\t3000\t15624.37\t0.000119990436\n",
            "\t\t4000\t13972.674\t0.0001016809\n",
            "\t\t5000\t12687.74\t9.31238e-05\n",
            "\t\t6000\t11583.397\t9.424644e-05\n",
            "\t\t7000\t10647.358\t7.557055e-05\n",
            "\t\t8000\t9948.931\t5.889105e-05\n",
            "\t\t9000\t9382.136\t4.8086084e-05\n",
            "\t\t10000\t8960.187\t4.2830874e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8960.187\t4.2830874e-05\n",
            "\n",
            "\tBest loss outter loop: 8960.1865234375\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [4693.2983]\n",
            "N =  0  J =  4 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20161.4\t0.00018770748\n",
            "\t\t2000\t17179.494\t0.00014595578\n",
            "\t\t3000\t15079.502\t0.00011849845\n",
            "\t\t4000\t13533.057\t9.675889e-05\n",
            "\t\t5000\t12348.607\t8.7537e-05\n",
            "\t\t6000\t11252.598\t9.1203256e-05\n",
            "\t\t7000\t10350.813\t7.660345e-05\n",
            "\t\t8000\t9592.475\t6.779758e-05\n",
            "\t\t9000\t9038.735\t5.34779e-05\n",
            "\t\t10000\t8628.762\t4.1080937e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8628.762\t4.1080937e-05\n",
            "\n",
            "\tBest loss: 8628.76171875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20789.902\t0.00018635383\n",
            "\t\t2000\t17762.633\t0.00014765038\n",
            "\t\t3000\t15587.813\t0.00011945757\n",
            "\t\t4000\t13960.807\t0.00010176732\n",
            "\t\t5000\t12699.069\t8.404499e-05\n",
            "\t\t6000\t11660.531\t8.0309226e-05\n",
            "\t\t7000\t10724.085\t7.666879e-05\n",
            "\t\t8000\t9984.854\t6.3862186e-05\n",
            "\t\t9000\t9418.566\t4.852215e-05\n",
            "\t\t10000\t9011.775\t3.510908e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9011.775\t3.510908e-05\n",
            "\n",
            "\tBest loss outter loop: 9011.775390625\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [4443.981]\n",
            "N =  0  J =  5 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19630.637\t0.00018552136\n",
            "\t\t2000\t16804.717\t0.00014177416\n",
            "\t\t3000\t14788.69\t0.00011587697\n",
            "\t\t4000\t13321.71\t9.404287e-05\n",
            "\t\t5000\t12158.058\t9.051498e-05\n",
            "\t\t6000\t11119.841\t8.860417e-05\n",
            "\t\t7000\t10178.496\t8.4615174e-05\n",
            "\t\t8000\t9425.445\t6.941332e-05\n",
            "\t\t9000\t8861.345\t5.4768774e-05\n",
            "\t\t10000\t8426.167\t4.4734013e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8426.167\t4.4734013e-05\n",
            "\n",
            "\tBest loss: 8426.1669921875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20839.164\t0.00018619445\n",
            "\t\t2000\t17786.328\t0.00014613637\n",
            "\t\t3000\t15606.778\t0.00012056358\n",
            "\t\t4000\t13976.883\t0.000101999554\n",
            "\t\t5000\t12711.695\t9.156575e-05\n",
            "\t\t6000\t11574.425\t8.267816e-05\n",
            "\t\t7000\t10705.098\t7.2973926e-05\n",
            "\t\t8000\t9993.053\t6.185556e-05\n",
            "\t\t9000\t9425.558\t5.325164e-05\n",
            "\t\t10000\t9022.68\t3.7339403e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9022.68\t3.7339403e-05\n",
            "\n",
            "\tBest loss outter loop: 9022.6796875\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [4586.049]\n",
            "N =  0  J =  6 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21175.338\t0.00018397663\n",
            "\t\t2000\t18142.426\t0.00014283793\n",
            "\t\t3000\t15966.708\t0.000114116054\n",
            "\t\t4000\t14345.682\t0.000101487465\n",
            "\t\t5000\t13011.857\t9.36558e-05\n",
            "\t\t6000\t11864.522\t8.954468e-05\n",
            "\t\t7000\t10924.68\t7.669116e-05\n",
            "\t\t8000\t10176.799\t6.7167275e-05\n",
            "\t\t9000\t9557.17\t5.0781447e-05\n",
            "\t\t10000\t9149.889\t3.5112753e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9149.889\t3.5112753e-05\n",
            "\n",
            "\tBest loss: 9149.888671875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20824.395\t0.00018688902\n",
            "\t\t2000\t17779.092\t0.0001474039\n",
            "\t\t3000\t15605.326\t0.00011769686\n",
            "\t\t4000\t14002.386\t9.923384e-05\n",
            "\t\t5000\t12714.974\t9.399942e-05\n",
            "\t\t6000\t11577.902\t8.8978275e-05\n",
            "\t\t7000\t10675.526\t7.6743105e-05\n",
            "\t\t8000\t9955.185\t6.758349e-05\n",
            "\t\t9000\t9378.758\t4.914455e-05\n",
            "\t\t10000\t9001.185\t3.6669175e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9001.185\t3.6669175e-05\n",
            "\n",
            "\tBest loss outter loop: 9001.1845703125\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [4770.8564]\n",
            "N =  0  J =  7 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21802.871\t0.00017886145\n",
            "\t\t2000\t18730.723\t0.00014022869\n",
            "\t\t3000\t16528.875\t0.000115551455\n",
            "\t\t4000\t14818.974\t0.00010160666\n",
            "\t\t5000\t13474.408\t9.58757e-05\n",
            "\t\t6000\t12274.825\t0.00010039232\n",
            "\t\t7000\t11247.7\t8.0912774e-05\n",
            "\t\t8000\t10402.135\t7.087511e-05\n",
            "\t\t9000\t9753.498\t5.8869642e-05\n",
            "\t\t10000\t9291.296\t4.2355558e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9291.296\t4.2355558e-05\n",
            "\n",
            "\tBest loss: 9291.2958984375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20740.537\t0.00018660902\n",
            "\t\t2000\t17719.959\t0.00014679383\n",
            "\t\t3000\t15555.433\t0.000119141325\n",
            "\t\t4000\t13960.301\t9.736486e-05\n",
            "\t\t5000\t12736.536\t8.855075e-05\n",
            "\t\t6000\t11649.687\t9.019011e-05\n",
            "\t\t7000\t10693.6\t7.935265e-05\n",
            "\t\t8000\t9944.992\t6.431451e-05\n",
            "\t\t9000\t9387.864\t5.2217285e-05\n",
            "\t\t10000\t8989.859\t3.6389505e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8989.859\t3.6389505e-05\n",
            "\n",
            "\tBest loss outter loop: 8989.859375\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [4614.1895]\n",
            "N =  0  J =  8 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22595.06\t0.00018175102\n",
            "\t\t2000\t19373.062\t0.00014132481\n",
            "\t\t3000\t17004.428\t0.000119439916\n",
            "\t\t4000\t15213.096\t0.0001036597\n",
            "\t\t5000\t13760.329\t9.7218646e-05\n",
            "\t\t6000\t12510.035\t9.241726e-05\n",
            "\t\t7000\t11481.746\t8.258011e-05\n",
            "\t\t8000\t10620.43\t7.263626e-05\n",
            "\t\t9000\t10000.734\t5.0189108e-05\n",
            "\t\t10000\t9580.08\t3.730747e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9580.08\t3.730747e-05\n",
            "\n",
            "\tBest loss: 9580.080078125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20817.168\t0.0001868601\n",
            "\t\t2000\t17765.992\t0.00014685314\n",
            "\t\t3000\t15578.362\t0.00012047011\n",
            "\t\t4000\t13976.488\t9.683295e-05\n",
            "\t\t5000\t12725.641\t9.399736e-05\n",
            "\t\t6000\t11607.464\t9.1106966e-05\n",
            "\t\t7000\t10703.088\t7.745777e-05\n",
            "\t\t8000\t9986.892\t6.306698e-05\n",
            "\t\t9000\t9419.087\t5.380656e-05\n",
            "\t\t10000\t8977.867\t4.0244922e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8977.867\t4.0244922e-05\n",
            "\n",
            "\tBest loss outter loop: 8977.8671875\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [5006.245]\n",
            "N =  0  J =  9 I =  8\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t23141.662\t0.00018977653\n",
            "\t\t2000\t19642.188\t0.00015439904\n",
            "\t\t3000\t17064.387\t0.00013114962\n",
            "\t\t4000\t15129.425\t0.000110815316\n",
            "\t\t5000\t13629.115\t0.000104028855\n",
            "\t\t6000\t12331.777\t9.2248694e-05\n",
            "\t\t7000\t11312.916\t8.752365e-05\n",
            "\t\t8000\t10471.401\t6.723591e-05\n",
            "\t\t9000\t9846.196\t5.841461e-05\n",
            "\t\t10000\t9376.373\t3.6764097e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9376.373\t3.6764097e-05\n",
            "\n",
            "\tBest loss: 9376.373046875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20850.693\t0.00018712152\n",
            "\t\t2000\t17795.143\t0.00014705151\n",
            "\t\t3000\t15613.037\t0.00011913953\n",
            "\t\t4000\t13976.072\t9.9909674e-05\n",
            "\t\t5000\t12692.811\t9.093273e-05\n",
            "\t\t6000\t11653.944\t8.085731e-05\n",
            "\t\t7000\t10685.266\t7.6947304e-05\n",
            "\t\t8000\t9977.39\t6.312704e-05\n",
            "\t\t9000\t9381.607\t4.923371e-05\n",
            "\t\t10000\t9001.278\t3.4390632e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9001.278\t3.4390632e-05\n",
            "\n",
            "\tBest loss outter loop: 9001.2783203125\n",
            "\n",
            "OUTTER FOLDER: 8 OUTTER MSE:  [5288.8916]\n",
            "N =  0  J =  0 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20951.176\t0.00019060407\n",
            "\t\t2000\t17783.338\t0.00015296829\n",
            "\t\t3000\t15500.046\t0.00012750352\n",
            "\t\t4000\t13751.603\t0.00011140926\n",
            "\t\t5000\t12364.897\t0.0001000559\n",
            "\t\t6000\t11211.0205\t8.9799636e-05\n",
            "\t\t7000\t10283.582\t7.9572885e-05\n",
            "\t\t8000\t9485.21\t7.679953e-05\n",
            "\t\t9000\t8905.36\t5.4278793e-05\n",
            "\t\t10000\t8450.85\t5.0034072e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8450.85\t5.0034072e-05\n",
            "\n",
            "\tBest loss: 8450.849609375\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20957.82\t0.00019166154\n",
            "\t\t2000\t17812.818\t0.00015479783\n",
            "\t\t3000\t15539.803\t0.0001251669\n",
            "\t\t4000\t13850.889\t0.00010433711\n",
            "\t\t5000\t12586.102\t8.960905e-05\n",
            "\t\t6000\t11490.815\t8.7273365e-05\n",
            "\t\t7000\t10579.169\t7.762664e-05\n",
            "\t\t8000\t9870.01\t6.856238e-05\n",
            "\t\t9000\t9320.997\t4.588723e-05\n",
            "\t\t10000\t8957.817\t3.412144e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8957.817\t3.412144e-05\n",
            "\n",
            "\tBest loss outter loop: 8957.8173828125\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8136.2295]\n",
            "N =  0  J =  1 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20463.363\t0.00019991722\n",
            "\t\t2000\t17272.049\t0.00015568706\n",
            "\t\t3000\t14961.315\t0.00013091949\n",
            "\t\t4000\t13263.777\t0.00010866057\n",
            "\t\t5000\t11968.1045\t9.978328e-05\n",
            "\t\t6000\t10904.253\t8.39983e-05\n",
            "\t\t7000\t10065.764\t7.198234e-05\n",
            "\t\t8000\t9327.797\t6.731358e-05\n",
            "\t\t9000\t8795.044\t4.8964277e-05\n",
            "\t\t10000\t8374.656\t5.7601657e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8374.656\t5.7601657e-05\n",
            "\n",
            "\tBest loss: 8374.65625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21177.164\t0.0001917972\n",
            "\t\t2000\t17979.623\t0.00015466507\n",
            "\t\t3000\t15656.706\t0.00012604082\n",
            "\t\t4000\t13964.636\t0.00010320767\n",
            "\t\t5000\t12690.969\t9.310011e-05\n",
            "\t\t6000\t11604.177\t8.642086e-05\n",
            "\t\t7000\t10662.655\t8.022393e-05\n",
            "\t\t8000\t9899.109\t6.18507e-05\n",
            "\t\t9000\t9346.014\t4.9525683e-05\n",
            "\t\t10000\t8944.931\t3.8537277e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8944.931\t3.8537277e-05\n",
            "\n",
            "\tBest loss outter loop: 8944.9306640625\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8132.618]\n",
            "N =  0  J =  2 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19762.623\t0.00019801458\n",
            "\t\t2000\t16737.738\t0.00015330702\n",
            "\t\t3000\t14522.507\t0.00012936219\n",
            "\t\t4000\t12882.446\t0.00011036088\n",
            "\t\t5000\t11612.996\t9.8041906e-05\n",
            "\t\t6000\t10570.332\t9.284043e-05\n",
            "\t\t7000\t9746.0205\t7.604689e-05\n",
            "\t\t8000\t9055.986\t6.1894105e-05\n",
            "\t\t9000\t8566.41\t4.6395457e-05\n",
            "\t\t10000\t8188.872\t4.2393294e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8188.872\t4.2393294e-05\n",
            "\n",
            "\tBest loss: 8188.8720703125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21131.89\t0.00019091458\n",
            "\t\t2000\t17962.092\t0.00015242456\n",
            "\t\t3000\t15642.128\t0.00012547169\n",
            "\t\t4000\t13950.248\t0.000103524064\n",
            "\t\t5000\t12650.908\t9.6018965e-05\n",
            "\t\t6000\t11530.85\t8.341396e-05\n",
            "\t\t7000\t10608.188\t9.1772825e-05\n",
            "\t\t8000\t9893.432\t5.991227e-05\n",
            "\t\t9000\t9390.481\t4.429988e-05\n",
            "\t\t10000\t9047.755\t4.0365776e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9047.755\t4.0365776e-05\n",
            "\n",
            "\tBest loss outter loop: 9047.7548828125\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8096.5913]\n",
            "N =  0  J =  3 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20294.6\t0.00019609592\n",
            "\t\t2000\t17186.107\t0.00015816961\n",
            "\t\t3000\t14933.625\t0.00012717425\n",
            "\t\t4000\t13266.41\t0.000108565415\n",
            "\t\t5000\t12000.981\t9.560478e-05\n",
            "\t\t6000\t10928.553\t9.238847e-05\n",
            "\t\t7000\t10071.525\t7.213506e-05\n",
            "\t\t8000\t9451.238\t5.6206405e-05\n",
            "\t\t9000\t8973.07\t4.9407554e-05\n",
            "\t\t10000\t8606.514\t3.9031413e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8606.514\t3.9031413e-05\n",
            "\n",
            "\tBest loss: 8606.513671875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20980.861\t0.0001907997\n",
            "\t\t2000\t17819.291\t0.00015309801\n",
            "\t\t3000\t15553.624\t0.00012430245\n",
            "\t\t4000\t13880.93\t0.00010228253\n",
            "\t\t5000\t12621.567\t8.804218e-05\n",
            "\t\t6000\t11543.82\t7.9429454e-05\n",
            "\t\t7000\t10698.433\t7.092023e-05\n",
            "\t\t8000\t10009.46\t6.653419e-05\n",
            "\t\t9000\t9440.727\t5.9992446e-05\n",
            "\t\t10000\t8982.124\t4.4574397e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8982.124\t4.4574397e-05\n",
            "\n",
            "\tBest loss outter loop: 8982.1240234375\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8274.752]\n",
            "N =  0  J =  4 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t20104.379\t0.0001940665\n",
            "\t\t2000\t17047.98\t0.00015028847\n",
            "\t\t3000\t14895.02\t0.000120818055\n",
            "\t\t4000\t13349.628\t0.00010123321\n",
            "\t\t5000\t12145.132\t9.262113e-05\n",
            "\t\t6000\t11091.475\t8.698211e-05\n",
            "\t\t7000\t10225.356\t7.897557e-05\n",
            "\t\t8000\t9493.87\t6.521052e-05\n",
            "\t\t9000\t8972.892\t4.7449703e-05\n",
            "\t\t10000\t8569.525\t4.1364896e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8569.525\t4.1364896e-05\n",
            "\n",
            "\tBest loss: 8569.525390625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21021.432\t0.00019089592\n",
            "\t\t2000\t17875.934\t0.00015348678\n",
            "\t\t3000\t15585.173\t0.00012373763\n",
            "\t\t4000\t13908.929\t0.00010502492\n",
            "\t\t5000\t12642.791\t8.7739936e-05\n",
            "\t\t6000\t11576.021\t8.52815e-05\n",
            "\t\t7000\t10634.273\t7.8234414e-05\n",
            "\t\t8000\t9936.039\t5.8574362e-05\n",
            "\t\t9000\t9410.308\t4.4102784e-05\n",
            "\t\t10000\t9022.054\t4.1454856e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9022.054\t4.1454856e-05\n",
            "\n",
            "\tBest loss outter loop: 9022.0537109375\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8124.9985]\n",
            "N =  0  J =  5 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t19788.602\t0.00019055241\n",
            "\t\t2000\t16851.299\t0.00015273751\n",
            "\t\t3000\t14746.483\t0.00012110796\n",
            "\t\t4000\t13214.863\t9.812797e-05\n",
            "\t\t5000\t12032.24\t9.397694e-05\n",
            "\t\t6000\t11008.754\t8.772433e-05\n",
            "\t\t7000\t10120.269\t7.5743395e-05\n",
            "\t\t8000\t9417.316\t6.397794e-05\n",
            "\t\t9000\t8902.404\t4.6070403e-05\n",
            "\t\t10000\t8532.097\t4.2690826e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8532.097\t4.2690826e-05\n",
            "\n",
            "\tBest loss: 8532.0966796875\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21013.922\t0.00019124286\n",
            "\t\t2000\t17854.38\t0.00015443754\n",
            "\t\t3000\t15567.128\t0.00012588798\n",
            "\t\t4000\t13897.298\t0.000102021564\n",
            "\t\t5000\t12608.965\t9.254401e-05\n",
            "\t\t6000\t11529.453\t8.2577186e-05\n",
            "\t\t7000\t10646.152\t7.484538e-05\n",
            "\t\t8000\t9940.601\t6.601278e-05\n",
            "\t\t9000\t9370.694\t5.210455e-05\n",
            "\t\t10000\t8964.193\t3.4859702e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8964.193\t3.4859702e-05\n",
            "\n",
            "\tBest loss outter loop: 8964.193359375\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [7775.1797]\n",
            "N =  0  J =  6 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21310.73\t0.0001885798\n",
            "\t\t2000\t18151.557\t0.00015201705\n",
            "\t\t3000\t15890.275\t0.00011767556\n",
            "\t\t4000\t14224.0205\t0.00010098259\n",
            "\t\t5000\t12935.739\t9.118767e-05\n",
            "\t\t6000\t11876.595\t7.99993e-05\n",
            "\t\t7000\t10954.156\t8.896374e-05\n",
            "\t\t8000\t10158.849\t6.392186e-05\n",
            "\t\t9000\t9604.523\t4.7582736e-05\n",
            "\t\t10000\t9223.614\t3.1444284e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9223.614\t3.1444284e-05\n",
            "\n",
            "\tBest loss: 9223.6142578125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21112.572\t0.0001908118\n",
            "\t\t2000\t17947.123\t0.00015472753\n",
            "\t\t3000\t15630.757\t0.0001240639\n",
            "\t\t4000\t13950.021\t0.00010275586\n",
            "\t\t5000\t12650.503\t9.3860974e-05\n",
            "\t\t6000\t11540.862\t9.019445e-05\n",
            "\t\t7000\t10583.067\t8.138076e-05\n",
            "\t\t8000\t9840.197\t6.9365466e-05\n",
            "\t\t9000\t9289.096\t4.488849e-05\n",
            "\t\t10000\t8924.282\t3.4249657e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8924.282\t3.4249657e-05\n",
            "\n",
            "\tBest loss outter loop: 8924.2822265625\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8584.5]\n",
            "N =  0  J =  7 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22043.164\t0.00018585783\n",
            "\t\t2000\t18829.154\t0.00014623618\n",
            "\t\t3000\t16515.21\t0.00012226815\n",
            "\t\t4000\t14761.796\t0.000103323\n",
            "\t\t5000\t13395.999\t9.906069e-05\n",
            "\t\t6000\t12207.72\t8.734744e-05\n",
            "\t\t7000\t11260.407\t7.431808e-05\n",
            "\t\t8000\t10427.302\t7.7165256e-05\n",
            "\t\t9000\t9771.456\t5.576359e-05\n",
            "\t\t10000\t9322.399\t4.2109503e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9322.399\t4.2109503e-05\n",
            "\n",
            "\tBest loss: 9322.3994140625\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21028.2\t0.00019269141\n",
            "\t\t2000\t17856.818\t0.00015091746\n",
            "\t\t3000\t15567.491\t0.00012500702\n",
            "\t\t4000\t13920.11\t0.00010143354\n",
            "\t\t5000\t12655.889\t9.212377e-05\n",
            "\t\t6000\t11543.74\t8.721161e-05\n",
            "\t\t7000\t10654.788\t7.07525e-05\n",
            "\t\t8000\t9976.265\t6.969182e-05\n",
            "\t\t9000\t9402.772\t5.3276824e-05\n",
            "\t\t10000\t8984.538\t3.5432884e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8984.538\t3.5432884e-05\n",
            "\n",
            "\tBest loss outter loop: 8984.5380859375\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8199.487]\n",
            "N =  0  J =  8 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22731.945\t0.00018641129\n",
            "\t\t2000\t19396.957\t0.0001510157\n",
            "\t\t3000\t16925.92\t0.00012599278\n",
            "\t\t4000\t15059.485\t0.00010847727\n",
            "\t\t5000\t13599.255\t9.9231576e-05\n",
            "\t\t6000\t12353.135\t9.3432885e-05\n",
            "\t\t7000\t11307.542\t8.2038896e-05\n",
            "\t\t8000\t10508.2295\t6.458435e-05\n",
            "\t\t9000\t9943.867\t4.988693e-05\n",
            "\t\t10000\t9488.6455\t4.394451e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9488.6455\t4.394451e-05\n",
            "\n",
            "\tBest loss: 9488.6455078125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21140.014\t0.00019194948\n",
            "\t\t2000\t17944.037\t0.00015508058\n",
            "\t\t3000\t15640.691\t0.00012498385\n",
            "\t\t4000\t13942.3545\t0.0001058936\n",
            "\t\t5000\t12674.225\t8.644382e-05\n",
            "\t\t6000\t11629.382\t8.992777e-05\n",
            "\t\t7000\t10712.384\t8.112761e-05\n",
            "\t\t8000\t9966.177\t6.231628e-05\n",
            "\t\t9000\t9427.936\t4.733464e-05\n",
            "\t\t10000\t9027.328\t3.9591752e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9027.328\t3.9591752e-05\n",
            "\n",
            "\tBest loss outter loop: 9027.328125\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [8466.188]\n",
            "N =  0  J =  9 I =  9\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t22885.219\t0.00019002584\n",
            "\t\t2000\t19438.467\t0.00015461068\n",
            "\t\t3000\t16915.85\t0.00012826099\n",
            "\t\t4000\t15014.545\t0.00010763143\n",
            "\t\t5000\t13564.126\t9.516962e-05\n",
            "\t\t6000\t12288.334\t0.00010036142\n",
            "\t\t7000\t11273.828\t8.133152e-05\n",
            "\t\t8000\t10449.552\t6.5040425e-05\n",
            "\t\t9000\t9856.196\t5.112322e-05\n",
            "\t\t10000\t9454.591\t3.976498e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t9454.591\t3.976498e-05\n",
            "\n",
            "\tBest loss: 9454.5908203125\n",
            "\n",
            "Optimal N:  25\n",
            "\n",
            "\tReplicate: 1/1\n",
            "\t\tIter\tLoss\t\t\tRel. loss\n",
            "\t\t1000\t21024.592\t0.00019207444\n",
            "\t\t2000\t17850.855\t0.00015370238\n",
            "\t\t3000\t15566.834\t0.00012444785\n",
            "\t\t4000\t13890.032\t0.00010193434\n",
            "\t\t5000\t12616.614\t9.063058e-05\n",
            "\t\t6000\t11540.553\t8.232856e-05\n",
            "\t\t7000\t10578.553\t7.9384874e-05\n",
            "\t\t8000\t9846.899\t6.346773e-05\n",
            "\t\t9000\t9285.469\t5.268792e-05\n",
            "\t\t10000\t8883.372\t3.7375317e-05\n",
            "\t\tFinal loss:\n",
            "\t\t10000\t8883.372\t3.7375317e-05\n",
            "\n",
            "\tBest loss outter loop: 8883.3720703125\n",
            "\n",
            "OUTTER FOLDER: 9 OUTTER MSE:  [7714.384]\n",
            "ERROR TEST:  [array([22499.97], dtype=float32), array([21841.355], dtype=float32), array([22616.877], dtype=float32), array([23225.662], dtype=float32), array([23403.312], dtype=float32), array([23010.328], dtype=float32), array([22820.36], dtype=float32), array([22512.95], dtype=float32), array([23255.418], dtype=float32), array([22013.2], dtype=float32), array([16983.314], dtype=float32), array([17123.088], dtype=float32), array([17478.559], dtype=float32), array([17471.816], dtype=float32), array([17266.77], dtype=float32), array([17521.438], dtype=float32), array([16967.547], dtype=float32), array([17320.906], dtype=float32), array([17569.67], dtype=float32), array([17463.342], dtype=float32), array([17554.783], dtype=float32), array([17005.613], dtype=float32), array([17375.504], dtype=float32), array([17096.797], dtype=float32), array([17010.645], dtype=float32), array([17087.74], dtype=float32), array([17411.424], dtype=float32), array([17012.244], dtype=float32), array([17470.998], dtype=float32), array([17318.537], dtype=float32), array([18093.28], dtype=float32), array([17578.139], dtype=float32), array([18168.713], dtype=float32), array([17764.207], dtype=float32), array([18000.246], dtype=float32), array([17417.63], dtype=float32), array([17752.271], dtype=float32), array([17439.828], dtype=float32), array([17525.506], dtype=float32), array([17682.889], dtype=float32), array([14660.121], dtype=float32), array([14619.607], dtype=float32), array([14694.652], dtype=float32), array([14624.031], dtype=float32), array([14518.011], dtype=float32), array([14587.206], dtype=float32), array([14660.076], dtype=float32), array([14552.257], dtype=float32), array([14786.587], dtype=float32), array([14579.094], dtype=float32), array([11051.492], dtype=float32), array([10704.066], dtype=float32), array([10987.019], dtype=float32), array([11323.897], dtype=float32), array([11359.609], dtype=float32), array([11091.43], dtype=float32), array([11332.413], dtype=float32), array([11267.28], dtype=float32), array([11124.642], dtype=float32), array([11026.793], dtype=float32), array([5996.8296], dtype=float32), array([5724.0557], dtype=float32), array([5905.073], dtype=float32), array([5859.3623], dtype=float32), array([5642.2256], dtype=float32), array([5923.672], dtype=float32), array([5452.916], dtype=float32), array([6004.144], dtype=float32), array([5750.568], dtype=float32), array([6022.606], dtype=float32), array([4802.706], dtype=float32), array([4821.8496], dtype=float32), array([4825.7734], dtype=float32), array([4682.909], dtype=float32), array([4618.3535], dtype=float32), array([5018.044], dtype=float32), array([4812.2075], dtype=float32), array([4698.8125], dtype=float32), array([4861.5117], dtype=float32), array([4753.3896], dtype=float32), array([4751.288], dtype=float32), array([5171.8296], dtype=float32), array([4912.262], dtype=float32), array([4693.2983], dtype=float32), array([4443.981], dtype=float32), array([4586.049], dtype=float32), array([4770.8564], dtype=float32), array([4614.1895], dtype=float32), array([5006.245], dtype=float32), array([5288.8916], dtype=float32), array([8136.2295], dtype=float32), array([8132.618], dtype=float32), array([8096.5913], dtype=float32), array([8274.752], dtype=float32), array([8124.9985], dtype=float32), array([7775.1797], dtype=float32), array([8584.5], dtype=float32), array([8199.487], dtype=float32), array([8466.188], dtype=float32), array([7714.384], dtype=float32)] GENERALIZED ERROR:  72408.38526089722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Statistical Analysis"
      ],
      "metadata": {
        "id": "hb5FpXUi1qWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats\n",
        "import numpy as np, scipy.stats as st\n",
        "alpha = 0.05\n",
        "\n",
        "# for i, (par_index, test_index) in enumerate(CV1.split(X,y)):\n",
        "#   print(test_index)\n",
        "\n",
        "#ann_predictions_test = np.concatenate(ann_predictions_test)\n",
        "\n",
        "temp1 = np.arange(184, 1840, 1)\n",
        "temp2 = np.arange(2024, 3680, 1)\n",
        "temp3 = np.arange(3864, 5520, 1)\n",
        "temp4 = np.arange(5704, 7360, 1)\n",
        "temp5 = np.arange(7544, 9200, 1)\n",
        "temp6 = np.arange(9384, 11040, 1)\n",
        "temp7 = np.arange(11224, 12880, 1)\n",
        "temp8 = np.arange(13063, 14710, 1)\n",
        "temp9 = np.arange(14893, 16540, 1)\n",
        "temp10 = np.arange(16723, 18370, 1)\n",
        "\n",
        "\n",
        "temp11 = np.concatenate((temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8 , temp9, temp10))\n",
        "print(temp11)\n",
        "\n",
        "#ann_predictions_test = np.delete(ann_predictions_test, temp11)\n",
        "\n",
        "\n",
        "#lin_predictions_test = np.concatenate(lin_predictions_test)\n",
        "#ann_predictions_test = np.concatenate(ann_predictions_test)\n",
        "#baseline_reg_predictions_test = np.concatenate(baseline_reg_predictions_test)\n",
        "#test_reg_true_values = np.concatenate(test_reg_true_values)\n",
        "\n",
        "# Linear to ANN\n",
        "print('Linear to ANN')\n",
        "zA = np.abs(test_reg_true_values - lin_predictions_test) ** 2\n",
        "zB = np.abs(test_reg_true_values - ann_predictions_test) ** 2\n",
        "print('Confidence interval Linear Regression')\n",
        "CIA = st.t.interval(1-alpha, df=len(zA)-1, loc=np.mean(zA), scale=st.sem(zA))\n",
        "print(CIA)\n",
        "print('Confidence interval ANN')\n",
        "CIB = st.t.interval(1-alpha, df=len(zB)-1, loc=np.mean(zB), scale=st.sem(zB))\n",
        "print(CIB)\n",
        "\n",
        "z=zA-zB\n",
        "print('z value')\n",
        "print(z.mean())\n",
        "print('Confidence Interval')\n",
        "CI = st.t.interval(1-alpha, df=len(z)-1, loc=np.mean(z), scale=st.sem(z))\n",
        "print(CI)\n",
        "p = 2*st.t.cdf(-np.abs(np.mean(z))/st.sem(z), df=len(z)-1)\n",
        "print('p-value')\n",
        "print(p)\n",
        "print('\\n')\n",
        "\n",
        "# Linear to Baseline\n",
        "print('Linear to Baseline')\n",
        "zA = np.abs(test_reg_true_values- lin_predictions_test) ** 2\n",
        "zB = np.abs(test_reg_true_values- baseline_reg_predictions_test) ** 2\n",
        "print('Confidence Interval Linear Regression')\n",
        "CIA = st.t.interval(1-alpha, df=len(zA)-1, loc=np.mean(zA), scale=st.sem(zA))\n",
        "print(CIA)\n",
        "print('Confidence Interval Baseline')\n",
        "CIB = st.t.interval(1-alpha, df=len(zB)-1, loc=np.mean(zB), scale=st.sem(zB))\n",
        "print(CIB)\n",
        "\n",
        "z=zA-zB\n",
        "print('Z value')\n",
        "print(z.mean())\n",
        "print('Confidence Interval')\n",
        "CI = st.t.interval(1-alpha, df=len(z)-1, loc=np.mean(z), scale=st.sem(z))\n",
        "print(CI)\n",
        "print('p-value')\n",
        "p = 2*st.t.cdf(-np.abs(np.mean(z))/st.sem(z), df=len(z)-1)\n",
        "print(p)\n",
        "print('\\n')\n",
        "\n",
        "# ANN to Baseline\n",
        "print('ANN to Baseline')\n",
        "zA = np.abs(test_reg_true_values- ann_predictions_test) ** 2\n",
        "zB = np.abs(test_reg_true_values- baseline_reg_predictions_test) ** 2\n",
        "print('Confidence interval ANN')\n",
        "CIA = st.t.interval(1-alpha, df=len(zA)-1, loc=np.mean(zA), scale=st.sem(zA))\n",
        "print(CIA)\n",
        "print('Confidence interval Baseline')\n",
        "CIB = st.t.interval(1-alpha, df=len(zB)-1, loc=np.mean(zB), scale=st.sem(zB))\n",
        "print(CIB)\n",
        "\n",
        "z=zA-zB\n",
        "print('Z value')\n",
        "print(z.mean())\n",
        "print('Confidence interval')\n",
        "CI = st.t.interval(1-alpha, df=len(z)-1, loc=np.mean(z), scale=st.sem(z))\n",
        "print(CI)\n",
        "print('p-value')\n",
        "p = 2*st.t.cdf(-np.abs(np.mean(z))/st.sem(z), df=len(z)-1)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XupUbuwi1s7x",
        "outputId": "788454b9-003e-4089-b5f9-0d231a1e2fb6"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  184   185   186 ... 18367 18368 18369]\n",
            "1837\n",
            "Linear to ANN\n",
            "Confidence interval Linear Regression\n",
            "(11381.637645941311, 14329.225967304694)\n",
            "Confidence interval ANN\n",
            "(11240.232183142958, 13687.182745239403)\n",
            "z value\n",
            "391.72434243182056\n",
            "Confidence Interval\n",
            "(-541.7001432101493, 1325.1488280737904)\n",
            "p-value\n",
            "0.41057606313977535\n",
            "\n",
            "\n",
            "Linear to Baseline\n",
            "Confidence Interval Linear Regression\n",
            "(11381.637645941311, 14329.225967304694)\n",
            "Confidence Interval Baseline\n",
            "(13037.626096424108, 15823.228913409737)\n",
            "Z value\n",
            "-1574.99569829392\n",
            "Confidence Interval\n",
            "(-2530.867779743117, -619.123616844723)\n",
            "p-value\n",
            "0.0012529080524917562\n",
            "\n",
            "\n",
            "ANN to Baseline\n",
            "Confidence interval ANN\n",
            "(11240.232183142958, 13687.182745239403)\n",
            "Confidence interval Baseline\n",
            "(13037.626096424108, 15823.228913409737)\n",
            "Z value\n",
            "-1966.7200407257405\n",
            "Confidence interval\n",
            "(-2575.175495197768, -1358.2645862537129)\n",
            "p-value\n",
            "2.8957583256261364e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLASSIFICATION"
      ],
      "metadata": {
        "id": "LZ0zOdZ7azEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will turn the variable we want to predict into a class, where if the score of a game is over the mean of the whole dataset, we consider it as a good score and if not we consider it as a bad score."
      ],
      "metadata": {
        "id": "sQodvUXFa5Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = data_csv['Critic_Score'].mean()\n",
        "for i in data_csv.index:\n",
        "    data_csv.at[i, 'Critic_Score'] = 1 if data_csv.at[i, 'Critic_Score'] > mean else 0\n",
        "features_class, response_class = data_csv.drop('Critic_Score', axis=1),data_csv['Critic_Score']"
      ],
      "metadata": {
        "id": "XIdL9uKDoEbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combined model generation thing with two-level cross validation"
      ],
      "metadata": {
        "id": "k_WSysB6qE90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pylab import (figure, semilogx, loglog, xlabel, ylabel, legend, \n",
        "                           title, subplot, show, grid, plot, xscale)\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import sklearn.linear_model as lm\n",
        "from sklearn import model_selection\n",
        "\n",
        "X_log_regr = features_class.to_numpy()\n",
        "attributeNames = features_class.columns.to_numpy()\n",
        "classNames = np.array(['Bad', 'Good'])\n",
        "Y_log_regr = response_class.to_numpy()\n",
        "N, M = X_log_regr.shape\n",
        "\n",
        "def KNN_regression_validate(X,y,lambdas,cvf=10):\n",
        "    CV = model_selection.KFold(cvf, shuffle=False)\n",
        "    M = X.shape[1]\n",
        "    w = np.empty((M,cvf,len(lambdas)))\n",
        "    train_error = np.empty((cvf,len(lambdas)))\n",
        "    test_error = np.empty((cvf,len(lambdas)))\n",
        "    f = 0\n",
        "    y = y.squeeze()\n",
        "    for train_index, test_index in CV.split(X,y):\n",
        "        X_train = X[train_index]\n",
        "        y_train = y[train_index]\n",
        "        X_test = X[test_index]\n",
        "        y_test = y[test_index]\n",
        "        \n",
        "        # Standardize the training and set set based on training set moments\n",
        "        mu[f, 0:6] = np.mean(X_train[:, 0:6], 0)\n",
        "        sigma[f, 0:6] = np.std(X_train[:, 0:6], 0)\n",
        "        \n",
        "        X_train[:, 0:6] = (X_train[:, 0:6] - mu[f, 0:6] ) / sigma[f, 0:6]\n",
        "        X_test[:, 0:6] = (X_test[:, 0:6] - mu[f, 0:6] ) / sigma[f, 0:6]\n",
        "        \n",
        "        for l in range(0, len(lambdas)):\n",
        "          knclassifier = KNeighborsClassifier(n_neighbors=lambdas[l])\n",
        "          knclassifier.fit(X_train, y_train)\n",
        "          y_train_est = knclassifier.predict(X_train)\n",
        "          y_test_est = knclassifier.predict(X_test)\n",
        "          \n",
        "          # MEASURE FOR ERROR IS # OF ERRORS/NUMBER OF TEST VALUES (which is done here)\n",
        "          train_error[f,l] = np.sum(y_train_est != y_train) / len(y_train)\n",
        "          test_error[f,l] = np.sum(y_test_est != y_test) / len(y_test)\n",
        "    \n",
        "        f=f+1\n",
        "\n",
        "    opt_val_err = np.min(np.mean(test_error,axis=0))\n",
        "    opt_lambda = lambdas[np.argmin(np.mean(test_error,axis=0))]\n",
        "    train_err_vs_lambda = np.mean(train_error,axis=0)\n",
        "    test_err_vs_lambda = np.mean(test_error,axis=0)\n",
        "    mean_w_vs_lambda = np.squeeze(np.mean(w,axis=1))\n",
        "    \n",
        "    return opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda\n",
        "\n",
        "def logistic_regression_validate(X,y,lambdas,cvf=10):\n",
        "    CV = model_selection.KFold(cvf, shuffle=False)\n",
        "    M = X.shape[1]\n",
        "    w = np.empty((M,cvf,len(lambdas)))\n",
        "    train_error = np.empty((cvf,len(lambdas)))\n",
        "    test_error = np.empty((cvf,len(lambdas)))\n",
        "    f = 0\n",
        "    y = y.squeeze()\n",
        "    for train_index, test_index in CV.split(X,y):\n",
        "        X_train = X[train_index]\n",
        "        y_train = y[train_index]\n",
        "        X_test = X[test_index]\n",
        "        y_test = y[test_index]\n",
        "\n",
        "        \n",
        "        # Standardize the training and set set based on training set moments\n",
        "        mu[f, 0:6] = np.mean(X_train[:, 0:6], 0)\n",
        "        sigma[f, 0:6] = np.std(X_train[:, 0:6], 0)\n",
        "        \n",
        "        X_train[:, 0:6] = (X_train[:, 0:6] - mu[f, 0:6] ) / sigma[f, 0:6]\n",
        "        X_test[:, 0:6] = (X_test[:, 0:6] - mu[f, 0:6] ) / sigma[f, 0:6]\n",
        "        \n",
        "        for l in range(0, len(lambdas)):\n",
        "          mdl = LogisticRegression(penalty='l2', C=1/lambdas[l], max_iter=1000)\n",
        "          \n",
        "          mdl.fit(X_train, y_train)\n",
        "\n",
        "          y_train_est = mdl.predict(X_train).T\n",
        "          y_test_est = mdl.predict(X_test).T\n",
        "          \n",
        "          # MEASURE FOR ERROR IS # OF ERRORS/NUMBER OF TEST VALUES (which is done here)\n",
        "          train_error[f,l] = np.sum(y_train_est != y_train) / len(y_train)\n",
        "          test_error[f,l] = np.sum(y_test_est != y_test) / len(y_test)\n",
        "    \n",
        "        f=f+1\n",
        "\n",
        "    opt_val_err = np.min(np.mean(test_error,axis=0))\n",
        "    opt_lambda = lambdas[np.argmin(np.mean(test_error,axis=0))]\n",
        "    train_err_vs_lambda = np.mean(train_error,axis=0)\n",
        "    test_err_vs_lambda = np.mean(test_error,axis=0)\n",
        "    mean_w_vs_lambda = np.squeeze(np.mean(w,axis=1))\n",
        "    \n",
        "    return opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda\n",
        "\n",
        "## Crossvalidation\n",
        "# Create crossvalidation partition for evaluation\n",
        "K = 10\n",
        "CV = model_selection.KFold(K, shuffle=False)\n",
        "#CV = model_selection.KFold(K, shuffle=False)\n",
        "\n",
        "# Values of lambda\n",
        "lambdas_interval = np.power(2.,range(-5,8))\n",
        "neighbours_interval = np.arange(1, 501, 10)\n",
        "\n",
        "train_error_rate_class = np.zeros(K)\n",
        "test_error_rate_class = np.zeros(K)\n",
        "train_error_rate_class_KNN = np.zeros(K)\n",
        "test_error_rate_class_KNN = np.zeros(K)\n",
        "test_error_rate_class_baseline = np.zeros(K)\n",
        "\n",
        "w_est = np.empty((M,K))\n",
        "log_predictions_test = []\n",
        "knn_predictions_test = []\n",
        "baseline_predictions_test = []\n",
        "test_true_values = []\n",
        "\n",
        "k=0\n",
        "for train_index, test_index in CV.split(X_log_regr, Y_log_regr):\n",
        "    \n",
        "    # extract training and test set for current CV fold\n",
        "    X_train = X_log_regr[train_index]\n",
        "    y_train = Y_log_regr[train_index]\n",
        "    X_test = X_log_regr[test_index]\n",
        "    y_test = Y_log_regr[test_index]\n",
        "    internal_cross_validation = 10\n",
        "    \n",
        "    opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda = logistic_regression_validate(X_train, y_train, lambdas_interval, internal_cross_validation)\n",
        "\n",
        "    mu[k, 0:6] = np.mean(X_train[:, 0:6], 0)\n",
        "    sigma[k, 0:6] = np.std(X_train[:, 0:6], 0)\n",
        "    \n",
        "    X_train[:, 0:6] = (X_train[:, 0:6] - mu[k, 0:6] ) / sigma[k, 0:6]\n",
        "    X_test[:, 0:6] = (X_test[:, 0:6] - mu[k, 0:6] ) / sigma[k, 0:6]\n",
        "\n",
        "    # logistic regression part\n",
        "    mdl = LogisticRegression(penalty='l2', C=1/opt_lambda, max_iter=1000)\n",
        "    \n",
        "    mdl.fit(X_train, y_train)\n",
        "\n",
        "    y_train_est = mdl.predict(X_train).T\n",
        "    y_test_est = mdl.predict(X_test).T\n",
        "    log_predictions_test.append(y_test_est)\n",
        "    test_true_values.append(y_test)\n",
        "    \n",
        "    # MEASURE FOR ERROR IS # OF ERRORS/NUMBER OF TEST VALUES (which is done here)\n",
        "    train_error_rate_class[k] = np.sum(y_train_est != y_train) / len(y_train)\n",
        "    test_error_rate_class[k] = np.sum(y_test_est != y_test) / len(y_test)\n",
        "\n",
        "    w_est[:,k] = mdl.coef_[0]\n",
        "    \n",
        "    print('Logistic Regression Statistic')\n",
        "    print(k, opt_lambda)\n",
        "    print('Training error: {0}'.format(train_error_rate_class[k]))\n",
        "    print('Test error:     {0}'.format(test_error_rate_class[k]))\n",
        "\n",
        "        # Display the results for the last cross-validation fold\n",
        "    if k == K-1:\n",
        "        figure(k, figsize=(12,8))\n",
        "        title('Optimal lambda: {0}'.format(opt_lambda))\n",
        "        plot(lambdas_interval,train_err_vs_lambda.T,'b.-',lambdas_interval,test_err_vs_lambda.T,'r.-')\n",
        "        xscale('log', basex=2)\n",
        "        xlabel('Regularization factor')\n",
        "        ylabel('Error')\n",
        "        legend(['Train error','Validation error'])\n",
        "        grid()\n",
        "\n",
        "    # KNN section\n",
        "    opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda = KNN_regression_validate(X_train, y_train, neighbours_interval, internal_cross_validation)\n",
        "\n",
        "    knclassifier = KNeighborsClassifier(n_neighbors=opt_lambda)\n",
        "    knclassifier.fit(X_train, y_train)\n",
        "    y_train_est_knn = knclassifier.predict(X_train)\n",
        "    y_test_est_knn = knclassifier.predict(X_test)\n",
        "    knn_predictions_test.append(y_test_est_knn)\n",
        "\n",
        "    train_error_rate_class_KNN[k] = np.sum(y_train_est_knn != y_train) / len(y_train)\n",
        "    test_error_rate_class_KNN[k] = np.sum(y_test_est_knn != y_test) / len(y_test)\n",
        "\n",
        "    print('KNN statistic')\n",
        "    print(k, opt_lambda)\n",
        "    print('Training error: {0}'.format(train_error_rate_class_KNN[k]))\n",
        "    print('Test error:     {0}'.format(test_error_rate_class_KNN[k]))\n",
        "\n",
        "    # Display the results for the last cross-validation fold\n",
        "    if k == K-1:\n",
        "        figure(k+1, figsize=(12,8))\n",
        "        title('Optimal neighbours: {0}'.format(opt_lambda))\n",
        "        plot(neighbours_interval,train_err_vs_lambda.T,'b.-',neighbours_interval,test_err_vs_lambda.T,'r.-')\n",
        "        xlabel('Number of Neighbours')\n",
        "        ylabel('Error')\n",
        "        legend(['Train error','Validation error'])\n",
        "        grid()\n",
        "\n",
        "    # Baseline model\n",
        "    dummy_clf = DummyClassifier(strategy='most_frequent') #use most_frequent strategy\n",
        "    dummy_clf.fit(X_train,y_train)\n",
        "    y_test_predict_baseline = dummy_clf.predict(X_test)\n",
        "    baseline_predictions_test.append(y_test_predict_baseline)\n",
        "    test_error_rate_class_baseline[k] = np.sum(y_test_predict_baseline != y_test) / len(y_test)\n",
        "\n",
        "    print('Baseline statistic')\n",
        "    print('Test error:     {0}'.format(test_error_rate_class_baseline[k]))\n",
        "\n",
        "    k+=1\n",
        "\n",
        "opt_fold_idx_regression = np.argmin(test_error_rate_class)\n",
        "print('index for the fold with lowest error for regression: {0}', opt_fold_idx_regression)\n",
        "print(w_est[:, opt_fold_idx_regression])\n",
        "\n",
        "# print(knn_predictions_test)\n",
        "# print(log_predictions_test)\n",
        "# print(test_true_values)"
      ],
      "metadata": {
        "id": "5KZJ7qe7qETw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82c914aa-a890-4514-d82d-9158f71c0a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Statistic\n",
            "0 16.0\n",
            "Training error: 0.2383545069570478\n",
            "Test error:     0.13043478260869565\n",
            "KNN statistic\n",
            "0 61\n",
            "Training error: 0.249848759830611\n",
            "Test error:     0.13043478260869565\n",
            "Baseline statistic\n",
            "Test error:     0.13043478260869565\n",
            "Logistic Regression Statistic\n",
            "1 32.0\n",
            "Training error: 0.249848759830611\n",
            "Test error:     0.20108695652173914\n",
            "KNN statistic\n",
            "1 151\n",
            "Training error: 0.25650332728372655\n",
            "Test error:     0.22282608695652173\n",
            "Baseline statistic\n",
            "Test error:     0.23369565217391305\n",
            "Logistic Regression Statistic\n",
            "2 8.0\n",
            "Training error: 0.2365396249243799\n",
            "Test error:     0.25\n",
            "KNN statistic\n",
            "2 131\n",
            "Training error: 0.24924379915305506\n",
            "Test error:     0.32608695652173914\n",
            "Baseline statistic\n",
            "Test error:     0.2554347826086957\n",
            "Logistic Regression Statistic\n",
            "3 8.0\n",
            "Training error: 0.23774954627949182\n",
            "Test error:     0.22282608695652173\n",
            "KNN statistic\n",
            "3 91\n",
            "Training error: 0.2516636418632789\n",
            "Test error:     0.29347826086956524\n",
            "Baseline statistic\n",
            "Test error:     0.3532608695652174\n",
            "Logistic Regression Statistic\n",
            "4 16.0\n",
            "Training error: 0.24198427102238354\n",
            "Test error:     0.25\n",
            "KNN statistic\n",
            "4 151\n",
            "Training error: 0.24621899576527526\n",
            "Test error:     0.24456521739130435\n",
            "Baseline statistic\n",
            "Test error:     0.4891304347826087\n",
            "Logistic Regression Statistic\n",
            "5 16.0\n",
            "Training error: 0.2335148215366001\n",
            "Test error:     0.30978260869565216\n",
            "KNN statistic\n",
            "5 71\n",
            "Training error: 0.23109497882637628\n",
            "Test error:     0.34782608695652173\n",
            "Baseline statistic\n",
            "Test error:     0.5054347826086957\n",
            "Logistic Regression Statistic\n",
            "6 16.0\n",
            "Training error: 0.24016938898971568\n",
            "Test error:     0.20652173913043478\n",
            "KNN statistic\n",
            "6 121\n",
            "Training error: 0.25529340592861466\n",
            "Test error:     0.2608695652173913\n",
            "Baseline statistic\n",
            "Test error:     0.5217391304347826\n",
            "Logistic Regression Statistic\n",
            "7 32.0\n",
            "Training error: 0.23941958887545345\n",
            "Test error:     0.2896174863387978\n",
            "KNN statistic\n",
            "7 71\n",
            "Training error: 0.24425634824667472\n",
            "Test error:     0.3114754098360656\n",
            "Baseline statistic\n",
            "Test error:     0.6120218579234973\n",
            "Logistic Regression Statistic\n",
            "8 32.0\n",
            "Training error: 0.23155985489721886\n",
            "Test error:     0.366120218579235\n",
            "KNN statistic\n",
            "8 71\n",
            "Training error: 0.24123337363966144\n",
            "Test error:     0.3770491803278688\n",
            "Baseline statistic\n",
            "Test error:     0.7431693989071039\n",
            "Logistic Regression Statistic\n",
            "9 8.0\n",
            "Training error: 0.22914147521160821\n",
            "Test error:     0.31693989071038253\n",
            "KNN statistic\n",
            "9 71\n",
            "Training error: 0.24062877871825877\n",
            "Test error:     0.3114754098360656\n",
            "Baseline statistic\n",
            "Test error:     0.7213114754098361\n",
            "index for the fold with lowest error for regression: {0} 0\n",
            "[ 0.11101737  0.41153207  0.41335508 -0.05979886  0.10843147  1.2092258\n",
            "  0.         -0.04559744  0.06703138  0.          0.04545407  0.\n",
            " -0.06656777 -0.01500958  0.2841769   0.20484647  0.21546962 -0.15001365\n",
            "  0.00217458  0.01174268 -0.43877578  0.0589787   0.07860892 -0.05491335\n",
            " -0.07490517 -0.47793557 -0.08775444  0.23853284  0.08562325  0.11947383\n",
            " -0.23512461 -0.07122257  0.14451328  0.08079068 -0.13064931 -0.03610913\n",
            "  0.14022409 -0.03250322 -0.00655821 -0.18790979  0.16119325  0.17367578]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAHwCAYAAABtz0NOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iUVfrG8fukEelFBQRpNor0AAKWIHYUBHXVFQXLWnZ1V1fRxVXsbS3rb9W17KrsWsCyiijYNa5KdCmidARFxIKCSkgoaef3xzPDTEIICck7k8x8P9f1XlPfmTMzycw9Z55zjvPeCwAAAEDNpcS7AQAAAECiIFwDAAAAtYRwDQAAANQSwjUAAABQSwjXAAAAQC0hXAMAAAC1hHANALvIOdfBOZfvnEsN4Lavd849GcDtHuKcW1bF62Y759ZUcvlk59zNtdc6AKj/CNcAkoZzbrxzboFzbpNz7nvn3IPOuebV2H+Vc+6I8Gnv/WrvfWPvfUkwLa593vv3vfcHxLsdsRT6AhS9lTjn7gtdluGcez702nrnXHacmwugniNcA0gKzrnLJd0haYKkZpIOktRR0pvOuYx4tg2Vc86l1WT/0Begxt77xpLaSNos6bmoq3wgaayk72tyPwAgEa4BJAHnXFNJN0i6xHv/mve+yHu/StKvJHWSBatwKcbzzrlnnHMbnXPznHO9Q5c9IamDpJdDvZ9XOuc6hXo700LXyXHO3eycmxW6zsvOuVbOuaecc3nOudnOuU5R7fo/59zXocvmOucOqeLjyXbOrXHOXe6c+8E5951z7uyoyxs45+5yzq12zq11zj3knNstet+o6/Zzzn0SerzPhR77zeXur8L7CdndOfdmaP/3nHMdo/YbEnrMG0KHQ6IuK/MrQHQZTNTzeq5zbrWkd5xzmc65J51z651zv4Rur3VVnq9yTpL0g6T3Jcl7X+i9v9d7/4GkevMLBIC6i3ANIBkMkZQp6YXoM733+ZJmSjoy6uxRsl7NlpKeljTNOZfuvT9T0mpJJ4R6Qf+yg/s6TdKZktpJ2kdSrqTHQ7e3RNJ1UdedLalP1H0955zLrOJjaiPrgW8n6VxJDzjnWoQuu13S/qHb3jd0nUnlbyDUY/+ipMmhNkyRNLoa9yNJZ0i6SdLukuZLeip02y0lzZD0N0mtJN0jaYZzrlUVH58kHSapm6SjJY0LtWPv0O1dKOuBlnPuT865V6p4m+Mk/dt776vRDgCoMsI1gGSwu6R13vviCi77LnR52Fzv/fPe+yJZIMyUlZBU1ePe+5Xe+w2SXpW00nv/Vui+n5PUN3xF7/2T3vv13vti7/3dkhpIqmo9dJGkG0O98DMl5Us6wDnnJJ0v6TLv/U/e+42SbpWF/vIOkpQm6W+h23lB0v+qcj9Rl8/w3v/Xe79V0p8lDXbO7S1phKTPvfdPhB7fFElLJZ1QxccnSdd77wu895tD7WglaV/vfYn3fq73Pk+SvPe3e++P39mNhXrVD5P0r2q0AQCqpUZ1bABQT6yTlS+kVRCw24YuD/s6fMR7XxoqodirGve1Nur45gpONw6fcM5dIesN3kuSl9RUZYN+ZdaXeyybQre9h6SGkuZazra7klTRjCZ7SfqmXC/u1+Wus6P72e763vt859xPodvdS9JX5W7rK1kPeFVFt+UJWa/11NAg1Ccl/Tn0JaiqzpT0gff+y2rsAwDVQs81gGSQK2mrpDHRZzrnGks6VtLbUWfvHXV5iqT2kr4NnVVrpQSh+uorZXXfLbz3zSVtkAXhmlgnC/E9vPfNQ1uz0GC+8r6T1M5FpXBFPf4qin6+GsvKS74NbR3LXbeDpG9CxwtkXwLC2lRw29ue71DP+Q3e++6yMp/jJZ1VzbaeJXqtAQSMcA0g4YVKNG6QdJ9z7hjnXHpoYOGzktbIekXD+jvnxoQGKV4qC+UfhS5bK6lLLTWriaRiST9KSnPOTZL1XNeI975U0j8k/dU5t6ckOefaOeeOruDqubJBfBc759Kcc6MkDazmXR7nnDs4VL99k6SPvPdfy2rZ93fO/Tp026dK6i4pXBs9X9JpodciS9LJld2Jc26Yc66nsznF82RlIqVVbWRoMGU7lZ0lJHxZg6ha94zQ4MmafskBkKQI1wCSQmgA4tWS7pKFs49lZQfDQ/XCYS9JOlXSz7IygjFRpQe3SbomNFvFFTVs0uuSXpO0XFYusUXbl2TsqqskrZD0kXMuT9JbqqCW23tfKOvNP1fSL7JZU16RfaGoqqdlgzR/ktQ/dBvy3q+X9S5fLmm9rJf+eO99uATnWtmAz59lX3ye3sn9tJH0vOy1WyLpPYW+FDnnrnbOvbqT/cdJeiFUg17eMllvfzvZ67JZ2/e6A0CVOAZMA4Bxzl0vGzA3Nt5tiRfn3MeSHvLePx7vtgBAfUTPNQAkMefcYc65NqHSjXGSesl61AEAu4DZQgAguR0gqz1vJOkLSSd777+Lb5MAoP6iLAQAAACoJZSFAAAAALWEcA0AAADUkoSpud599919p06dYn6/BQUFatSoUczvF/HB651ceL2TC6938uE1Ty61+XrPnTt3nfd+j4ouS5hw3alTJ82ZMyfm95uTk6Ps7OyY3y/ig9c7ufB6Jxde7+TDa55cavP1ds59taPLKAsBAAAAagnhGgAAAKglhGsAAACgliRMzTUAAEBdU1RUpDVr1mjLli3xbkrSa9asmZYsWVKtfTIzM9W+fXulp6dXeR/CNQAAQEDWrFmjJk2aqFOnTnLOxbs5SW3jxo1q0qRJla/vvdf69eu1Zs0ade7cucr7URYCAAAQkC1btqhVq1YE63rIOadWrVpV+1cHwjUAAECACNb11668doRrAACABLV+/Xr16dNHffr0UZs2bdSuXbttpwsLCyvdd86cOfr9738fo5YmDmquAQAAElSrVq00f/58SdL111+vxo0b64orrth2eXFxsdLSKo6DWVlZysrKqvU2lZSUKDU1dYenq7pfXUXPNQAAQB2SmyvddpsdBmH8+PG68MILNWjQIF155ZX63//+p8GDB6tv374aMmSIli1bJslWNDz++OMlWTA/55xzlJ2drS5duuhvf/tbhbf9xhtvaPDgwerXr59OOeUU5efnS7KVtK+66ir169dPzz333Hanp0yZop49e+rAAw/UVVddte32GjdurMsvv1y9e/dWblBPSC2j5xoAACAGLr1UCnUi79CGDdJnn0mlpVJKitSrl9Ss2Y6v36ePdO+91W/LmjVrNGvWLKWmpiovL0/vv/++0tLS9NZbb+nqq6/Wf/7zn+32Wbp0qd59911t3LhRBxxwgC666KIyU9StW7dON998s9566y01atRId9xxh+655x5NmjRJkvWiz5s3T5L0pz/9advpb7/9VgcddJDmzp2rFi1a6KijjtK0adN04oknqqCgQIMGDdLdd99d/QcZJ4RrAACAOmLDBgvWkh1u2FB5uN5Vp5xyyrYSiw0bNmjcuHH6/PPP5ZxTUVFRhfuMGDFCDRo0UIMGDbTnnntq7dq1at++/bbLP/roIy1evFhDhw6VJBUWFmrw4MHbLj/11FPL3F749OzZs5Wdna099thDknTGGWfov//9r0488USlpqbqpJNOqr0HHgOEawAAgBioSg9zbq40fLhUWChlZEhPPSVF5dNa06hRo23Hr732Wg0bNkwvvviiVq1apezs7Ar3adCgwbbjqampKi4uLnO5915HHnmkpkyZstP7rOh0RTIzM+tFnXU0aq4BAADqiMGDpbfflm66yQ6DCNblbdiwQe3atZMkTZ48eZdv56CDDtKHH36oFStWSJIKCgq0fPnyne43cOBAvffee1q3bp1KSko0ZcoUHXbYYbvcjngjXAMAANQhgwdLEyfGJlhL0pVXXqmJEyeqb9++2/VGV8cee+yhyZMn6/TTT1evXr00ePBgLV26dKf7tW3bVrfffruGDRum3r17q3///ho1atQutyPenPc+3m2oFVlZWX7OnDkxv9+cnJwd/nyCxMPrnVx4vZMLr3fyicVrvmTJEnXr1i3Q+0DVVHf587CKXkPn3FzvfYXzFNJzXUPN5s+X/vzn4ObLAQAAQL3BgMaa+PBD9bnsMsk56a9/jV1xFAAAAOokeq5r4r//tUPvbVhvTk5cmwMAAID4IlzXRHa2fHjJ0LQ0iVo9AACApEa4ronBg/XpHXdYsD7hBEpCAAAAkhzhuoY29OsnHX+89NFHVh4CAACApEW4rg1jxkhr1khxmAoQAABgR4YNG6bXX3+9zHn33nuvLrrooh3uk52drfD0xscdd5x++eWX7a5z/fXX66677qr0vqdNm6bFixdvOz1p0iS99dZb1Wl+vUS4rg3HH2+lIS+8EO+WAAAAbHP66adr6tSpZc6bOnWqTj/99CrtP3PmTDVv3nyX7rt8uL7xxht1xBFH7NJtVVf5xXCqujhOTRbRCSNc14YWLaRhwyxcUxoCAABqIjdXuu22WllD4+STT9aMGTNUWFgoSVq1apW+/fZbHXLIIbrooouUlZWlHj166Lrrrqtw/06dOmndunWSpFtuuUX777+/Dj74YC1btmzbdf7xj39owIAB6t27t0466SRt2rRJs2bN0vTp0zVhwgT16dNHK1eu1Pjx4/X8889Lkt5++2317dtXPXv21DnnnKOtW7duu7/rrrtO/fr1U8+ePStc4bGkpEQTJkzQgAED1KtXLz388MOSbFGgQw45RCNHjlT37t23O71lyxadffbZ6tmzp/r27at3331Xki35PnLkSB1++OEaPnx4jZ9z5rmuLWPGSBddJC1ZInXvHu/WAACAuubSS6X58yu/zoYN0mefSaWlUkqK1KuX1KzZjq/fp4907707vLhly5YaOHCgXn31VY0aNUpTp07Vr371KznndMstt6hly5YqKSnR8OHD9dlnn6lXr14V3s7cuXM1depUzZ8/X8XFxerXr5/69+8vSRozZox+85vfSJKuueYaPfroo7rkkks0cuRIHX/88Tr55JPL3NaWLVs0fvx4vf3229p///111lln6cEHH9Sll14qSdp99901b948/f3vf9ddd92lf/7zn2X2f/TRR9WsWTPNnj1bW7du1dChQ3XUUUdJkubNm6eFCxeqc+fOysnJKXP61ltvlXNOCxYs0NKlS3XUUUdp+fLl2/b77LPP1LJly0penKqh57q2jBpli8lQGgIAAHbVhg0WrCU73LChxjcZXRoSXRLy7LPPql+/furbt68WLVpUpoSjvPfff1+jR49Ww4YN1bRpU40cOXLbZQsXLtQhhxyinj176qmnntKiRYsqbc+yZcvUuXNn7b///pKkcePG6b/htUNkYV2S+vfvr1WrVm23/xtvvKF///vf6tOnjwYNGqT169fr888/lyQNHDhQnTt33nbd6NO5ubkaO3asJKlr167q2LHjtnB95JFH1kqwlui5rj1t29pUfC+8IF1zTbxbAwAA6ppKepi3yc2Vhg+3xekyMqSnnqrxVL+jRo3SZZddpnnz5mnTpk3q37+/vvzyS911112aPXu2WrRoofHjx2vLli27dPvjx4/XtGnT1Lt3b02ePFk5NVxUr0GDBpKk1NTUCmugvfe67777dPTRR5c5PycnR40aNSpzXvnTO1LV61UFPde1acwY6ZNPpC+/jHdLAABAfTR4sPT229JNN9lhLayh0bhxYw0bNkznnHPOtl7rvLw8NWrUSM2aNdPatWv16quvVnobhx56qKZNm6bNmzdr48aNevnll7ddtnHjRrVt21ZFRUV66qmntp3fpEkTbdy4cbvbOuCAA7Rq1SqtWLFCkvTEE0/osMMOq/LjOfroo/Xggw+qqKhIkrR8+XIVFBTsdL8hQ4Zsa9/y5cu1evVqHXDAAVW+36oiXNem0aPtcNq0+LYDAADUX4MHSxMn1uridKeffro+/fTTbeG6d+/e6tu3r7p27apf//rXGjp0aKX79+vXT6eeeqp69+6tY489VgMGDNh22U033aRBgwZp6NCh6tq167bzTzvtNN15553q27evVq5cue38zMxMPf744zrllFPUs2dPpaSk6MILL6zyYznvvPPUvXt39evXTwceeKAuuOCCKs3ycd5556m0tFQ9e/bUqaeeqsmTJ2/rJa9NzifI7BZZWVl+Thzmmc7JyVF29LLnffpITZpI778f87YgeNu93khovN7Jhdc7+cTiNV+yZIm6desW6H2gajZu3KgmTZpUe7+KXkPn3FzvfVZF16fnuraNGSN9+KH0/ffxbgkAAABijHBd28aMsbmuX3op3i0BAABAjBGua1uPHtJ++0kvvhjvlgAAACDGCNe1zTkb2Pj229Ivv8S7NQAAIM4SZXxbMtqV145wHYQxY6TiYumVV+LdEgAAEEeZmZlav349Abse8t5r/fr1yszMrNZ+LCIThAEDpHbtbEGZ0EpAAAAg+bRv315r1qzRjz/+GO+mJL0tW7ZUOyhnZmaqffv21dqHcB2ElBTpxBOlxx6TNm2SGjaMd4sAAEAcpKenl1mOG/GTk5Ojvn37Bn4/lIUEZcwYafNm6fXX490SAAAAxAjhOiiHHiq1bGmlIQAAAEgKhOugpKVJo0ZJL78sFRbGuzUAAACIAcJ1kEaPljZskN59N94tAQAAQAwQroN05JFSo0YsKAMAAJAkCNdBysyURoyQpk2TSkri3RoAAAAEjHAdtNGjpbVrpdzceLcEAAAAASNcB+2446SMDGYNAQAASAKE66A1bWq11y++KLH0KQAAQEIjXMfCmDHSqlXS/PnxbgkAAAACRLiOhRNOsCXRKQ0BAABIaITrWNhjD1uxkXANAACQ0AjXsTJmjLR4sbRsWbxbAgAAgIAEGq6dc8c455Y551Y45/5UweUXOucWOOfmO+c+cM51j7psYmi/Zc65o4NsZ0yceKIdsqAMAABAwgosXDvnUiU9IOlYSd0lnR4dnkOe9t739N73kfQXSfeE9u0u6TRJPSQdI+nvodurv/beWxowgNIQAACABBZkz/VASSu891947wslTZU0KvoK3vu8qJONJIXnqhslaar3fqv3/ktJK0K3V7+NGSPNni19/XW8WwIAAIAABBmu20mKTpFrQueV4Zz7nXNupazn+vfV2bfeGTPGDqdNi287AAAAEIi0eDfAe/+ApAecc7+WdI2kcVXd1zl3vqTzJal169bKyckJpI2Vyc/Pr9b9DmrTRrrtNi1JSVFejx7BNQyBqO7rjfqN1zu58HonH17z5BKr1zvIcP2NpL2jTrcPnbcjUyU9WJ19vfePSHpEkrKysnx2dnYNmrtrcnJyVOX7zc2V1q2TiovV7/LLpXfflQYPDrR9qF3Ver1R7/F6Jxde7+STtK95bq6UkyNlZydVDonV6x1kuJ4taT/nXGdZMD5N0q+jr+Cc2897/3no5AhJ4ePTJT3tnLtH0l6S9pP0vwDbGhs5OZEl0LdutfKQJPqjBgAAtWzWLGnmTKl3b6lLF2nDBikvzw6jj4cPV62y8V+lpVJGhs1idtxx8X4UCSWwcO29L3bOXSzpdUmpkh7z3i9yzt0oaY73frqki51zR0gqkvSzQiUhoes9K2mxpGJJv/PelwTV1pjJzrY/5MJCqaTE/qAnTZIaNYp3ywAAQF1Qvld50yabCGH16u23ZcukbyorCgjZbTepaVOpWTOpoMCCtWR5ZMQIaeBAC9gjRkj9+tmq0thlgdZce+9nSppZ7rxJUcf/UMm+t0i6JbjWxcHgwdLbb9s/TYMG0hVXSOPHS88+KzkX79YBAIB4ev556de/loqKLBc0aWI9ztGck/baS+rQQWrZUvr2W/tVPCVFOuMM6ZxzLEQ3a2aBumlT69gLy82Vhg+3YJ2WJp15prRwoXTDDdL110utW0vHHmth+6ij7HZQLXEf0Jh0Bg+OlIKUlkoTJkg33yxde2182wUAAGLv+++tk+3pp6WPP46c773UtastQtehg62X0aGD1K6dlJ5u14kOyhkZ0kUX7bzcNLqjL7rm+scfpddftxKTl16SJk+28D10qNSjh4X3UaOkI46o/eegpER65ZVImw4/XGrceOcdj3W0dpxwHU+XXy599pmVhhx4oDR6dLxbBAAAdqS2wtwvv9iick8/bZMblJZazfRFF0mPP2491xkZ0r33Vn4/OwrKOxPd0Re2xx7S2LG2FRdb0J8xQ3ruOem99+w6999vpaxduljQD2/h4N+hg/Wqp6eXfa66dy9bzlK+zGXNGgvYkj1mycJ8uAe+om3jRmnKFNuvQQN7HupIwCZcx5Nz0iOPSMuX288ys2ZJvXrFu1UAAKC8adOkU06x4JmaauUXBx8cCZXt25ctvwgLh8yDDrLe4aefll591Xqb99lHuvpq6fTTLYBKlgeqE5YrCso1Fe6xHjrUSlOuvdZCrHNSz57SnntaKM7NlX76qey+KSlSq1bS+vWR2u6Kbj8cyA85xML1e+9FyluOOkrq3z8yKDO8ff21lbBs2CD9/HNkkojCQnvOCNeQJGVm2sDGrCxp5EgbwbvHHvFuFQAAKC2V3nhDevBB6eWXI2GupET6xz9sC3PO6pWje3RLSmzfwsLI9dq2lX77W6utzsravvQhiLBcE9GTMWRkSPfcU7Z9BQXb90TPmGFfJCR7fMccY2PMws9L69b2BSWsfHnLpEk7fw5mzbISlfA+dWhKRcJ1XdC2rX0jPvRQ6eSTpTffrPjbLwAACN4PP1h5xsMPS19+aT21Y8daiUS4ZGPmTKt/rqjcYcECC5ibN0du0znp3HOlhx4qGyzrup2VnjRqZLXhXbtGzjv22LJh+dpra7+8ZciQXSuJiQHCdV0xYID06KM20veSS+yfjxlEAABB894Gss2bJw0bVqdCSkx5L73/vvU0/+c/FqKzs6XbbrMxUeEBg+XD3H777fj2XntNGjMmEsjPOad+Beuw6vam70pY3pUe+7rWyx9CuK5Lfv1rqyW67Tarvf7d7+LdIgBAfVN+0F1+fqRHNfrn+/Dxr76y8CdZvev550dKFnbbLZ6PJHBNFy2S3nnHBse9/rq0ZInUvLmVbVxwgdStW9kdqhPmnLMe3HfeqZO9q4Gro8E3FgjXdc3NN1vA/sMf7J/68MPj3SIAQH3gvfTEE9J550XmSW7c2IJjtJSUyDzJ/ftbaeIHH9j+paX2y+lDD9mMD/3726C98OC2+j4myHsbPBcq2+j70EORQXfdukmPPSadeqrUsGHt3WcSh8xkRbiua1JSpCeftH/EU06R/vc/G00MAEB5+fn28/uMGVYDHL1an/c2A0V4nuTwlGnhqdLCyg8me+EFC+cffmih+29/k+66y667//4Wstu0sVki+vWz2SPC9xet/OnFi62XfMSIYMJm+R779euts2rBgrKH5RdlkaxU48wzpbPPrv12IekQruuipk2l6dNtOdKRI+0No2nTeLcKAFBTtTFP8uefW5CeMcOmLysstOnSjjxSOuAA6a9/jdT4/vWvu76oyAkn2OGWLdLcuRa2P/zQ6pErCqhVdcstVnJy8MEWzHv2tC8BjRpV73a8t4D/9dc2o8c119g0ec5ZaUf0FHHNm9v9jB1r60oceKC0aZNKR41SanFxnZttAvUb4bqu2mcfG5V81FG2BOmxx1qJCD8tAUD9NGuWDRgsLLRfKYcPt/f66KWqyy+U0bSptHSpfR4UFEiffGLhWrLZGS6+2HqCDz44MsvUCSfUzqIiYZmZkbIQSbr1Vpv9obTUHsdZZ0mnnWaXlR+IHz49ZYr0r3/ZPs7Zkt0PPWTBPXy9Ll0sAB94oB2WlFio79TJvjxEz8oR3jZt2r693ts+V18dua22bSucJODTu+9Wv7y85KuHRqAI13XZ4Ydb7fU999ib8i231KkViAAAVTRvng0SDM93XFpqwXH+fFsQI3oe5MocdJD0+99bp0uXLhVfJ+ga32HDbEW8cBnJ+efv/P4aN5amTo3s8/zz9uvsF19sX7YxffqOFx9p08ZKW3r0sE6ncLnLL7/YJADhHvv776/Sc5DXowc91qh1hOu6rlUr+7btvbR1a51agQgAsBM//CD9+c821Wrz5lbrXFpqAfCVVyLv51u2WKlF+RXpnn7aaqC9t7rgkSOttzqednWatYr22W8/28aMiVx3yxZpwgTp73+P9I5fdpl1MDVosOP76NYtOWflQJ1DuK7rhg2zn+Q2b7Y3mX33jXeLACAhuZISWzF3yZKaz/dcWGi9pzfcYKULl11mq84tXlxxAMzMtG3PPcveTtu2Vl9d11ahC3JO4sxM6+V/9NHI4z7ppMqD9a62CQgA4bquC3/bf/FFq0+76Sarr6vNaYIAIJl4b7NqLFhQZjtk4UKr85Wsl/i666yXuEWL6t3+a69Jl14qLVtmpQt//asNNJRisxhHIkjWx42EQLiuD8JvxsOH2xv1+efbXKas4AgAO5abK736qk09530kSC9caDW6Ye3aST17Kq+0VM0XLrTrlpRYT/MNN9j774gRVufcs+eO33s//9x6qGfMsFKHV16x/WoqWXtkk/Vxo94jXNcnRx8t3XijjdI+6KD4190BQCyVn8autFRau7bs7BHhVQcXL7ae42hNm1o4Pu20yBRwPXpILVtKkr544AH1mzAhUopw7712ezNmSBMn2ta+vYXsESNs0PmCBdZTvWKFzeiRmSn95S82GD08eweApEK4rm+uvlr6+GPrHenXTxoyJN4tAoDgPfOMLfJRVGQD3Nq0kX78MbJsd1jjxlLHjtb7HB4MnpIiXXGFdPvtlf7il9ejR8WlCDfdZFPHvfqq1T8//bT0yCNSWpoF/PDMFiNGSP/8p7UNQNIiXNc3KSlWEpKVZSs4zp3LGzmA+PvgA+m//635QMBoa9bY9G1TpthUdmGlpdLuu1vYDk/FFt6aNbMAXX7VwRNPrFop3Y5KEfbaSzr3XNsKC+3xXnedHUpWox1euRBAUiNc10fNm9sKWYMHS6eeKr31VtmlbAEgVtatk668Unr8cTudkmIB9PTTbR7j6q66t26dzYE8ZYr0/vvW8zxggM3t/MgjkXmMH3qo8hAf5IC4jAwrCdltt7IBvq7M5B518r4AACAASURBVAEgrgjX9VXv3vZBc+aZVgd4113xbhGAZLJqlXT33TZd2ubNkfNLS6V//MO21FSpb9/I6n5Dh1oPcHkbN0ovvWSB+o03bAnrbt1sMOHpp0emID3ttOrPrRzkgDhmtABQAcJ1fTZ2rPTRR/YBN2iQlYkAQJA+/dQG7D3zjPVSjx0rHXlkpFwiI8OmDi0pkT780LaHH5b+7/9s/86dLWS3bWtlH2vXWgnH5s1W1vHHP9ocx716bV/GURdnj6iLbQIQV4Tr+u6ee6zu+uyzpQMPtN4eAKhN3lvv7B13SK+/boMGL7vMZsRo396u06nT9j24xx1nh4WF0iefRML2jBnSzz9Hbn/MGAvVgwdbYAeAeoxwXd9lZNj0T/37S6NHS//7n003heRRfnoyoLzcXOndd6s+2DD8N3XIIdazfMcd0uzZUuvW0q23ShddZGM/olXWg5uRYb+uDRpkIfrWW21K0dJSKx3JyrLebABIAITrRNC+vf1Ee8QR0jnnWNhmgZnEVlJiX6Qeflj697+tZzE9XXrvPQI2IgoLpeuvtynovLfzWre2JbabNYtsTZtGjq9fL913X2SKO++lffaxAYTjxtk8zjU1bJgtZc1AQAAJiHCdKLKz7QN0wgSrwb7iini3CLVt/Xr7SX7GDFu04qefIvP4ShaGLr7YZlho2DC+bUV85eXZgOe//tXmZw5zzlYj7NBB2rBB+u47aelSO75hw/ZzRks2oPCJJ6yHubYwEBBAAiNcJ5LLL7cBjldeaSuTnXNO3fnQonSh6sLP1WGHWUieMcMWrvjoo8j8viNG2Na8uZUDFRZacJo3z6Y/e+456u+T0dq1NnDw73+3sHz44faF++qrI73E999f8f+g99KWLdI770gnnxyZ8u6SS2o3WIcxEBBAgiJcJxLnpAsvlF54wVYJe/xxm9oq3rOI5Obah3xhof0U/Pbb9fZDtemiRfZ4gvqS8PLLkWAT7pGWrKb+mmtsgFhWVtmwE90DmJ8vnXGGzQv80EM2kwMS34oVNh3n5Mn2fzZmjHTVVfZ3IFmt886+3Dpn8zaPGGEBmy/DQMKqbn9XLPrHduU+6mq/HeE60cyebaPtS0psO/VUW5DhqqtsufRYKi21MobLL7ceMckOc3Lq1n9BVRQVSY88oj5/+IM9r+npVobzq1/Zz+y7UuNeWmo/yX/wgW0ffih98UXZ65x0kvU0VrbqW/kewPnzbT7gM8+0FfP+7/8sNCHxzJ1rgw3/8x9binvcOCsJ23//sterbi8xvcpArQk6yJa/flGR9MMP9kNWRduyZfYjp/f20dWrl33E7Lab/VhafvvhBxveU1xsH3233GL9PTu6fnp6ZJHUnBzp4IOl7t1tgqBffqn4cOlS61sqKbG+o+xsm60zPX3H23ffWR9iSUnd67cjXCea7Gz7Kbew0P76TjrJ/mKffdYGPP7pT9aLHOSAxx9+sL/4hx+WvvxSatHCPvhLSuy/ed264O67Nn33nfTqq1aS8cYb0saN2vasFRXZl4bLL7fSjAMPlHr2LHvYooVdN/wOM3iwPQ8ffhgJ0+HpyPbc02ZLGDHCamWLi+11vPzy6i+nvNde1vM4aZJ022028PHZZ7cPXKgbqvJJWlJiC62Ea6Nfe83+TlautMGIEybYtHht28ay5QAqsWmTVfWdeaZ9ZKSnSzffLO23X6T/q6TE3u7Dx5cts6ESxcX2cXH22TYGubBQ2ro1chg+/t139lFSWmof602a2JCLijRsaB8nxcWRH0a9t7eWzEwbnrFpU9mt/DCMwkJ7u6lMaqqF3U2bqvY8paXZ9UtK7HRJiU2n/8UXdv8VbeHrRrerLvXbEa4TTUUDhTZssBKBe++1gN2/v/VkjxlTe7WU3ltgfPBB6ykvKrKa4dtus5rguXMt8L36qrXj8MMtSNYl4Rk4Zs60d8RPPrHz27WznuB99lHppElKLSmx4Hv33fa4FyyQFi6Unn7anuuwdu1sJpc5c7Z/J+ja1Z7/gw+2UL3vvpEvPKefXvPfudLSbLqzgw+2d/asLCsV+tWvdu32UHu8ty+gq1dLb75ps3kUF9svTuEvx+EQHd42bqz4ttLT7f/tyCNj+QiApJWbax+xBx5o32W//Vb65puyh+Hj0R8HkgXinQXTaKEfTCXZ20KDBpHD8PENGyxYS/bW0rWrVQ+2br391rhx5DEMHx4ZhvHkkzv+qCkuto+jE06IfEG4/377yCofxDdtsrWgNm2yfWbNivSOjxhhFaotWlh/VPRhw4Y2pCi6TdOnV/7xV1pqkeOYY+rmpEPOR9d11mNZWVl+zpw5Mb/fnJwcZdelV7QyW7bYqP8775Q+/9z+O664wn5K/uSTXfsdKivLvmo/9JC0aJFN5TVunNV+VzSgLj/fQveyZfaf0adPLT/IanrtNetl//ln+wLw00/2hWPIEHuHOu4464kOBd95Dzygfnl5FT9P3tuKcwsXWuBesMDehb/7zi53zuqh77lH2mOP2D3Gr7+28qDcXOm3v7X7b9AgdvdfVXWweG7e/fer348/2heggQOrttPHH1s5VMeO9mm2enXZ7euv7VO2Iq1a2QqG0dPkld/efluaOjUyR/RNN0kTJ9beg05i9er9HLXigQfmKS+vX5m3He/to+CLL+zHoZUr7fi8edajWlFsSkuzsL3XXra1a2eHmzfbgqbhYPrAA1Lfvvavm5pq+0Ufnz/f3q7D44lfe82mm9/Rj83lg3JVSyNiUapS3XbFoua6Nv/HnXNzvfdZFV5GuK6ZevlmXFIiTZsWWRiiRQvrGSsttf/uiRMjJQTR/9Hh459/br9tRQ+6y8qyhSVOPVVq1Kjy+//2W+mgg6wdH38cWeEtlvLzbdq6f/0rct6xx0rjx1svYLiko5xqv967+s5X24qK7HW9+26rvZ840V7HuhJkP/zQnqfoT6CDD44EyszMij9davoJkZdnYTcceqOPL18u/803qnEBlXP2Kduhw/bbzz/b/011P4Hqwt9UAqqX7+fYJnqipf79Ky6jiD785BPp8stLVVycotRU6dBDrQZ45crte53btLF/t9Wr7XRKio0X/8MfLEjvsceOFxeNdc11XVEX20W4ribC9S4IL2l8wQUWtHaFcxYOHnigevt99pmFpy5dbF7mJk127f6ry3sr37jyyrLz/1axB3CXXu+69A4zfbr1nufn22uXkWHlOkOGxL4tP/1ktewzZ9oMNwUFO75uevr2i52UlNjvjuERMEcdFflFoKL3tR9/tDKMkhJ77A0bbn+fqakWhPfeW8rPl//sMwvXKSn25euIIyp/TG+9ZY/He9vn8stt9E96+o73SaQh8vVcvX4/T0A5OVah162b9cH89FPZbf36yPFvvpG++qpm99eqlU2w06WLrZu0zz52vEsX6zPie239F6twTc11MnPOVkr717+sBjrca/ivf0XKNaJHPYQP58+3ObTDv1vtynRvvXrZXMwjRlhv9/Tp1msepDlzrJth1izr1rjuOunSS4Mv2KpLMy+MHGlfhu68017LrVutaO3UU60E5ogjgvui4719qZo507ZZs+zXklatrOwiJ8eCb1qa/TKy117b1x5HbytWlB0Bk5tbdknu8j3dv/wSub73Vu4zZowF6Q4d7LBt28jfYW6uSocNU2p4cOmf/7zz13HQIPuyEv6bGj268mAt7drfR136m0LSKS21Hz/ff186/ngLnDWVl2cfLZ98YuUXH3yw/eRJ0Ro3llq2tK1VK3vbCq+p5Zz9AHnUUTuuVW7QwPqULr20VKWlKcrIsLH/lf1bsfYRqopwDXuHqM68tt26SZ061fwd5uijbbGLCy6Qfv976/0OYhaTtWttEY3HH7eezUcftfKPlBQLWMn2Tjl6tI1IKSy05yAry2YT+ec/LQgedpgF7REjajbDSG6u1R5nZtqn5MyZ1r0kWWnK1VfbfQwYYD3GNS3qmzmz8v3KX/+ee3b6Sfrp3XfvuMZ+B/vw6Yt4q60fNoqLrURiyRLbFi+2w0WLIrOr3nuv/aC03342zKBjR/t4iD4e/s4bblfv3vYddt68SJhesSJyv23a2G2Gw3JKivSb31jfSMuWVrWXkbH9Y47+977++p0/9iOPlLyfv13NdWX4XouqIFzDxGse3PPPt3fVO++0AZZ//GPNbzOssFC67z7pxhtt+PIf/yhde62VFIQl4ztlRQGwqMjqnsOrQf7xj7btu68F7U6drD44K8vOC/ce5+WV7U0On/7yS+t6Cg9jb9jQyipGjLCe8oqmjNuVv8HqBNldCL55PXpU/xeNZPybQlyFB+B99ZVVWk2aZME4NVU67zwLvuV7bcsfX7zY+lgaNrQhOEuWSMuXl52KrX17m6+4Xz8Ls+Fe4q5dLfQuWWITQm3eXLZ9TZvawrKrVkXeEsI6dbLbGz/eBvr17WtvD+XD8rhxlS86u6vfa3v0yKtTs0wgMRCuEX+33249m1dcYTMljB5d89t89VXpsstsVpJjj7WJQw84oOa3myjKB8D0dPtEys62LzpffmnP4YwZNhNMYeHObzM8yWqzZnb98KdoSorVsl9zTfCPo7avD9QBs2bZv2LnzhZUV62yIP3VV5Hj+fnb71dcbP++1dWunVXOHX+8Bdru3S1AhyvGygffe+8tO9PGunVl27ZqlQ1HCL8lOGeVhX/5i4XyiuxKWObfG3UF4Rrxl5JiUwSuWWOD7XJyqj7tWbTcXJvzNzfXtv32s0+k446r9SYnvM6dbdq+3/7Wev5vuME+GVNSbK7ss86KDCwMDzJs3DgyXL78p29tFGUCCay01KqmVqyw7fPP7TC8mEZ5zZtbr++++9q/V7gUIy/PhlWEh8TMnGm9wZXNnDF5sm3h2R1/97vKx3ZXFnyds+q7PfawH7rCyr8lnHvujoN19P0QllEfEa5RN+y2mw1qHDTIZqv/+GP7tNiZTZts4ZcpU6xmONw18rvfWU1t+cI8VN+RR9qvC+FPxd//PpASDKC21bWJWAoL7W3utddsEF5paSRIr1wZqWOW7F9tn33sMLr2+OKL7ftudHVbeQccUL3HkJZmb6HVGdsddBUXUJ8RrlF37LlnZFDaiBFWAxw9+4Mkff+9nR/e5s2z3z6jpaba75oE69qxq5+KdDshTryXXnrJFlYtKrK3hEsusbeFiuY7Dh9fuLCX5s+P9OBecIGVR+y+e9mtWbOyP9KE/zX69LF5kCsq2/jqK/txLlp6uo0Z3ndfG4qw7772g9u++1p9c3icb3SP72mnVR6spbobfHlLQLIgXKNu6dbN5jw++mjrMR0yxGabCIfqlSvtepmZNsvEhAk2jVtamtVq18V1UBMBn4qoA8r3Km/ebIPuli2Tli61bdky26KnMC8ttR+yoqWlbT+w7+efG2+brbG4eMfT96ekWM9zw4a23lD5QXrR97H33lauMXy4Xffddy38p6bajBZXX135Yyb4AvUP4Rp1z+GHS1ddZYtvhBcGat7cPlkuvNAWn+nXb/ueaX5zBOqN8kG5qMgG5RUUVHz46ac21ra42Mok9tzTZtkMT8HvnIXYrl1tueiMDOlvf7Prp6dL//mPvXVkZNhW0Wp6DzywUBMm9Nv2HX36dCvNWL/eBulFb+vXl50QxzmbJv6ssyL1z3vtZSE6+jFH90IPG1a154rgC9QvhGvUTY0a2adf+PfZCROq1sXDJxBQp61fb6H3llsia/qkpW1f3VUZ76XWrW3gXteutu23nw3diDZ6dPW+b/fokVfhd/TOnSu+fvmwfMMNLEICgHCNuio7236nrW4XD4A6Z/ly6wV++eWyvb2S9fgOHWpVYI0a2aQzFR0uW2aTCYVnwXjwwaqNqw1y8UumiwNQEcI16ia6eIB6q7jYenXDgXrZMju/d29bRb5jRxtgGP7ufNttO/8X79GjegvJxgphGUB5hGvUXXxqAfWC9za93JNP2kqBs2db+Ud6uv3odMkltiBJx46Rfbp3ZwIaAImJcA0AKCN6sOGgQTaAb82aHW9ffVV2Ec9jjrEV+I4+2tYYqghBGUCiIlwDQIIrPzNHSYn1MP/wg/Tjj2UPFyywco6SEquHTk3dfrBhWprNhNG+va3+17q1zZQZnmLu0EOlU06JxyMFgPgjXANAAiostKD8zDM2x3M4LDdrZktk72hu5oYNI7N4SDbV/MknW5AOb3vuWfkUc0wzDyCZEa4BoJ4rKbFBg7NnR7ZPP7WVB6N5bysCHnWUBeQ99ih72KqV7RsdlG+/ndXuAaA6Ag3XzrljJP2fpFRJ//Te317u8j9KOk9SsaQfJZ3jvf8qdFmJpAWhq6723o8Msq0AUN7ChU31/vu2OEhdCYwlJbaI6QsvWE/0t99Kc+faQiuSTV3Xv78NIszKsh7ms86KhOV77w1mLmZqqAHABBaunXOpkh6QdKSkNZJmO+eme+8XR13tE0lZ3vtNzrmLJP1F0qmhyzZ77/sE1T4A9V/5WuLqXr+gwJakXr3atujjy5dLa9b0lWTLVI8dK40fb2USDRoE+xi8t9UHly+XPv/cDqO36Bro7t2lceOkAQNsO+CAsiUbktSuHXMxA0CsBNlzPVDSCu/9F5LknJsqaZSkbeHae/9u1PU/kjQ2wPYASBBbtkiPPSZdeqkFzXDv7F57Wc9ucbEdRh//9ltpxoxI7XHjxtLGjWVv1zm7jb33llq0sJkwJKtPfuIJ6d//tlUADznESieOOELq06fipbR3prTU2nPKKbYwSkqKTVv3008WoKPblpEh7buvlXTsvrv0/vuRwYNjx0oTJ1Z+X4RlAIidIMN1O0lfR51eI2lQJdc/V9KrUacznXNzZCUjt3vvp9V+EwFURW6u9O67Fv7iEdI2bLDZKN5/37bZs8tO/VZcbGE7PLtFWpodRh/fvDkyUM97qVs36cQTpQ4dLEx36GA9vOnpkcc8bFipiotTlZFhM2hs3iy99ZaVTVx1lV2vVSvp8MMjYXvtWum996SDD7Z5nb/6Slq1yg6jj69eXbYmurTUHtfAgdYTvf/+ka1Dh0hvNIMHAaBuc977YG7YuZMlHeO9Py90+kxJg7z3F1dw3bGSLpZ0mPd+a+i8dt77b5xzXSS9I2m4935luf3Ol3S+JLVu3br/1KlTA3kslcnPz1fjxo1jfr+Ij7r4ei9a1FTz5zdXnz6/qEePvBrdVkmJ9P33mVq9uqG+/rqhVq9uqKVLm2jlyshj3meffHXuvEl77rlFe+65VXvuuUWtW9th48aRaSaq267o67dtu0WffdYstDXXF180kvdOqaml2n//fPXq9YuaNSvS5MmdVFzslJ7udeedn6pnzx3fz6JFTXX55b1VVGTXv/vuT3farjlz0rRs2V4VPoZ16zL0ySctNHeubevWhWtFot9TXZl9WrQoVOvWW9S69Ra1abNFpaXStGntVVLilJ5eWqU2lX+uavqaI6Iu/n8jWLzmyaU2X+9hw4bN9d5nVXRZkOF6sKTrvfdHh05PlCTv/W3lrneEpPtkwfqHHdzWZEmveO+f39H9ZWVl+Tlz5tRS66suJydH2XQdJY1YvN7la3A3bZK++862778ve3zxYul//7OeWOeknj2tt7R5cytraNEicjz6cMUK631t1Soy08TSpVbfG90jvPvuUqNG1ssavo+OHe3w66+3n/+4SRPrZW3SxHphS0utx/Wkk6xXOCXFNufKHv/mGyu7iO5ZlmxauMGDrQzjkENsQZNGjXb8XFX3ud2Zqr7e3lspx4QJtty3ZI9r1CjpwgulTp3sedltt5q3CcHh/Tz58Jonl9p8vZ1zOwzXQZaFzJa0n3Ous6RvJJ0m6dflGtZX0sOyHu4fos5vIWmT936rc253SUNlgx2BhOS9tHKlNHmyTX0WrgvebTcL1+WlpdnCHeF9w4cbN1ro/ewz6ZdfrJxiZ1JSrJ63a1dpxAgbENe1qx22arV9GcLTT0cWIlm7tuwgwPCgwI8/jgTl4mLpxRet3KK01NoZfRg+Hu3YY20QYd++kTKNilS3ljio2mPn7PmaONHKRsLP1ZVXVm0aO0I1ACSOwMK1977YOXexpNdlU/E95r1f5Jy7UdIc7/10SXdKaizpOeecFJlyr5ukh51zpZJSZDXXiyu8IyCGFixoqpwcW9a5JoGoqEj65BPpgw+slviDD2x1vGjeS717SyNHSm3bSm3a2GHbthZ6U1K2D75PPVW2XSUlFrB/+UX6+Wc7fOwxacqUyIC466+Xrrlmx23d0dRsqak2+G+vvaxHOVr5dr39duXPV/nrX3ut1R7XN8z3DAAIdJ5r7/1MSTPLnTcp6vgRO9hvlqSeQbYNqKqiIgtLDzwgvfSSTc12ww02CG7ffS1ctmsXCZrh423b2pRtubnSa69ZOcb69RamP/7YBsdJUpcuFtYPPthKHn7zm0jIvPvums1JnJoqtWxpW1jDhtaTHL6P4cN3/hzsSg9xdUJmIoVSeqIBILmxQiNQgcJC6Z13pOeek6ZNs+nRossTwstIFxZKs2ZZzXB0rXJYeKnpcNlDSorUr590/vkWpocOtRAerUuXYOckjlWQrSslGwAAxBLhGgjZulV6803p+eell16yEoomTaws4+STref5mGMiU7M98kjZRT9++slC9rff2vbNN9Irr9iAQ8mC9bXXWhlGZWIRMgmyAAAEg3CNpJaTIz36qPTjj1a+kZdnvc2jRtniHkceWXY1vrvv/lR5ef226/F1zuqgW7WSevWKnH/EEWVriY8+OlaPDAAAxAPhGnVWUFOUeW/TxN16q/VQhx1/vPTb31oYzsioeN8ePfKqtWhHItUSAwCAnSNco84pKLBa5wsusGncGjTY+WwTVbFunfTkk9ZTvXChTWcXlpoqDRliU8DVNkowAABIHoRrxERFvdA//ywtWWILoSxZEjn+1Vdl9928WRo7Vjr7bFtmesCAyuc+jlZSYvMOP/qo9VIXFtr+Dz1kAwdHjWIZaQAAUHsI1whcbq6F4q1brYe4Z08b8Ld2beQ6mZm2CMeQIdK559rgv5tvtuCbkmL7XXutbY0bS4ceard5+OE2F3RKStn7XLVKevxxW5Rl9Wqbiu6ii+y2e0ZN8kjJBgAAqE2EawSitNRmyZg2zRYt2bLFzi8utvKM446TunWTune3w44dLUBHO/zwssF33To7/c47ts0MzaDesqVdp1Mnac0a6YsvpLlz7bIjjpD+8hfpxBPLDkwMo2QDAADUJsI1as2WLdYT/NJL0ssvS99/b3XNffrYtHalpVZ+8cwzuzZ/8+6725R4J59sp7/5Rnr33UjQfuEFO985KyGZNMlCOwAAQKwQriGp+jNzhK/fr58t2/3SS7YKYUGBlW0ce6zVMx93nNSiRTAzf7RrZ7XYY8fazB/XXmsBPiXFVk4kWAMAgFgjXNcDL75oy2WPHGk1ybXBe+nLL6WPPrLbf+GFSDDt29d6idPTK97Wr5emT7cSj7C2bS3knniiNGzY9iUYQZdfhO+TwYkAACCeCNd1mPfS734nPfignb7jDlugZOhQ6cADbWDegQdaz/DObNwozZljPcgffWTbjz/aZenpFqwlO/zxRwvZRUUVb3l5kWDtnHThhdL9928/qDCWmE8aAADUBYTrOio/3+qGn38+cp5z0oYN0tNP22FYu3aRoN2zpwXkTz+VGja0QYAffWTzOocDdNeu0ogR0kEH2ZaXZysHhnt9p06tPJzm5pZddfDMM+MbrMMYnAgAAOKNcF0Hff65lVcsXWo91489FgmyU6ZYIF6zxgLzggW2LVxoA/sKC8veVuPG1tM9erTtN3Cgza5RXnV6feklBgAAqBjhuo555RXpjDOsVOONN6yH+Iwztg+ye+9tW/SKgsXF0oQJ0t/+Zr3UqanSxInS1Vfv/H6r2+tLLzEAAMD26sCP+ZAsDN9wg3TCCTbTxdy5FqwlC7ETJ+48zKalSb/6lQ3sS021nu5hw4JvOwAAAAw913XAhg1Wt/zyy9JZZ9nS3Lvttmu3RckGAABA/BCu42zRIquH/vJL6b77rMbauZrdJiUbAAAA8UG4jqPnn5fGj7dBh++8Ix1ySLxbBAAAgJogXMdYbq4F6aVLpSeftBk8nn/eptMDAABA/Ua4jqHw/NCbN9vpUaOkZ57ZfjVDAAAA1E/MFhJDOTnSli12PCVFGjSIYA0AAJBICNcxlJ1tU+RJFqqzs+PZGgAAANQ2wnUMDR5s81Cnpdl0eczoAQAAkFgI1zHWtKnUogXBGgAAIBERrmOsoEBq1CjerQAAAEAQCNcxlp9v81oDAAAg8RCuY4xwDQAAkLgI1zFGWQgAAEDiIlzHGD3XAAAAiYtwHWOEawAAgMRFuI6x/HzKQgAAABIV4TrGCgrouQYAAEhUhOsYKi0lXAMAACQywnUMbdpkh4RrAACAxES4jqGCAjuk5hoAACAxEa5jKD/fDum5BgAASEyE6xgiXAMAACQ2wnUMURYCAACQ2AjXMUTPNQAAQGIjXMcQ4RoAACCxEa5jiHANAACQ2AjXMUTNNQAAQGIjXMcQPdcAAACJjXAdQ+Fw3bBhfNsBAACAYBCuY6igwIJ1Cs86AABAQiLmxVB+PiUhAAAAiYxwHUOEawAAgMRGuI6h/HxmCgEAAEhkhOsYKiig5xoAACCREa5jiLIQAACAxBZouHbOHeOcW+acW+Gc+1MFl//RObfYOfeZc+5t51zHqMvGOec+D23jgmxnrBCuAQAAEltg4do5lyrpAUnHSuou6XTnXPdyV/tEUpb3vpek5yX9JbRvS0nXSRokaaCk65xzLYJqa6wUFFBzDQAAkMiC7LkeKGmF9/4L732hpKmSRkVfwXv/rvd+U+jkR5Lah44fLelN7/1P3vufJb0p6ZgA2xoT9FwDAAAktrQAb7udpK+jTq+R9UTvyLmSXq1k33bld3DOnS/pRDtcBwAAHR9JREFUfElq3bq1cnJyatDcXZOfn1/l+83LO0Q///yNcnK+CLZRCEx1Xm/Uf7zeyYXXO/nwmieXWL3eQYbrKnPOjZWUJemw6uznvX9E0iOSlJWV5bOzs2u/cTuRk5OjqtxvSYm0davUtWsHZWd3CL5hCERVX28kBl7v5MLrnXx4zZNLrF7vIMtCvpG0d9Tp9qHzynDOHSHpz5JGeu+3Vmff+mRTqPiFshAAAIDEFWS4ni1pP+dcZ+dchqTTJE2PvoJzrq+kh2XB+oeoi16XdJRzrkVoIONRofPqrfx8OyRcAwAAJK7AykK898XOuYtloThV0mPe+0XOuRslzfHeT5d0p6TGkp5zzknSau/9SO/9T865m2QBXZJu9N7/FFRbY4FwDQAAkPgCrbn23s+UNLPceZOijh9Ryb6PSXosuNbFVkGBHTIVHwAAQOJihcYYoecaAAAg8RGuY4RwDQAAkPgI1zFCWQgAAEDiI1zHCD3XAAAAiY9wHSOEawAAgMRHuI6RcLimLAQAACBxEa5jpKBAck7abbd4twQAAABBIVzHSH6+9Vqn8IwDAAAkLKJejOTnU28NAACQ6AjXMVJQQL01AABAoiNcxwg91wAAAImPcB0jhGsAAIDER7iOkfCARgAAACQuwnWMFBTQcw0AAJDoCNcxQlkIAABA4iNcxwjhGgAAIPERrmOEqfgAAAASH+E6BoqLpS1b6LkGAABIdITrGCgosEPCNQAAQGIjXMdAOFxTFgIAAJDYCNcxkJ9vh/RcAwAAJDbCdQwQrgEAAJID4ToGwuGashAAAIDERriOAQY0AgAAJAfCdQxQFgIAAJAcdhqunXMpzrkhsWhMoiJcAwAAJIedhmvvfamkB2LQloTFVHwAAADJoaplIW87505yzrlAW5Og6LkGAABIDlUN1xdIek5SoXMuzzm30TmXF2C7Ekp+vpSSImVmxrslAAAACFJaVa7kvW8SdEMSWX6+lYTQ7w8AAJDYqhSuJck5N1LSoaGTOd77V4JpUuIpKKAkBAAAIBlUqSzEOXe7pD9IWhza/uCcuy3IhiWS/HzCNQAAQDKoas/1cZL6hGYOkXPuX5I+kTQxqIYlEsI1AABAcqjOIjLNo443q+2GJLKCAqbhAwAASAZV7bm+VdInzrl3JTlZ7fWfAmtVgsnPl1q1incrAAAAELSdhmvnXIqkUkkHSRoQOvsq7/33QTYskeTnSx07xrsVAAAACNpOw7X3vtQ5d6X3/llJ02PQpoRDWQgAAEByqGrN9VvOuSucc3s751qGt0BblkAY0AgAAJAcqlpzfWro8HdR53lJXWq3OYmJcA0AAJAcqlpz/Sfv/TMxaE/CKSqSCgsJ1wAAAMlgp2UhobmtJ8SgLQmpoMAOqbkGAABIfNRcByw/3w7puQYAAEh81FwHjHANAACQPKoUrr33nYNuSKKiLAQAACB5VFoW4py7Mur4KeUuuzWoRiUSeq4BAACSx85qrk+LOj6x3GXH1HJbEhLhGgAAIHnsLFy7HRyv6DQqEA7XlIUAAAAkvp2Fa7+D4xWdRgXCNdf0XAMAACS+nQ1o7O2cy5P1Uu8WOq7Q6cxAW5YgKAsBAABIHpWGa+99aqwakqgI1wAAAMmjqovI7BLn3DHOuWXOuRXOuT9VcPmhzrl5zrli59zJ5S4rcc7ND23Tg2xnkAoKpNRUKSMj3i0BAABA0Kq6iEy1OedSJT0g6UhJayTNds5N994vjrraaknjJV1RwU1s9t73Cap9sZKfb73WjuGfAAAACS+wcC1poKQV3vsvJMk5N1XSKEnbwrX3flXostIA2xFX4XANAACAxBdkWUg7SV9HnV4TOq+qMp1zc5xzHznnTqzdpsVOfj7T8AEAACSLIHuua6qj9/4b51wXSe845xZ471dGX8E5d76k8yWpdevWysnJiXkj8/PzK73f1at7yvsM5eTMjV2jEJidvd5ILLzeyYXXO/nwmieXWL3eQYbrbyTtHXW6fei8KvHefxM6/MI5lyOpr6SV5a7ziKRHJCkrK8tnZ2fXrMW7ICcnR5Xdb4MGUtu2qvQ6qD929nojsfB6Jxde7+TDa55cYvV6B1kWMlvSfs65zs65DNlS6lWa9cM518I51yB0fHdJQxVVq12fUHMNAACQPAIL1977YkkXS3pd0hJJz3rvFznnbnTOjZQk59wA59waSadIetg5tyi0ezdJc5xzn0p6V9Lt5WYZqTcKCqi5BgAASBaB1lx772dKmlnuvElRx2fLykXK7zdLUs8g2xYr9FwDAAAkj0AXkQHhGgAAIJkQrgNGWQgAAEDyIFwHqLBQKiqi5xoAACBZEK4DlJ9vh4RrAACA5EC4DlA4XFMWAgAAkBwI1wEqKLBDeq4BAACSA+E6QJSFAAAAJBfCdYAI1wAAAMmFcB2gcFkINdcAAADJgXAdIHquAQAAkgvhOkCEawAAgORCuA4QU/EBAAAkF8J1gJiKDwAAILkQrgOUny+lp0sZGfFuCQAAAGKBcB2g/Hx6rQEAAJIJ4TpABQXUWwMAACQTwnWA6LkGAABILoTrABGuAQAAkgvhOkCUhQAAACQXwnWA6LkGAABILoTrABGuAQAAkgvhOkD5+ZSFAAAAJBPCdYAKCui5BgAASCaE64B4T1kIAABAsiFcB2TrVqmkhHANAACQTAjXASkosENqrgEAAJIH4Tog+fl2SM81AABA8iBcB4RwDQAAkHwI1wEJh2vKQgAAAJIH4Tog4Zpreq4BAACSB+E6IJSFAAAAJB/CdUAI1wAAAMmHcB0QpuIDAABIPoTrgNBzDQAAkHwI1wFhthAAAIDkQ7gOSEGBlJEhpafHuyUAAACIFcJ1QPLzKQkBAABINoTrgBCuAQAAkg/hOiCEawAAgORDuA5IQQGDGQEAAJIN4Tog9FwDAAAkH8J1QAjXAAAAyYdwHRDKQgAAAJIP4Tog9FwDAAAkH8J1QAjXAAAAyYdwHQDvLVxTFgIAAJBcCNcB2LLFAjY91wAAAMmFcB2A/Hw7JFwDAAAkF8J1AAjXAAAAyYlwHYCCAjuk5hoAACC5EK4DQM81AABAcgo0XDvnjnHOLXPOrXDO/amCyw91zs1zzhU7504ud9k459znoW1ckO2sbYRrAACA5BRYuHbOpUp6QNKxkrpLOt05173c1VZLGi/p6XL7tpR0naRBkgZKus451yKotta2cLimLAQAACC5BNlzPVDSCu/9F977QklTJY2KvoL3fpX3/jNJpeX2PVrSm977n7z3P0t6U9IxAba1VoVrrum5BgAASC5Bhut2kr6OOr0mdF7Q+8YdZSEAAADJKS3eDaiJ/2/v/oMtr+v7jj9fXFhAyaBBu2MEZYnrKEx1qwtKa5IbSCypRjIZiBiaYMOE2ImWdkob7HRMgkOm1BhNRlOzxq1ITJRo1J0MLXGAK3aGwEIA5UfAFVGXoWIBIeeyu7Lsu3+c79GTm0v27t7POUfu9/mY2Tnf7+f743zO+VwOr/u57/P9JrkAuABg/fr1LCwsTL0Pg8HgHzzv7bcfC7yEW2/9Ivfe+9TU+6TJWW68tXY53v3iePePY94v0xrvSYbrB4DjxtaP7dpWeuz8kmMXlu5UVVuALQCbN2+u+fn5pbtM3MLCAkuf9/rrh49nnPFjzM1NvUuaoOXGW2uX490vjnf/OOb9Mq3xnmRZyHZgY5INSdYB5wDbVnjs1cDrkzy3+yLj67u2Z4TBAI44AoO1JElSz0wsXFfVXuDtDEPx3cCVVXVnkkuSvAkgyclJdgJnA3+U5M7u2EeAdzMM6NuBS7q2Z4TBwHprSZKkPppozXVVXQVctaTtXWPL2xmWfCx37FZg6yT7NymLi16GT5IkqY+8Q+MEOHMtSZLUT4brCTBcS5Ik9ZPhegIGA8tCJEmS+shwPQGLi85cS5Ik9ZHhegIsC5EkSeonw/UEGK4lSZL6yXA9AV6KT5IkqZ8M143t22fNtSRJUl8ZrhvbtQuqDNeSJEl9ZLhubDAYPloWIkmS1D+G68YWF4ePzlxLkiT1j+G6sdHMteFakiSpfwzXjRmuJUmS+stw3dioLMSaa0mSpP4xXDfmzLUkSVJ/Ga4bM1xLkiT1l+G6MctCJEmS+stw3Zgz15IkSf1luG5sFK6f9azZ9kOSJEnTZ7hubDCAI4+EublZ90SSJEnTZrhubHHRkhBJkqS+Mlw3NhgYriVJkvrKcN2Y4VqSJKm/DNeNLS56GT5JkqS+Mlw35sy1JElSfxmuGzNcS5Ik9ZfhurHBwLIQSZKkvjJcN+al+CRJkvrLcN2YZSGSJEn9ZbhuaN8+eOIJw7UkSVJfGa4beuKJ4aM115IkSf1kuG5oMBg+OnMtSZLUT4brhgzXkiRJ/Wa4bmgUri0LkSRJ6ifDdUOLi8NHZ64lSZL6yXDdkGUhkiRJ/Wa4bshwLUmS1G+G64ZGZSHWXEuSJPWT4bohZ64lSZL6zXDdkOFakiSp3wzXDY3KQo48crb9kCRJ0mwYrhsaDIb11of4rkqSJPWSMbChwcCSEEmSpD4zXDc0mrmWJElSPxmuG1pcdOZakiSpzwzXDVkWIkmS1G+G64YM15IkSf1muG5ocdGaa0mSpD4zXDfkzLUkSVK/Ga4bMlxLkiT1m+G6IS/FJ0mS1G8TDddJzkhyT5IdSS5eZvvhST7Zbb8xyfFd+/FJdiW5rfv3oUn2s4WnnoLdu525liRJ6rNDJ3XiJHPAB4GfBnYC25Nsq6q7xnY7H3i0ql6S5BzgMuDN3bavVtWmSfWvtcXF4aPhWpIkqb8mOXN9CrCjqu6rqu8CnwDOXLLPmcDl3fKngNOTZIJ9mpjBYPhouJYkSeqvic1cAy8Evjm2vhN4zdPtU1V7kzwGHNNt25DkVuBx4L9W1ReXPkGSC4ALANavX8/CwkLTF7ASg8GAhYUFdu48EngN3/jG3SwsfGvq/dB0jMZb/eB494vj3T+Oeb9Ma7wnGa5X40HgRVX1cJJXA59NclJVPT6+U1VtAbYAbN68uebn56fe0YWFBebn57n11uH6ySe/nPn5l0+9H5qO0XirHxzvfnG8+8cx75dpjfcky0IeAI4bWz+2a1t2nySHAkcDD1fVnqp6GKCqbgG+Crx0gn1dNctCJEmSNMlwvR3YmGRDknXAOcC2JftsA87rls8Crq2qSvL87guRJDkB2AjcN8G+rtroC41eik+SJKm/JlYW0tVQvx24GpgDtlbVnUkuAW6uqm3AR4ArkuwAHmEYwAF+HLgkyZPAPuBtVfXIpPragjPXkiRJmmjNdVVdBVy1pO1dY8u7gbOXOe7TwKcn2bfWDNeSJEnyDo2NjMK1ZSGSJEn9ZbhuxJvISJIkyXDdyGAACRx55Kx7IkmSpFkxXDcyGAxnrZ+Z95eUJElSC4brRhYXrbeWJEnqO8N1I6OZa0mSJPWX4boRw7UkSZIM140MBpaFSJIk9Z3hupHFRWeuJUmS+s5w3YhlIZIkSTJcN2K4liRJkuG6ES/FJ0mSJMN1I85cS5IkyXDdwN69sGeP4VqSJKnvDNcNLC4OHy0LkSRJ6jfDdQODwfDRmWtJkqR+M1w3YLiWJEkSGK6bGIVry0IkSZL6zXDdwKjm2plrSZKkfjNcN2BZiCRJksBw3YThWpIkSWC4bsJL8UmSJAkM1004cy1JkiQwXDdhuJYkSRIYrpsYDOCQQ+Dww2fdE0mSJM2S4bqBxcXhrHUy655IkiRplgzXDQwGloRIkiTJcN2E4VqSJElguG5icdHL8EmSJMlw3YQz15IkSQLDdROGa0mSJIHhuonBwLIQSZIkGa6bGF2KT5IkSf1muG7AshBJkiSB4boJw7UkSZLAcL1qTz4ZnnzSmmtJkiQZrldt9+45wJlrSZIkGa5Xbdcuw7UkSZKGDNerNJq5tixEkiRJhutVcuZakiRJI4brVTJcS5IkacRwvUqjcG1ZiCRJkgzXq7Rr1/AtdOZakiRJhutVsixEkiRJI4brVTJcS5IkacRwvUpeik+SJEkjhutV2rVrjkMPhXXrZt0TSZIkzZrhepV27ZrjqKMgmXVPJEmSNGuG61XatWvOkhBJkiQBhutV2717zi8zSpIkCZhwuE5yRpJ7kuxIcvEy2w9P8slu+41Jjh/b9s6u/Z4k/3KS/VyNUVmIJEmSNLFwnWQO+CDwM8CJwFuSnLhkt/OBR6vqJcD7gMu6Y08EzgFOAs4A/rA73w8cw7UkSZJGJjlzfQqwo6ruq6rvAp8Azlyyz5nA5d3yp4DTk6Rr/0RV7amqrwE7uvP9wHn00cN48EG44YZZ90SSJEmzNslw/ULgm2PrO7u2Zfepqr3AY8AxKzx25m64AXbufBb33gunn27AliRJ6rtDZ92B1UhyAXABwPr161lYWJjq83/84y+iagMAe/bsY+vW+9mz5xtT7YOmazAYTP3nTLPjePeL490/jnm/TGu8JxmuHwCOG1s/tmtbbp+dSQ4FjgYeXuGxVNUWYAvA5s2ba35+vlXfV+Tww+GKK55i79451q07hF/5lRM49dQTptoHTdfCwgLT/jnT7Dje/eJ4949j3i/TGu9JloVsBzYm2ZBkHcMvKG5bss824Lxu+Szg2qqqrv2c7moiG4CNwE0T7OtBOfVUeO97b+fd74ZrrhmuS5Ikqb8mNnNdVXuTvB24GpgDtlbVnUkuAW6uqm3AR4ArkuwAHmEYwOn2uxK4C9gL/HpVPTWpvq7GSSc9jr/0SpIkCSZcc11VVwFXLWl719jybuDspzn2UuDSSfZPkiRJask7NEqSJEmNGK4lSZKkRgzXkiRJUiOGa0mSJKkRw7UkSZLUiOFakiRJasRwLUmSJDViuJYkSZIaMVxLkiRJjRiuJUmSpEYM15IkSVIjhmtJkiSpEcO1JEmS1IjhWpIkSWrEcC1JkiQ1kqqadR+aSPJt4OszeOrnAf9vBs+r2XC8+8Xx7hfHu38c835pOd4vrqrnL7dhzYTrWUlyc1VtnnU/NB2Od7843v3iePePY94v0xpvy0IkSZKkRgzXkiRJUiOG69XbMusOaKoc735xvPvF8e4fx7xfpjLe1lxLkiRJjThzLUmSJDViuD5ISc5Ick+SHUkunnV/1EaSrUkeSnLHWNsPJ/l8kq90j8/t2pPkD7qfgS8ledXseq4DleS4JNcluSvJnUku7Nod7zUqyRFJbkpyezfmv921b0hyYze2n0yyrms/vFvf0W0/fpb918FJMpfk1iR/2a073mtUkvuTfDnJbUlu7tqm/pluuD4ISeaADwI/A5wIvCXJibPtlRr5KHDGkraLgWuqaiNwTbcOw/Hf2P27APgfU+qj2tgL/MeqOhF4LfDr3X/HjvfatQc4rapeCWwCzkjyWuAy4H1V9RLgUeD8bv/zgUe79vd1++mZ50Lg7rF1x3tt+8mq2jR2yb2pf6Ybrg/OKcCOqrqvqr4LfAI4c8Z9UgNVdT3wyJLmM4HLu+XLgZ8ba/9YDf018JwkL5hOT7VaVfVgVf1Nt/x3DP/n+0Ic7zWrG7tBt3pY96+A04BPde1Lx3z0s/Ap4PQkmVJ31UCSY4E3AH/crQfHu2+m/pluuD44LwS+Oba+s2vT2rS+qh7slv8vsL5b9udgjej+/PvPgBtxvNe0rkTgNuAh4PPAV4HvVNXebpfxcf3emHfbHwOOmW6PtUrvB/4zsK9bPwbHey0r4K+S3JLkgq5t6p/ph7Y4idQXVVVJvMTOGpLkKODTwL+vqsfHJ6oc77Wnqp4CNiV5DvAZ4GUz7pImJMkbgYeq6pYk87Puj6bidVX1QJJ/Anw+yd+Ob5zWZ7oz1wfnAeC4sfVjuzatTd8a/amoe3yoa/fn4BkuyWEMg/XHq+ovumbHuweq6jvAdcCpDP8cPJpsGh/X7415t/1o4OEpd1UH718Ab0pyP8PyzdOA38fxXrOq6oHu8SGGvzyfwgw+0w3XB2c7sLH7xvE64Bxg24z7pMnZBpzXLZ8HfG6s/Ze7bxy/Fnhs7E9P+gHX1VJ+BLi7qn5vbJPjvUYleX43Y02SI4GfZlhrfx1wVrfb0jEf/SycBVxb3hziGaOq3llVx1bV8Qz/P31tVZ2L470mJXl2kh8aLQOvB+5gBp/p3kTmICX5VwxrueaArVV16Yy7pAaS/BkwDzwP+Bbwm8BngSuBFwFfB36hqh7pwtkHGF5d5Ang31TVzbPotw5cktcBXwS+zPfrMf8Lw7prx3sNSvIKhl9ommM4uXRlVV2S5ASGM5s/DNwK/Ouq2pPkCOAKhvX4jwDnVNV9s+m9VqMrC7moqt7oeK9N3bh+pls9FPjTqro0yTFM+TPdcC1JkiQ1YlmIJEmS1IjhWpIkSWrEcC1JkiQ1YriWJEmSGjFcS5IkSY0YriVpP5JUkveOrV+U5LcanfujSc7a/56rfp6zk9yd5Lol7cd3r+8dY20fSPLW/ZzvbUl+eT/7vDXJB55m2+AAui9JzxiGa0navz3Azyd53qw7Mm7sLnMrcT7wq1X1k8tsewi4sLsp1opU1Yeq6mMH8PwTd4DvhyRNhOFakvZvL7AF+A9LNyydeR7NyCaZT/KFJJ9Lcl+S/5bk3CQ3Jflykh8dO81PJbk5yb1J3tgdP5fkPUm2J/lSkl8bO+8Xk2wD7lqmP2/pzn9Hksu6tncBrwM+kuQ9y7y+bwPX8P27mI2f70eT/O8kt3TP+7Ku/beSXNQtn9z18bauz3eMneJHuuO/kuS/Lzn3+5LcmeSaJM/v2jYl+evufJ9J8tyufSHJ5m75ed0trUez49uSXAtck+QFSa7v+nJHkh9b5vVK0sQYriVpZT4InJvk6AM45pXA24CXA78EvLSqTgH+GHjH2H7HA6cAbwA+1N0p7nyGt+M9GTgZ+NUkG7r9XwVcWFUvHX+yJD8CXAacBmwCTk7yc1V1CXAzcG5V/aen6etlwEVJ5pa0bwHeUVWvBi4C/nCZY/8n8GtVtQl4asm2TcCbgX8KvDnJcV37s4Gbq+ok4AsM74YK8DHgN6rqFQzvnvmb7N+rgLOq6ieAXwSu7vrySuC2FRwvSc34JzRJWoGqejzJx4B/B+xa4WHbq+pBgCRfBf6qa/8yMF6ecWVV7QO+kuQ+4GXA64FXjM2KHw1sBL4L3FRVX1vm+U4GFqrq291zfhz4ceCzK3h99yW5kWE4pTv+KOCfA38+vFMwAIePH5fkOcAPVdUNXdOfAm8c2+Waqnqs2/cu4MXANxnecv6T3T5/AvxF94vLc6rqC1375cCf76/vwOer6pFueTuwNclhwGerynAtaaqcuZaklXs/wxnlZ4+17aX7LE1yCDBet7xnbHnf2Po+/v7kRi15ngLCcMZ4U/dvQ1WNwvniql7F0/sd4De654bh6/rOWB82VdXLD/Cc4+/BUzz9pM7S92Cp773PwBFLtn3v/aiq6xn+QvEA8NH9felSklozXEvSCnWzo1cyDNgj9wOv7pbfBBx2EKc+O8khXR32CcA9wNXAv+1mYEny0iTP/sdOAtwE/ERXkzwHvIVhycWKVNXfMqzj/tlu/XHga0nO7vqQJK9ccsx3gL9L8pqu6ZwVPt0hwGhW/heB/9PNcD86Vif9S2P9v5/vv89Pe3WVJC8GvlVVH2ZYfvOqFfZHkpowXEvSgXkvMH7VkA8zDLS3A6dycLPK32AYjP8X8Laq2s0wGN4F/E33BcE/Yj+lfF0JysXAdcDtwC1V9bkD7MulwLFj6+cC53ev707gzGWOOR/4cJLbGM7qP7aC51kETule22nAJV37ecB7knyJYb32qP13Gf6ycSt///1fah64vdvvzcDvr6AvktRMqvb3lzhJkp5ekqOqanSVlIuBF1TVhTPuliTNhF9olCSt1huSvJPh/1O+Drx1tt2RpNlx5lqSJElqxJprSZIkqRHDtSRJktSI4VqSJElqxHAtSZIkNWK4liRJkhoxXEuSJEmN/H8du/erZZLwdAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Comparison"
      ],
      "metadata": {
        "id": "yj5SM70V1xq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from toolbox_02450 import mcnemar\n",
        "alpha = 0.05\n",
        "\n",
        "log_predictions_test = np.concatenate(log_predictions_test)\n",
        "knn_predictions_test = np.concatenate(knn_predictions_test)\n",
        "baseline_predictions_test = np.concatenate(baseline_predictions_test)\n",
        "test_true_values = np.concatenate(test_true_values)\n",
        "\n",
        "# Logistic to KNN\n",
        "print(\"Logistic to KNN\")\n",
        "[thetahat, CI, p] = mcnemar(test_true_values, log_predictions_test, knn_predictions_test, alpha = alpha)\n",
        "print(\"theta = theta_A-theta_B point estimate\", thetahat, \" CI: \", CI, \"p-value\", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Logistic to Baseline\n",
        "print(\"Logistic to Baseline\")\n",
        "[thetahat, CI, p] = mcnemar(test_true_values, log_predictions_test, baseline_predictions_test, alpha = alpha)\n",
        "print(\"theta = theta_A-theta_B point estimate\", thetahat, \" CI: \", CI, \"p-value\", p)\n",
        "print(\"\\n\")\n",
        "\n",
        "# KNN to Baseline\n",
        "print(\"KNN to Baseline\")\n",
        "[thetahat, CI, p] = mcnemar(test_true_values, knn_predictions_test, baseline_predictions_test, alpha = alpha)\n",
        "print(\"theta = theta_A-theta_B point estimate\", thetahat, \" CI: \", CI, \"p-value\", p)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "sVODrKQT1zxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e01daf-0079-4770-99c7-a8c30eaaaa46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic to KNN\n",
            "Result of McNemars test using alpha= 0.05\n",
            "Comparison matrix n\n",
            "[[1228.  142.]\n",
            " [  90.  377.]]\n",
            "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (0.012108528474162883, 0.04449818753173629)\n",
            "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 0.0007771346459499484\n",
            "theta = theta_A-theta_B point estimate 0.028307022318998367  CI:  (0.012108528474162883, 0.04449818753173629) p-value 0.0007771346459499484\n",
            "\n",
            "\n",
            "Logistic to Baseline\n",
            "Result of McNemars test using alpha= 0.05\n",
            "Comparison matrix n\n",
            "[[812. 558.]\n",
            " [187. 280.]]\n",
            "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (0.17427085584191415, 0.22949023767715193)\n",
            "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 1.0901363430218254e-43\n",
            "theta = theta_A-theta_B point estimate 0.20195971692977682  CI:  (0.17427085584191415, 0.22949023767715193) p-value 1.0901363430218254e-43\n",
            "\n",
            "\n",
            "KNN to Baseline\n",
            "Result of McNemars test using alpha= 0.05\n",
            "Comparison matrix n\n",
            "[[760. 558.]\n",
            " [239. 280.]]\n",
            "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (0.14453225134048786, 0.20262410554052224)\n",
            "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 3.260030620211951e-30\n",
            "theta = theta_A-theta_B point estimate 0.17365269461077845  CI:  (0.14453225134048786, 0.20262410554052224) p-value 3.260030620211951e-30\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dummy Classifier**: we will label all of the predictions as the main class"
      ],
      "metadata": {
        "id": "gnQR7esTqANP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy_clf = DummyClassifier() #use uniform strategy\n",
        "# dummy_clf.fit(X_train,y_train)\n",
        "# y_test_predict = dummy_clf.predict(X_test)\n",
        "# dummy_modelscore = dummy_clf.score(X_test,y_test)\n",
        "# print(dummy_modelscore)\n",
        "# print(metrics.confusion_matrix(y_test, y_test_predict))\n",
        "# print(metrics.classification_report(y_test, y_test_predict))"
      ],
      "metadata": {
        "id": "SPX81SJQqX9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "awVbnWygtnfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LR_model = LogisticRegression(random_state=1,max_iter=1000)\n",
        "# LR_model.fit(X_train,y_train)\n",
        "# y_test_predict = None\n",
        "# y_test_predict = LR_model.predict(X_test)\n",
        "# model_scoreLR = LR_model.score(X_test, y_test)\n",
        "# print(model_scoreLR)\n",
        "# print(metrics.confusion_matrix(y_test, y_test_predict))\n",
        "# print(metrics.classification_report(y_test, y_test_predict))"
      ],
      "metadata": {
        "id": "0uZTOk0KtqSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from numpy import mean\n",
        "# from numpy import std\n",
        "# from sklearn.datasets import make_classification\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "# outer_results = list()\n",
        "# for train_ix, test_ix in cv_outer.split(features):\n",
        "# \t# split data\n",
        "#   X_train, X_test = features.iloc[train_ix, :], features.iloc[test_ix, :]\n",
        "#   y_train, y_test = response.iloc[train_ix], response.iloc[test_ix]\n",
        "  \n",
        "#   # configure the  inner cross-validation\n",
        "#   cv_inner = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "#   model = LogisticRegression(max_iter=10000)\n",
        "#   # define search space for the hyperparameters we want to optimize\n",
        "#   space = dict()\n",
        "#   space['C'] = [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 20, 50, 100]\n",
        "#   search = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True)\n",
        "#   result = search.fit(X_train, y_train)\n",
        "#   # get the best performing model fit on the whole training set\n",
        "#   best_model = result.best_estimator_\n",
        "#   # evaluate model on the hold out dataset\n",
        "#   yhat = best_model.predict(X_test)\n",
        "#   # evaluate the model\n",
        "#   acc = accuracy_score(y_test, yhat)\n",
        "#   # store the result\n",
        "#   outer_results.append(acc)\n",
        "#   # report progress\n",
        "#   print('>accuracy=%.3f, est=%.3f, parameter_val=%s' % (acc, result.best_score_, result.best_params_))\n",
        "# # summarize the estimated performance of the model\n",
        "# print('Accuracy: %.3f, Standard deviation: %.3f' % (mean(outer_results), std(outer_results)))"
      ],
      "metadata": {
        "id": "OyAlqLV_LyK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-nearest neighbours**"
      ],
      "metadata": {
        "id": "XQ_RPRqptMj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN_model=KNeighborsClassifier()\n",
        "# KNN_model.fit(X_train,y_train)\n",
        "# y_test_predict = None\n",
        "# y_test_predict = KNN_model.predict(X_test)\n",
        "# model_scoreKNN = KNN_model.score(X_test, y_test)\n",
        "# print(model_scoreKNN)\n",
        "# print(metrics.confusion_matrix(y_test, y_test_predict))\n",
        "# print(metrics.classification_report(y_test, y_test_predict))"
      ],
      "metadata": {
        "id": "raNqNpBuraAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from numpy import mean\n",
        "# from numpy import std\n",
        "# from sklearn.datasets import make_classification\n",
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "# outer_results = list()\n",
        "# for train_ix, test_ix in cv_outer.split(features):\n",
        "# \t# split data\n",
        "#   X_train, X_test = features.iloc[train_ix, :], features.iloc[test_ix, :]\n",
        "#   y_train, y_test = response.iloc[train_ix], response.iloc[test_ix]\n",
        "  \n",
        "#   # configure the  inner cross-validation\n",
        "#   cv_inner = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "#   model = KNeighborsClassifier()\n",
        "#   # define search space for the hyperparameters we want to optimize\n",
        "#   space = dict()\n",
        "#   space['n_neighbors'] = list(range(1,200,10))\n",
        "#   search = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True)\n",
        "#   result = search.fit(X_train, y_train)\n",
        "#   # get the best performing model fit on the whole training set\n",
        "#   best_model = result.best_estimator_\n",
        "#   # evaluate model on the hold out dataset\n",
        "#   yhat = best_model.predict(X_test)\n",
        "#   # evaluate the model\n",
        "#   acc = accuracy_score(y_test, yhat)\n",
        "#   # store the result\n",
        "#   outer_results.append(acc)\n",
        "#   # report progress\n",
        "#   print('>accuracy=%.3f, est=%.3f, parameter_val=%s' % (acc, result.best_score_, result.best_params_))\n",
        "# # summarize the estimated performance of the model\n",
        "# print('Accuracy: %.3f, Standard deviation: %.3f' % (mean(outer_results), std(outer_results)))"
      ],
      "metadata": {
        "id": "vVASzYwF7kJv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vD4PcoWQ7fuZ",
        "1CxOMDJw86Hw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}